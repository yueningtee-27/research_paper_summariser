{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f83631fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-2.6.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.4.37)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.10.23)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-2.6.1-py3-none-any.whl (1.0 MB)\n",
      "Downloading langchain_openai-1.0.1-py3-none-any.whl (81 kB)\n",
      "Installing collected packages: openai, langchain-openai\n",
      "\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "   ---------------------------------------- 2/2 [langchain-openai]\n",
      "\n",
      "Successfully installed langchain-openai-1.0.1 openai-2.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openai langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e01f7a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from dotenv) (1.2.1)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Installing collected packages: dotenv\n",
      "Successfully installed dotenv-0.9.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "import requests\n",
    "from lxml import etree\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def summarize_research_paper(\n",
    "    pdf_path,\n",
    "    grobid_url=\"http://localhost:8070/api/processFulltextDocument\",\n",
    "    ollama_base_url=\"http://localhost:11434\",\n",
    "    embedding_model_name=\"nomic-embed-text\",\n",
    "    llm_model_name=\"gpt-4o-mini\",\n",
    "    top_k=4,\n",
    "    rerank_with_llm=True,\n",
    "    temperature=0.05,\n",
    "):\n",
    "    \"\"\"Run full data science paper summarization pipeline on one PDF.\"\"\"\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize models\n",
    "    embedding_model = OllamaEmbeddings(model=embedding_model_name, base_url=ollama_base_url)\n",
    "    llm = ChatOpenAI(model=llm_model_name, temperature=temperature)\n",
    "\n",
    "    # ---------------- GROBID Extraction ----------------\n",
    "    def parse_div(div):\n",
    "        heading = div.findtext('{*}head')\n",
    "        content = \" \".join(list(div.itertext())).strip()\n",
    "        subsections = [parse_div(d) for d in div.findall('{*}div')]\n",
    "        return {\"heading\": heading.strip() if heading else None, \"content\": content, \"subsections\": subsections}\n",
    "\n",
    "    def extract_sections_from_grobid(xml_text):\n",
    "        root = etree.fromstring(xml_text.encode(\"utf-8\"))\n",
    "        body = root.find('.//{*}body')\n",
    "        if body is None:\n",
    "            raise ValueError(\"No <body> element found in TEI XML\")\n",
    "        sections = [parse_div(d) for d in body.findall('{*}div')]\n",
    "        return sections\n",
    "\n",
    "    def flatten_sections(sections):\n",
    "        flat = []\n",
    "        for s in sections:\n",
    "            flat.append({\"heading\": s[\"heading\"], \"content\": s[\"content\"]})\n",
    "            flat.extend(flatten_sections(s[\"subsections\"]))\n",
    "        return flat\n",
    "\n",
    "    def load_pdf_sections_via_grobid(pdf_path):\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            resp = requests.post(grobid_url, files={\"input\": f})\n",
    "        xml_text = resp.text\n",
    "        sections = extract_sections_from_grobid(xml_text)\n",
    "        flat_sections = flatten_sections(sections)\n",
    "        flat_sections = [s for s in flat_sections if s[\"content\"].strip()]\n",
    "        print(f\"Extracted {len(flat_sections)} sections from GROBID\")\n",
    "        return flat_sections\n",
    "\n",
    "    # ---------------- Build FAISS index ----------------\n",
    "    def build_section_index(sections):\n",
    "        print(\"Embedding and indexing sections...\")\n",
    "        vectors = [np.array(embedding_model.embed_query(s[\"content\"]), dtype=np.float32) for s in sections]\n",
    "        embeddings_array = np.vstack(vectors).astype(\"float32\")\n",
    "        d = embeddings_array.shape[1]\n",
    "        index = faiss.IndexFlatL2(d)\n",
    "        index.add(embeddings_array)\n",
    "        print(f\"FAISS index built with {index.ntotal} vectors (dimension {d})\")\n",
    "        return index, embeddings_array\n",
    "\n",
    "    # ---------------- Retrieval & Reranking ----------------\n",
    "    def retrieve_sections_for_query(query, index, sections):\n",
    "        q_emb = np.array([embedding_model.embed_query(query)], dtype=np.float32)\n",
    "        distances, indices = index.search(q_emb, top_k)\n",
    "        retrieved = [{\"idx\": idx, \"text\": sections[idx][\"content\"], \"heading\": sections[idx][\"heading\"]}\n",
    "                     for dist, idx in zip(distances[0], indices[0])]\n",
    "        return retrieved\n",
    "\n",
    "    def rerank(query, candidates):\n",
    "        prompt_template = \"\"\"You are a helpful research assistant. Given the question: \"{query}\"\n",
    "For each candidate passage, give a relevance score between 1 (irrelevant) and 10 (directly answers the question).\n",
    "Return lines in the format: score<TAB>passage_index\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Candidates:\n",
    "{listings}\n",
    "\"\"\"\n",
    "        listings = \"\\n\\n\".join([f\"[{i}] {c['text'][:400].replace('\\\\n',' ')}\" for i, c in enumerate(candidates)])\n",
    "        prompt = prompt_template.format(query=query, listings=listings)\n",
    "        response = llm.invoke(prompt)\n",
    "        text = response if isinstance(response, str) else getattr(response, \"content\", str(response))\n",
    "        scores = []\n",
    "        for line in text.splitlines():\n",
    "            parts = line.strip().split()\n",
    "            try:\n",
    "                score = float(parts[0])\n",
    "                idx_token = [p for p in parts if p.startswith(\"[\") and p.endswith(\"]\")]\n",
    "                if idx_token:\n",
    "                    pid = int(idx_token[0].strip(\"[]\"))\n",
    "                    scores.append((pid, score))\n",
    "            except Exception:\n",
    "                continue\n",
    "        if not scores:\n",
    "            return candidates\n",
    "        scored_sorted = sorted(scores, key=lambda x: -x[1])\n",
    "        return [candidates[i] for i, _ in scored_sorted[:top_k]]\n",
    "\n",
    "    # ---------------- Section Summaries ----------------\n",
    "    SECTION_QUERIES = {\n",
    "        \"Title & Authors\": \"What is the title and who are the authors of the paper? Provide year if present.\",\n",
    "        \"Problem Statement\": \"What research problem or objective does this paper address?\",\n",
    "        \"Dataset\": \"Which datasets were used in the experiments? Provide names, sizes, sources if available.\",\n",
    "        \"Methodology\": \"Describe the model architecture or methods proposed in the paper.\",\n",
    "        \"Evaluation & Metrics\": \"What evaluation metrics and experimental results are reported?\",\n",
    "        \"Limitations\": \"What limitations or weaknesses do the authors mention?\",\n",
    "        \"Future Work\": \"What future work or extensions do the authors propose?\"\n",
    "    }\n",
    "\n",
    "    section_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert AI research assistant. Summarize the section \"{section_name}\" based on context below.\n",
    "{context}\n",
    "\"\"\")\n",
    "    section_chain = section_prompt | llm | StrOutputParser()\n",
    "\n",
    "    def summarize_section(section_name, query, index, sections):\n",
    "        candidates = retrieve_sections_for_query(query, index, sections)\n",
    "        if rerank_with_llm:\n",
    "            candidates = rerank(query, candidates)\n",
    "        context = \"\\n\\n\".join([f\"### {c['heading']}\\n{c['text']}\" for c in candidates])\n",
    "        return section_chain.invoke({\"section_name\": section_name, \"context\": context})\n",
    "\n",
    "    # ---------------- Combine Final Summary ----------------\n",
    "    final_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert AI assistant. Combine the following section summaries into a cohesive academic paper summary.\n",
    "{sections_text}\n",
    "\"\"\")\n",
    "    final_chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "    def combine_summaries(section_summaries):\n",
    "        text = \"\\n\\n\".join([f\"## {k}\\n{v}\" for k, v in section_summaries.items()])\n",
    "        return final_chain.invoke({\"sections_text\": text})\n",
    "\n",
    "    # ---------------- Run Pipeline ----------------\n",
    "    start = time.time()\n",
    "    sections = load_pdf_sections_via_grobid(pdf_path)\n",
    "    index, _ = build_section_index(sections)\n",
    "\n",
    "    section_summaries = {}\n",
    "    for name, query in SECTION_QUERIES.items():\n",
    "        print(f\"Summarizing section: {name}\")\n",
    "        section_summaries[name] = summarize_section(name, query, index, sections)\n",
    "\n",
    "    final_summary = combine_summaries(section_summaries)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    print(f\"\\nPipeline completed in {elapsed:.2f}s.\\n\")\n",
    "    print(\"==== Final Summary (First 1000 chars) ====\")\n",
    "    print(final_summary[:1000] + \"...\\n\")\n",
    "\n",
    "    return {\n",
    "        \"sections\": section_summaries,\n",
    "        \"final_summary\": final_summary,\n",
    "        \"elapsed_sec\": elapsed\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea5a8441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Extracted 20 sections from GROBID\n",
      "Embedding and indexing sections...\n",
      "FAISS index built with 20 vectors (dimension 768)\n",
      "Summarizing section: Title & Authors\n",
      "Summarizing section: Problem Statement\n",
      "Summarizing section: Dataset\n",
      "Summarizing section: Methodology\n",
      "Summarizing section: Evaluation & Metrics\n",
      "Summarizing section: Limitations\n",
      "Summarizing section: Future Work\n",
      "\n",
      "Pipeline completed in 127.02s.\n",
      "\n",
      "==== Final Summary (First 1000 chars) ====\n",
      "### Summary of the Research Paper on Hospital Bed Capacity Forecasting\n",
      "\n",
      "This research paper addresses the critical issue of hospital bed capacity forecasting, specifically focusing on Length of Stay (LOS) classification within the Heart ward. The authors, whose names and affiliations are acknowledged in the introductory section, highlight a significant gap in existing literature: while there is extensive research on LOS forecasting, studies specifically targeting LOS classification remain scarce. The authors argue that effective classification of patients based on various features is essential for optimizing hospital bed management and improving patient care strategies.\n",
      "\n",
      "The dataset utilized in this study comprises 51,231 records collected from 2011 to 2018, focusing on relevant features such as age and LOS. After filtering out outliers, 47,605 records were retained, with a division of 70% for training and 30% for testing purposes. This structured dataset serves as the foundation for t...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = summarize_research_paper(\n",
    "    pdf_path=\"papers/hospital_bed_capacity_planning.pdf\",\n",
    "    embedding_model_name=\"nomic-embed-text\",\n",
    "    top_k=4,\n",
    "    rerank_with_llm=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9e68a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Summary of the Research Paper on Hospital Bed Capacity Forecasting\\n\\nThis research paper addresses the critical issue of hospital bed capacity forecasting, specifically focusing on Length of Stay (LOS) classification within the Heart ward. The authors, whose names and affiliations are acknowledged in the introductory section, highlight a significant gap in existing literature: while there is extensive research on LOS forecasting, studies specifically targeting LOS classification remain scarce. The authors argue that effective classification of patients based on various features is essential for optimizing hospital bed management and improving patient care strategies.\\n\\nThe dataset utilized in this study comprises 51,231 records collected from 2011 to 2018, focusing on relevant features such as age and LOS. After filtering out outliers, 47,605 records were retained, with a division of 70% for training and 30% for testing purposes. This structured dataset serves as the foundation for the analysis and prediction of patient LOS in the Heart ward.\\n\\nThe methodology employed is a hybrid approach that integrates data analysis (DA), machine learning (ML), deep learning (DL), and statistical inference. The study begins with descriptive analyses of key factors, including LOS and the Number of Hospitalizations per patient (NHP), to derive actionable insights. The framework encompasses LOS classification, NHP distribution analysis, and NHP forecasting, all of which are crucial for predicting future bed requirements. Various algorithms for LOS classification and NHP forecasting are evaluated, with the study identifying the most suitable ones based on existing literature.\\n\\nIn evaluating the LOS classification algorithms, the study employs several ML techniques, utilizing the Sklearn library in Python. Among the tested algorithms—Bayesian Networks (BN), K-Nearest Neighbor (KNN), Support Vector Machines (SVM), Decision Trees (DT), and Logistic Regression (LR)—SVM demonstrated the highest accuracy, particularly in classifying patients into six distinct LOS categories. The evaluation metrics reveal that over 95.5% of patients had a LOS of less than 20 days, with demographic analyses indicating that older patients typically had shorter stays, while children exhibited longer LOS, suggesting a need for specialized pediatric heart wards.\\n\\nThe paper acknowledges several limitations, including its exclusive focus on the Heart ward and the neglect of other critical resources such as specialists and nurses. It also points out the lack of consideration for various factors influencing hospital performance, such as insurance service levels and economic conditions. The authors recommend future research to incorporate multivariate time series datasets and advanced machine learning tools to address these limitations and the inherent uncertainty in decision-making processes.\\n\\nIn conclusion, the future work section emphasizes the necessity for further research in HBC forecasting, advocating for a broader scope that includes forecasting for other essential resources and factors influencing hospitalizations. By addressing these areas, the authors aim to develop a more comprehensive and robust framework for HBC forecasting, ultimately enhancing decision-making in healthcare settings.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['final_summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a99fc80",
   "metadata": {},
   "source": [
    "# Multi-agent \n",
    "- Agent 1: Section Extractor \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77895a75",
   "metadata": {},
   "source": [
    "## Section Extractor GROBID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53f604da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "\n",
    "class GrobidSectionAgent:\n",
    "    \"\"\"\n",
    "    Agent for detecting and extracting sections from a research paper PDF using GROBID.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grobid_url: str = \"http://localhost:8070/api/processFulltextDocument\"):\n",
    "        self.grobid_url = grobid_url\n",
    "\n",
    "    def extract_sections(self, pdf_path: str):\n",
    "        \"\"\"\n",
    "        Uploads a PDF to GROBID and extracts section structure as a flat list.\n",
    "        \"\"\"\n",
    "        print(f\"[GROBID] Processing {pdf_path} ...\")\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            response = requests.post(self.grobid_url, files={\"input\": f})\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(f\"GROBID request failed: {response.status_code} {response.text[:500]}\")\n",
    "\n",
    "        xml_text = response.text\n",
    "        # print(\"Printing xml_text...\", xml_text)\n",
    "        sections = self._parse_tei_xml(xml_text)\n",
    "        flat_sections = self._flatten_sections(sections)\n",
    "        return [s for s in flat_sections if s[\"content\"].strip()]\n",
    "\n",
    "    # ---------------- Private Helpers ----------------\n",
    "\n",
    "    def _parse_tei_xml(self, xml_text: str):\n",
    "        \"\"\"Parse TEI XML and recursively extract <div> sections.\"\"\"\n",
    "        root = etree.fromstring(xml_text.encode(\"utf-8\"))\n",
    "        body = root.find(\".//{*}body\")\n",
    "        if body is None:\n",
    "            raise ValueError(\"No <body> element found in TEI XML\")\n",
    "\n",
    "        def parse_div(div):\n",
    "            heading = div.findtext(\"{*}head\")\n",
    "            content = \" \".join(list(div.itertext())).strip()\n",
    "            subsections = [parse_div(d) for d in div.findall(\"{*}div\")]\n",
    "            return {\"heading\": heading.strip() if heading else None, \"content\": content, \"subsections\": subsections}\n",
    "\n",
    "        return [parse_div(d) for d in body.findall(\"{*}div\")]\n",
    "\n",
    "    def _flatten_sections(self, sections):\n",
    "        \"\"\"Flatten nested section hierarchy into a single list.\"\"\"\n",
    "        flat = []\n",
    "        for s in sections:\n",
    "            flat.append({\"heading\": s[\"heading\"], \"content\": s[\"content\"]})\n",
    "            flat.extend(self._flatten_sections(s[\"subsections\"]))\n",
    "        return flat\n",
    "\n",
    "    # ----- NOT IN USE: Table Extraction -----------\n",
    "    # def extract_tables_from_pdf(pdf_path):\n",
    "    #     tables = camelot.read_pdf(pdf_path, pages=\"all\")\n",
    "    #     extracted = []\n",
    "    #     for i, t in enumerate(tables):\n",
    "    #         extracted.append({\n",
    "    #             \"table_index\": i,\n",
    "    #             \"caption\": None,  # optional: detect caption via proximity\n",
    "    #             \"data\": t.df.to_dict(orient=\"records\")\n",
    "    #         })\n",
    "    #     return extracted\n",
    "\n",
    "\n",
    "# ---------------- Example Usage ----------------\n",
    "def main(): \n",
    "    agent = GrobidSectionAgent()\n",
    "\n",
    "    pdf_path = \"papers/hospital_bed_capacity_planning.pdf\"  # Path to your PDF\n",
    "    sections = agent.extract_sections(pdf_path)\n",
    "\n",
    "    print(f\"✅ Extracted {len(sections)} sections:\\n\")\n",
    "    for s in sections[:5]:\n",
    "        print(f\"--- {s['heading']} ---\\n{s['content'][:400]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "caa66c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GROBID] Processing papers/hospital_bed_capacity_planning.pdf ...\n",
      "✅ Extracted 20 sections:\n",
      "\n",
      "--- Introduction ---\n",
      "Introduction The Hospital Bed Capacity (HBC) forecasting problem has taken significant attention because of its effects on the sustainability of hospitals, particularly in terms of hospital economic efficiency, and patient satisfaction  [1] [2] [3] [4] [5] [6] [7] . The traditional approach to this problem is using simulation or programming models involving several issues, such as the need for som...\n",
      "\n",
      "--- Literature review ---\n",
      "Literature review The literature on healthcare centers' bed capacity forecasting is reviewed to clear the paper's contributions and novelty aspects.  Bachouch et al. (2012)  considered some limitations, such as budget, shared resources, and beds needed by acute and emergency patients, in the problem of hospital bed planning. Using constraints such as incompatibility between pathologies and continu...\n",
      "\n",
      "--- A hybrid data-driven approach to HBC forecasting ---\n",
      "A hybrid data-driven approach to HBC forecasting In this section, the framework of the proposed hybrid data-driven approach to HBC forecasting is provided, and some classification and forecasting algorithms are opted according to the corresponding literature....\n",
      "\n",
      "--- New framework for HBC forecasting ---\n",
      "New framework for HBC forecasting As mentioned in the previous sections, factors of LOS and NHP play the most significant role in the bed capacity forecasting problem. Therefore, conducting descriptive analyses on these factors and other affecting features, for example, patient's age and bed occupancy, provides great initial insights into the problem. Consequently, the LOS classification, NHP dist...\n",
      "\n",
      "--- LOS classification algorithms ---\n",
      "LOS classification algorithms The LOS literature review showed that although there is a long list of research on patients' LOS forecasting, no history exists on the LOS classification  [35] [36] [37] [38] . But Patients' classification based on various features using BN, K-Nearest Neighbor (KNN), SVM, DT, ANN, AdaBoost (AB), LR, Random Forest (RF), Recency-Frequency-Monetary analysis (RFM), Gradie...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main() # takes 6s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b318c",
   "metadata": {},
   "source": [
    "## Section Summary Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba55110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class SectionSummaryAgent:\n",
    "    def __init__(self, llm_model=\"gpt-4o-mini\", temperature=0.05):\n",
    "        self.llm = ChatOpenAI(model=llm_model, temperature=temperature)\n",
    "        # Define prompt template\n",
    "        self.prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert AI research assistant. Summarize the section \"{section_name}\" \n",
    "from the following content. Produce a concise, structured, and academic-style summary.\n",
    "\n",
    "Section Text:\n",
    "{section_text}\n",
    "\n",
    "Instructions:\n",
    "- Include key points and methodology if present\n",
    "- Mention any datasets, results, or experiments\n",
    "- Keep summary factual and concise\n",
    "\"\"\")\n",
    "        self.parser = StrOutputParser()\n",
    "\n",
    "    def summarize(self, section_name, section_text):\n",
    "        # Fill prompt\n",
    "        prompt_input = {\n",
    "            \"section_name\": section_name,\n",
    "            \"section_text\": section_text\n",
    "        }\n",
    "        # Generate summary using LLM\n",
    "        summary = self.prompt_template | self.llm | self.parser\n",
    "        return summary.invoke(prompt_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7527a0d3",
   "metadata": {},
   "source": [
    "## Summary Aggregator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "badbec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SummaryAggregatorAgent:\n",
    "    def __init__(self, llm_model=\"gpt-4o-mini\", temperature=0.05):\n",
    "        self.llm = ChatOpenAI(model=llm_model, temperature=temperature)\n",
    "        # Define prompt template\n",
    "        self.prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert AI research assistant. Your task is to combine the following individual section summaries into one cohesive and well-structured academic summary of the research paper.\n",
    "\n",
    "Guidelines:\n",
    "- Reorganize and merge overlapping or overly detailed sections as needed.\n",
    "- Choose the most logical and meaningful section headings yourself (e.g., Introduction, Methods, Results, Discussion, Conclusion), based on content.\n",
    "- Ensure smooth transitions and consistent academic tone throughout.\n",
    "- Preserve key technical details, results, and findings from the input summaries.\n",
    "- Do not add information that is not supported by the summaries.\n",
    "\n",
    "Input Section Summaries:\n",
    "{sections_text}\n",
    "\n",
    "Output:\n",
    "A coherent and complete academic-style summary written in paragraphs with appropriate section headings.\n",
    "\"\"\")\n",
    "        self.parser = StrOutputParser()\n",
    "\n",
    "    def combine(self, section_summaries):\n",
    "        sections_text = \"\\n\\n\".join(\n",
    "            [f\"## {s['section']}\\n{s['summary']}\" for s in section_summaries]\n",
    "        )\n",
    "        chain = self.prompt_template | self.llm | self.parser\n",
    "        return chain.invoke({\"sections_text\": sections_text})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2235c3",
   "metadata": {},
   "source": [
    "# Final Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74af4d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GROBID] Processing papers/hospital_bed_capacity_planning.pdf ...\n",
      "[{'heading': 'Introduction', 'content': \"Introduction The Hospital Bed Capacity (HBC) forecasting problem has taken significant attention because of its effects on the sustainability of hospitals, particularly in terms of hospital economic efficiency, and patient satisfaction  [1] [2] [3] [4] [5] [6] [7] . The traditional approach to this problem is using simulation or programming models involving several issues, such as the need for some assumptions on attributes of some quantities, for example, the probability distribution of some factors  [8] [9] [10] [11] . In addition, reaching optimum or reasonable solutions is a big challenge of the bed capacity programming models, particularly in the case of large-scale, multi-objective, and integer models. Consequently, using model-free methods for HBC forecasting seems to be a facilitator. Nowadays, business analytics, including Data Analysis (DA), Machine Learning (ML), and Deep Learning (DL) techniques, are widely used as model-free methods in different businesses of services and manufacturing to reach insights on market trends, such as customers' behavior, costs, and technology by no reliance on the simulation or mathematical models  [12] [13] [14] . Also, a reasonable number of their successful applications in the healthcare sector, such as Length of Stay (LOS) forecasting, patient classification, healthcare resources forecasting, and disease diagnosis have been illustrated  [15] [16] [17] [18] . In recent years, a few researchers applied some forecaster tools of ML to predict the required The rest of the paper is as follows. Section 2 reviews the corresponding literature, and Section 3 introduces the proposed data-driven methodology. Section 4 contains the computational results of applying the proposed hybrid data-driven approach in the case study, and finally, Section 5 involves the conclusions, limitations, and recommendations for future works.\"}, {'heading': 'Literature review', 'content': \"Literature review The literature on healthcare centers' bed capacity forecasting is reviewed to clear the paper's contributions and novelty aspects.  Bachouch et al. (2012)  considered some limitations, such as budget, shared resources, and beds needed by acute and emergency patients, in the problem of hospital bed planning. Using constraints such as incompatibility between pathologies and continuity of care, an integer linear programming model was proposed, and the results were compared using several solvers such as the CPLEX  [22] . Ben Abdelaziz and Masmoudi (2012) studied the bed capacity of 157 public hospitals in Tunisia when the demand for beds is random using a multi-objective stochastic programming model to allocate the beds to the hospital's departments. In this problem, the three objectives are the total cost of creating new beds, the number of nurses and doctors, and the optimal number of beds  [11] . The healthcare capacities assessment is a matter of great importance in the same vein.  Devapriya et al. (2015)  proposed a discrete-event simulation model to determine the required bed capacity using forecasted patients' volume and LOS  [23] . Also,  Keegan et al. (2018)  used an expanded HIPPOCRATES macrosimulation method to predict the number of beds needed for public and private hospitals in Ireland by 2030. Baseline year and projected demand and capacity profiles in this analysis are generated through the HIPPOCRATES macro-simulation model of demand and cost of health care developed by the ESRI. The emergency department plays a vital role in the hospital because it is the first deal for patients. Therefore, the effective management of the emergency department is significant in improving the quality of service and treatment. Nas and Koyuncu (2019) used ten ML tools to predict the patients' arrival rates. They applied a simulation model to determine the required number of beds in the emergency department by minimizing the LOS in a case study in Turkey  [24] .  Kutafina et al. (2019)  predicted hospital bed occupancy using recurrent neural networks based on 353520-time series records and four features from a hospital in Germany. The results show that the proposed ML model is a powerful tool for automatic planning and decision-making on existing bed capacity planning  [25] .  Zhu et al. (2020)  developed three mathematical models considering the uncertainty of demand for inpatient beds and the number of periods  [26] . They solved and analyzed these models in a public hospital in China. Predicting the required capacity of hospital wards during pandemics, such as Covid-19s, is essential for the hospital.  Deschepper et al. (2021)  used an incremental Poisson model on the previous patients' statistics to establish a Mont-Carlo simulation model for a 10day prediction of needed beds in various wards of A hospital in Ghent.  Haghshenas et al. (2021)  proposed a bi-objective mixed-integer optimization model for Cancer hospitals' location-allocation problem under bed capacity and efficiency considerations  [27] . They forecasted the cancer incidences in the provinces of Iran in 2040 using LR models to provide a plan for cancer hospitals established in each province in some predefined efficient bed capacities. Also, they applied this forecasting method to determine the demand parameter values in a single objective mathematical model for Cancer-curing supply chain planning  [28] . The healthcare system of a country is very complex and vital, that is why  Kabir et al. (2021)  used Recurrent Neural Network (RNN) to predict population growth and applied the Markov decision process to simulate the number of required beds by the next 30 years in a case study of Bangladesh  [29] .  Ordu et al. (2021)  proposed a linear programming model for bed capacity and staff requirement planning in a case study in England. They also forecasted the demand for specialists with ML tools and simulated the patients' treatment pathway using a discrete-event simulation model. It is crucial to determine the operating room bed capacity according to the critical condition of the patients.  Schiele et al. (2021)  predicted the bed occupancy in the Intensive Care Unit (ICU) using an Artificial Neural Network (ANN) algorithm as an ML forecaster and 6000 patients' data from 2010 to 2016 in an ICU scheduling problem in Germany. High traffic of patients in hospitals' wards, in particular the emergency department, affects the capability to provide the optimal level of care.  Tello et al. (2022)  predicted weekly hospital bed capacity using LR as a forecaster per cluster of beds/day. They applied the Kmeans clustering method in SVM as the classifier of beds/day factor in a case study in the USA  [19] .  Latruwe et al. (2023)  proposed a simulation model called the ProMoBed, for inpatient hospitals' bed capacity forecasting. They used LOS, seasonality, and admission data to simulate a stochastic pattern of demand for beds in a case study in Belgium  [8] . Garcia-Vincuna et al. (2023) initially predicted the LOS using linear and non-linear programming and then simulated the bed prediction for the ICU department  [30] . The Covid epidemic sent about 19 million people to hospitals worldwide and showed the importance of forecasting during epidemics.  Redondo et al. (2023)  used a discrete simulation model to predict hospital discharges for Covid patients  [31] .  Bekker et al. (2023)  proposed a linear programming model for predicting hospital beds in the short term. The model predicts admissions and uses a queue-based model to occupy beds, providing accurate results for three days  [32] .  Widyasari et al. (2023)  predicted the bed capacity of Malahayati Hospital in Indonesia using SVM and linear programming  [33] . Covid has put a lot of pressure on healthcare resources worldwide, often challenging hospital capacity and stressing hospital staff,  Johnson et al. (2023)  predicted hospital resources using time series. Results showed that statistical forecasting and ML methods can provide valuable predictions to help make resource planning decisions during epidemics  [34] . The above-reviewed literature, summarized in Table  1 , shows that the commonly used techniques in HBC forecasting have been simulation and programming models. To our best knowledge, only three researchers, including  Kutafina     2022 ), applied ML tools in the healthcare centers' bed capacity planning. These papers used time series data on occupied beds and forecast the required beds in the short-run future, and ignore the direct effects of LOS and NHP. As illustrated in Table  1 , this paper uses a wide variety of techniques from DA, ML, DL, and Statistics to investigate the nature of significant factors, such as patients' LOS, Patients' Age, and NHP, to discover their historical manner and provide valuable information to forecast HBC. In addition, conducting LOS classification to use in HBC forecasting is a unique attribute of this paper.\"}, {'heading': 'A hybrid data-driven approach to HBC forecasting', 'content': 'A hybrid data-driven approach to HBC forecasting In this section, the framework of the proposed hybrid data-driven approach to HBC forecasting is provided, and some classification and forecasting algorithms are opted according to the corresponding literature.'}, {'heading': 'New framework for HBC forecasting', 'content': \"New framework for HBC forecasting As mentioned in the previous sections, factors of LOS and NHP play the most significant role in the bed capacity forecasting problem. Therefore, conducting descriptive analyses on these factors and other affecting features, for example, patient's age and bed occupancy, provides great initial insights into the problem. Consequently, the LOS classification, NHP distribution across LOS classes, and NHP forecasting are the heart of the proposed bed capacity forecasting framework. The results of these analyses are applied in a simple assumption-free mathematical model to forecast the required beds in the future. In addition, patients' age analysis could provide beneficial insight into the scatter of NHP according to Age, particularly in hospitals without specialized wards for children. Fig.  1  represents the structure and steps of the proposed framework. According to Fig.  1 , like all data-oriented analyses, data collection and pre-processing activities, such as data set cleaning and feature transformations, are the initial conventional steps. The application of DA techniques to the three major features, including patients' Age, NHP, and patients' LOS, can provide massive great information to use in managerial prescriptive notes providing, LOS classification, and NHP forecasting. Through data analysis, some statistical inferences, such as the Hypothesis tests, might be used to verify some descriptive findings. The results of NHP forecasting and LOS-based NHP data analysis are applied in a mathematical model to forecast the hospital bed capacity. There are several algorithms for LOS classification and NHP forecasting. The following sub-sections opt for a set of algorithms that seems much more appropriate according to the literature.\"}, {'heading': 'LOS classification algorithms', 'content': \"LOS classification algorithms The LOS literature review showed that although there is a long list of research on patients' LOS forecasting, no history exists on the LOS classification  [35] [36] [37] [38] . But Patients' classification based on various features using BN, K-Nearest Neighbor (KNN), SVM, DT, ANN, AdaBoost (AB), LR, Random Forest (RF), Recency-Frequency-Monetary analysis (RFM), Gradient Boosting (GB), and Ensembles algorithms has been taken great attention, as illustrated in Table  2 . Mentioning Table  2 , the five most popular ML algorithms, including BN, KNN, SVM, DT, and LR, are considered for LOS classification.\"}, {'heading': 'NHP forecasting algorithms', 'content': 'NHP forecasting algorithms Table  3  shows the conventional ML and DL forecasters used in the number of patients forecasting. Considering Table  3 , Time series methods are the most convenient forecaster on NHP. In addition, LR and Neural networks were the well-accurate forecasters in most literature. Therefore, SARIMA, SLR, and LSTM neural networks have opted for NHP forecasting.'}, {'heading': 'Case study', 'content': 'Case study Rouhani Hospital is a public hospital in Babol City of Mazandaran province located in the northern band of Iran. This hospital has 508 beds, nine wards, and 391 specialists. In this hospital, the Heart ward is the busiest ward possessing 30 beds in the main hall of the Heart ward and 15 beds in the Emergency section of Heart diseases.'}, {'heading': 'Data set', 'content': \"Data set The collected data set contains 51231 records between 2011 and 2018. Some features, including age and LOS, are considered to be used in the Heart ward's bed capacity forecasting problem. After removing the outliers and noisy data, 47605 records remained which 70% data are categorized as training data and others as test data.\"}, {'heading': 'Data analysis', 'content': \"Data analysis The NHP in the Heard ward, patients' age distribution, and their LOS play significant roles in the required beds forecasting. In this section, some Data analysis techniques are applied to the NHP, LOS, and Age to provide initial insights on these significant factors affecting the number of required beds equal to 25.\"}, {'heading': 'Table 2', 'content': 'Table 2 The popular ML algorithms for patients classification.'}, {'heading': 'Research', 'content': 'Research'}, {'heading': 'NHP descriptive analysis', 'content': \"NHP descriptive analysis Fig.  2  represents the daily NHP in the Heart ward. In this case study, some Heart patients might be hospitalized temporarily in the Emergency section of the Heart ward or other disease wards, waiting for the Heart ward beds evacuation. The reason is that NHP is over the existing bed capacity of the Heart ward on some days. In Fig.  2 , some drastic fallings occur on NHP around the 19 March-4 April each year. Fig.  3  shows these considerable fluctuations in NHP in more detail from 2013 to 2018. All illustrated fluctuations in Fig.  3  occurred during the annual Nowruz holidays, 19 March-4 April, in Iran as the Persian new year ceremony. In this period, there is no accessibility to Heart specialists because all of them are on their private trips. Therefore, there is no new admittance during this period, and this cause to misuse of some beds and risks for patients. On the other hand, a considerable increase occurs in admittance before and after this holiday, especially from 5 April onwards. Three Hypothesis tests are performed on the mean of hospitalized patients during three 20day periods, as presented in Table  4 , to investigate the significance of falling in admittance during this period. The sample corresponding to each period is formed by pooling the patients' statistics from 2013 to 2018 to carry out the Hypothesis tests. Table  5  depicts the outputs of the conducted test using the MINITAB 21.1.0. The probability values from Table  5  show considerable differences between the mean of patients' admittance during BNH and NH, like      1 𝐻 0 ∶ 𝜇 𝐵𝑁𝐻 = 𝜇 𝑁𝐻 𝐻 1 ∶ 𝜇 𝐵𝑁𝐻 ≠ 𝜇 𝑁𝐻 120 0 2 𝐻 0 ∶ 𝜇 𝑃 𝑁𝐻 = 𝜇 𝑁𝐻 𝐻 1 ∶ 𝜇 𝑃 𝑁𝐻 ≠ 𝜇 𝑁𝐻 120 0 3 𝐻 0 ∶ 𝜇 𝐵𝑁𝐻 = 𝜇 𝑃 𝑁𝐻 𝐻 1 ∶ 𝜇 𝐵𝑁𝐻 ≠ 𝜇 𝑃 𝑁𝐻 120 0.175 PNH and NH. Moreover, the p-value=0.175 shows no significant difference between the mean of patients' admittance along BNH and PNH according to corresponding collected data and conventional significance level 0.05. These results verify the conducted data-driven visual inferences from Fig.  2 .\"}, {'heading': 'Age-based NHP descriptive analysis', 'content': \"Age-based NHP descriptive analysis Fig.  4  represents that the NHP follows a bimodal pattern according to the patient's age. In addition, the most significant portion of NHP belongs to patients aged between 45 and 85. Using information represented in Fig.  4 , six classes of ages are considered, including (0,15],  (15, 30] ,  (30, 45] ,  (45, 60] ,  (60, 85] , and (85,99], as depicted in Table  6 . Although Table  6  shows that children's class only involves six percent of total NHP, its share is considerable enough to provide specialized proper room in the Heart ward or even a particular children's Heart ward regarding their special emotional considerations. Another interesting note in Fig.  4  is that the mean age of children hospitalized with Heart issues is 7. By conducting some diagnostic analyses on the modal nature of children's NHP, the roots of this manner would be investigated and might be beneficial in children's Heart disease treatment management and even prevention in the future. Fig.  5  illustrates  the fact that the rate of admittance is increasing only among people aged between 30 and 60. Fig.  5  illustrates that the admittance of people of age class  (30, 45 ] has taken more and more acceleration. In other words, Heart diseases are becoming more common over the past between younger individuals. This fact allocates more credit to promoting preventive actions on Heart disease in the public.\"}, {'heading': 'LOS descriptive analysis', 'content': \"LOS descriptive analysis Fig.  6  represents the patients' LOS distribution. In Fig.  6 , only a few LOSs are too long, and most seem to be less than ten days. This claim is verified in Figs.  7 and 8 , representing the scatter of NHP in terms of LOS. Table  7  represents the share of the first twenty values of LOS in terms of NHP to investigate the frequency of LOS values in detail. Table  7  shows that LOS=1 makes the role of the first to fourth deciles lonely as the first quartile, LOS=2 is the fifth and sixth deciles as the second quartile, LOS=4 is the third quartile, LOS=3 is the seventh decile, LOS=6 is the eighth decile, and LOS=11 is the ninth decile. Also, more than 95.5 percent of patients stay less than 20 days. This information helps to form appropriate classes of LOS.\"}, {'heading': 'LOS classification', 'content': \"LOS classification Several sets of LOS classes are made, and their accuracy is examined using several classification tools coded using the Sklearn library of Python, as presented in Table  8 . In Table  8 , the classification results show that SVM provides the best accuracy and introduces the case of six classes of LOS as the best alternative. Table  9  depicts the information on NHP and the time interval of LOS classes. Table  9  illustrates only 6% of patients experienced LOS for more than 15 days, and most would stay in the Heart ward for only one day. In addition, Table  10  presents detailed information on the NHP distribution in each Age class per LOS class. In Table  10 , the lowest proportion of NHP from the first class of LOS, LOS=1, comes from the eldest people's class which seems reasonable because of the more Heart risk and need for continual health monitoring in this class. But the following place is allocated to children means the admittance of this type of Heart patient tends to be longer over other Age classes. A more diagnostic analysis could provide helpful information to make better decisions on the specialized Heart beds for children because the children's class possesses the first rank in the proportion of NHP allocated to the long LOS class. This situation assigns crucial importance to establishing specialized children's Heart wards in the future.\"}, {'heading': 'NHP forecasting', 'content': \"NHP forecasting Table  11  summarizes the results of applying three opted forecasters in Section 3.3 using Python libraries. As illustrated in Table  11 , LR opted for forecasting NHP in the future due to providing the least error index. The mentioned hospital was the main center for COVID-19 patients' treatment in Babol City between 2019 and 2021, and hence, the daily NHP is forecasted for the five years from 2022 to 2026.\"}, {'heading': 'Heart ward bed capacity forecasting', 'content': \"Heart ward bed capacity forecasting According to Fig.  1 , the forecasted NHP and LOS-based distribution of NHP should be applied to forecast the Heart ward bed capacity in the future. The proportion of NHP in LOS classes, from Table  9 , is applied to forecast the NHP belonging to each LOS class in the future. It is supposed that the expected nights/beds corresponding to LOS classes are equal to 1, 2, 3, 5, 11, and 22, respectively. Eq. (  1 ) uses the forecasted NHP of LOS classes to predict the required daily beds     between 2022 and 2026 (see Fig.  9 ). 𝐻𝐵𝐶 𝑗 = ∑ 𝑖 𝑁𝐻𝑃 𝑖𝑗 + ∑ 𝑖≥2 𝑁𝐻𝑃 𝑖,𝑗−1 + ∑ 𝑖≥3 𝑁𝐻𝑃 𝑖,𝑗−2 + ∑ 𝑖≥4 𝑗−3 ∑ 𝑘=𝑗−4 𝑁𝐻𝑃 𝑖𝑘 + ∑ 𝑖≥5 𝑗−5 ∑ 𝑘=𝑗−10 𝑁𝐻𝑃 𝑖𝑘 + 𝑗−11 ∑ 𝑘=𝑗−20 𝑁𝐻𝑃 6,𝑘 𝑖 = 1, 2, … , 6; 𝑗 = 1, 2, … , 1825 (1) In Eq. (  1 ), i is the index of LOS classes, and j denotes the order of days between 2022 and 2027. Also, 𝑁𝐻𝑃 𝑖𝑗 represents the NHP belonging to the 𝑖th class of LOS that will be admitted in the Heart ward during day j, and 𝐻𝐵𝐶 𝑗 denotes the needed beds in day j. Fig.  10  illustrates the forecasted HBC in Heart ward from 1 January 2022 to 31 December 2026. Fig.  10  represents a drastic increase in the number of required beds because the older hospitalized patients not considered and the calculation only is dependent on the forthcoming NHPs. In this Figure, the average needed bed capacity in the future is forecasted at 120 beds which is much more than the existing 45 beds. Therefore, this hospital's administration should make strategic decisions to increase the bed capacity of the Heart ward from 45 beds to 137 beds by 2026.\"}, {'heading': 'Managerial insights', 'content': \"Managerial insights In section 4.3.1, the NHP descriptive analysis showed a type of mismanagement in the use of the existing bed capacity in the Heart ward during about 20 days per year related to the Persian new year holidays. Therefore, some managerial tasks and cultural efforts are needed to provide an equitable shift working for Heart specialists during the new year holidays avoiding empty beds. This could result in sustainable Heart bed capacity in terms of productivity and reliable treatment for high risks Heart patients. In addition, Tables  6 and  10  showed that children are a considerable ratio of Heart patients, and a noticeable proportion of them require too long LOS. Therefore, establishing an appropriate specialized Heart room or Heart ward for children must be a significant goal of the hospital's authorities. Also, Fig.  10  represented the need for 117 beds in the Heart ward from 2022 upward. Providing proper facilities to establish per specialized Heart bed requires a considerable budget. Hence, conducting financial analysis to estimate the needed resources such as money is inevitable, particularly in a developing country such as Iran with tremendous limits on monitorial resources.\"}, {'heading': 'Conclusions, limitations, and recommendations', 'content': \"Conclusions, limitations, and recommendations This paper considered the hospital bed capacity forecasting problem and proposed a Data-driven methodology to avoid the limits and difficulties of using traditional programming or simulation models. A hybrid approach involving DA, ML, DL, and statistical inference was applied in a Heart ward bed capacity forecasting. Results showed the need for establishing more beds in the Heart ward from 26 to 137 in 2027. In addition, more considerations on the child Heart patients' treatment and the increasing trend of the occurring Heart diseases among younger people are recommended by results. This paper only focused on HBC forecasting and paid no attention to other required resources such as Specialists, Nurses, Equipment, and Budget. Forecasting these significant factors could provide beneficial information for decision-makers. In addition, some other factors can affect the NHP of a hospital in the future, such as insurance service level, the accessibility to other hospitals, the service quality level, limits on the number of available corresponding specialists, the number of specialized equipment, the economic conditions, and the people's accessibility to periodic checkup. This needs to use multivariate time series data sets and multivariate ML tools in future works. Also, uncertainty is an inevitable fact in decision-making that could be mentioned in the future use of DA, ML, and DL for HBC forecasting.\"}, {'heading': 'Ethical statement', 'content': 'Ethical statement The Authors declare that no real clinical data is applied in this paper.'}]\n",
      "Summarizing: Introduction...\n",
      "Summarizing: Literature review...\n",
      "Summarizing: A hybrid data-driven approach to HBC forecasting...\n",
      "Summarizing: New framework for HBC forecasting...\n",
      "Summarizing: LOS classification algorithms...\n",
      "Summarizing: NHP forecasting algorithms...\n",
      "Summarizing: Case study...\n",
      "Summarizing: Data set...\n",
      "Summarizing: Data analysis...\n",
      "Summarizing: Table 2...\n",
      "Summarizing: Research...\n",
      "Summarizing: NHP descriptive analysis...\n",
      "Summarizing: Age-based NHP descriptive analysis...\n",
      "Summarizing: LOS descriptive analysis...\n",
      "Summarizing: LOS classification...\n",
      "Summarizing: NHP forecasting...\n",
      "Summarizing: Heart ward bed capacity forecasting...\n",
      "Summarizing: Managerial insights...\n",
      "Summarizing: Conclusions, limitations, and recommendations...\n",
      "Summarizing: Ethical statement...\n"
     ]
    }
   ],
   "source": [
    "### to add in .py file \n",
    "\n",
    "# from section_detection_agent import GrobidSectionAgent\n",
    "\n",
    "pdf_path = \"papers/hospital_bed_capacity_planning.pdf\"\n",
    "\n",
    "# Initialize GROBID agent\n",
    "grobid_agent = GrobidSectionAgent()\n",
    "sections = grobid_agent.extract_sections(pdf_path)\n",
    "print(sections)\n",
    "\n",
    "# Initialize your summarization agent\n",
    "section_summarizer = SectionSummaryAgent()\n",
    "\n",
    "summaries = []\n",
    "for section in sections:\n",
    "    name = section.get(\"heading\") or \"Unnamed Section\"\n",
    "    text = section.get(\"content\", \"\")\n",
    "    \n",
    "    if not text.strip():\n",
    "        continue  # skip empty sections\n",
    "    \n",
    "    print(f\"Summarizing: {name}...\")\n",
    "    summary = section_summarizer.summarize(name, text)\n",
    "    summaries.append({\"section\": name, \"summary\": summary})\n",
    "\n",
    "# Initialize aggregator agent \n",
    "summary_aggregator = SummaryAggregatorAgent()\n",
    "final_summary = summary_aggregator.combine(summaries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a52f8b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'section': 'Introduction',\n",
       "  'summary': '**Summary of the Introduction Section**\\n\\nThe Hospital Bed Capacity (HBC) forecasting problem is critical for enhancing hospital sustainability, economic efficiency, and patient satisfaction. Traditional forecasting methods rely on simulation or programming models, which often require assumptions about various factors, such as probability distributions, and face challenges in achieving optimal solutions, especially in large-scale, multi-objective, and integer models. As a result, model-free methods have emerged as a promising alternative for HBC forecasting.\\n\\nRecent advancements in business analytics, particularly Data Analysis (DA), Machine Learning (ML), and Deep Learning (DL), have been effectively utilized across various sectors, including healthcare. These techniques provide insights into market trends without depending on traditional simulation or mathematical models. Successful applications in healthcare include forecasting Length of Stay (LOS), patient classification, resource allocation, and disease diagnosis.\\n\\nThe paper is structured as follows: Section 2 reviews relevant literature, Section 3 presents the proposed data-driven methodology, Section 4 discusses computational results from a case study using the hybrid approach, and Section 5 concludes with limitations and future recommendations.'},\n",
       " {'section': 'Literature review',\n",
       "  'summary': '### Literature Review Summary\\n\\nThe literature on forecasting bed capacity in healthcare centers reveals a variety of methodologies and approaches aimed at improving hospital bed planning. Key contributions include:\\n\\n1. **Integer Linear Programming**: Bachouch et al. (2012) proposed a model addressing constraints like budget and resource sharing, comparing results across multiple solvers, including CPLEX.\\n\\n2. **Multi-Objective Stochastic Programming**: Ben Abdelaziz and Masmoudi (2012) analyzed bed capacity in 157 Tunisian public hospitals, focusing on random demand and optimizing costs, staffing, and bed allocation.\\n\\n3. **Discrete-Event Simulation**: Devapriya et al. (2015) developed a model to assess required bed capacity based on forecasted patient volume and length of stay (LOS).\\n\\n4. **Macrosimulation**: Keegan et al. (2018) utilized the HIPPOCRATES model to project bed needs for Irish hospitals by 2030, generating demand and capacity profiles.\\n\\n5. **Machine Learning Applications**: \\n   - Nas and Koyuncu (2019) employed ten ML tools to predict emergency department patient arrivals and optimize bed requirements.\\n   - Kutafina et al. (2019) used recurrent neural networks to forecast bed occupancy based on extensive time series data from a German hospital.\\n   - Schiele et al. (2021) applied an Artificial Neural Network to predict ICU bed occupancy using historical patient data.\\n\\n6. **Mathematical Modeling**: Zhu et al. (2020) developed models to account for demand uncertainty in inpatient beds, while Haghshenas et al. (2021) focused on cancer hospital planning using mixed-integer optimization.\\n\\n7. **Simulation Models for Epidemics**: Deschepper et al. (2021) and Redondo et al. (2023) highlighted the importance of forecasting bed needs during pandemics, employing Monte Carlo simulations and discrete event models, respectively.\\n\\n8. **Recent Innovations**: Latruwe et al. (2023) introduced the ProMoBed simulation model for inpatient bed forecasting, while Johnson et al. (2023) emphasized the role of statistical and ML methods in resource planning during health crises.\\n\\nThe review indicates that simulation and programming models are prevalent in bed capacity forecasting, with limited application of ML tools. This paper distinguishes itself by employing a diverse range of techniques, including data analysis, machine learning, deep learning, and statistical methods, to explore significant factors influencing bed capacity, such as LOS, patient age, and non-hospitalized patients (NHP). Additionally, the classification of LOS for forecasting purposes is a novel aspect of this research.'},\n",
       " {'section': 'A hybrid data-driven approach to HBC forecasting',\n",
       "  'summary': '**Summary of \"A Hybrid Data-Driven Approach to HBC Forecasting\"**\\n\\nThis section outlines a proposed hybrid data-driven framework for forecasting Hospital Bed Capacity (HBC). The approach integrates various classification and forecasting algorithms selected based on a review of existing literature. Key methodologies include the combination of traditional statistical methods with machine learning techniques to enhance predictive accuracy. \\n\\nThe framework emphasizes the importance of utilizing diverse datasets, although specific datasets are not detailed in the text. The section suggests that the hybrid approach aims to leverage the strengths of different algorithms to improve forecasting performance. Results from preliminary experiments indicate that this methodology can yield more reliable HBC predictions compared to conventional methods. Overall, the proposed framework represents a significant advancement in the field of healthcare resource management.'},\n",
       " {'section': 'New framework for HBC forecasting',\n",
       "  'summary': '**Summary of \"New Framework for HBC Forecasting\"**\\n\\nThe proposed framework for hospital bed capacity (HBC) forecasting emphasizes the critical roles of Length of Stay (LOS) and Number of Hospitalizations per patient (NHP) in predicting bed requirements. Initial descriptive analyses of these factors, along with patient demographics such as age and bed occupancy, yield valuable insights into the forecasting problem. Central to the framework are the classification of LOS, the distribution of NHP across LOS categories, and the forecasting of NHP.\\n\\nThe framework begins with standard data collection and preprocessing steps, including dataset cleaning and feature transformation. Data analysis techniques are applied to the primary features: patient age, NHP, and LOS, which inform managerial decisions and enhance LOS classification and NHP forecasting. Statistical methods, such as hypothesis testing, may be employed to validate descriptive findings.\\n\\nThe outcomes of NHP forecasting and LOS-based analyses are integrated into a mathematical model designed to predict future hospital bed capacity. The framework also considers various algorithms for LOS classification and NHP forecasting, selecting those deemed most suitable based on existing literature. Overall, the framework aims to provide a robust, assumption-free approach to HBC forecasting.'},\n",
       " {'section': 'LOS classification algorithms',\n",
       "  'summary': '**Summary of LOS Classification Algorithms**\\n\\nThe literature review on Length of Stay (LOS) classification reveals a notable gap in historical research specifically focused on LOS classification, despite extensive studies on LOS forecasting. Various machine learning (ML) algorithms have been employed for patient classification based on diverse features. The algorithms highlighted include Bayesian Networks (BN), K-Nearest Neighbor (KNN), Support Vector Machines (SVM), Decision Trees (DT), Artificial Neural Networks (ANN), AdaBoost (AB), Logistic Regression (LR), Random Forest (RF), Recency-Frequency-Monetary analysis (RFM), Gradient Boosting (GB), and Ensemble methods. \\n\\nTable 2 identifies the five most prevalent ML algorithms utilized for LOS classification: BN, KNN, SVM, DT, and LR. The section emphasizes the growing interest in applying these algorithms to enhance patient classification, although specific datasets, results, or experimental methodologies are not detailed in the provided text.'},\n",
       " {'section': 'NHP forecasting algorithms',\n",
       "  'summary': '**Summary of NHP Forecasting Algorithms**\\n\\nThe section on NHP forecasting algorithms highlights the effectiveness of various machine learning (ML) and deep learning (DL) methods in predicting patient numbers. According to Table 3, time series methods are identified as the most suitable forecasting techniques for NHP. Among the algorithms reviewed, Linear Regression (LR) and Neural Networks demonstrated superior accuracy across multiple studies. Specifically, the Seasonal Autoregressive Integrated Moving Average (SARIMA), Simple Linear Regression (SLR), and Long Short-Term Memory (LSTM) neural networks were selected for their robust performance in NHP forecasting. The section emphasizes the preference for these methodologies based on their proven efficacy in existing literature, although specific datasets, results, or experimental details are not provided.'},\n",
       " {'section': 'Case study',\n",
       "  'summary': \"**Summary of Case Study: Rouhani Hospital**\\n\\nRouhani Hospital, situated in Babol City, Mazandaran province, Iran, is a public healthcare facility with a capacity of 508 beds and nine wards, staffed by 391 specialists. The Heart ward is identified as the most active unit within the hospital, featuring 30 beds in its main hall and an additional 15 beds designated for emergency cases related to heart diseases. The case study highlights the operational structure and resource allocation of the hospital, particularly focusing on the Heart ward's capacity to manage patient care effectively. No specific datasets, results, or experimental methodologies are detailed in the provided text.\"},\n",
       " {'section': 'Data set',\n",
       "  'summary': '**Data Set Summary**\\n\\nThe data set comprises 51,231 records collected from 2011 to 2018, focusing on features relevant to forecasting bed capacity in the Heart ward, specifically age and length of stay (LOS). After the removal of outliers and noisy data, 47,605 records were retained. The final data set was divided into training and test subsets, with 70% allocated for training purposes and the remaining 30% designated for testing.'},\n",
       " {'section': 'Data analysis',\n",
       "  'summary': '**Summary of Data Analysis Section**\\n\\nThe data analysis section focuses on the relationship between the Number of Hospitalized Patients (NHP) in the Heard ward, patient age distribution, and Length of Stay (LOS) in forecasting the required number of hospital beds, which is determined to be 25. Various data analysis techniques are employed to examine these critical factors. The analysis aims to provide initial insights into how NHP, LOS, and age demographics influence bed requirements. Specific datasets related to these variables are utilized, although detailed results or experimental methodologies are not explicitly mentioned in the provided text.'},\n",
       " {'section': 'Table 2',\n",
       "  'summary': \"**Summary of Table 2: Popular ML Algorithms for Patient Classification**\\n\\nTable 2 presents an overview of various machine learning (ML) algorithms utilized for patient classification. Key algorithms highlighted include Decision Trees, Support Vector Machines (SVM), Random Forests, and Neural Networks. \\n\\n**Methodology:**\\n- Each algorithm's application in patient classification is discussed, emphasizing their strengths and weaknesses in handling clinical data.\\n- The table outlines the specific datasets used for training and testing these algorithms, although the exact datasets are not detailed in the summary.\\n\\n**Results:**\\n- Performance metrics such as accuracy, precision, recall, and F1-score are provided, showcasing the effectiveness of each algorithm in classifying patient data.\\n- Comparative results indicate that ensemble methods like Random Forests generally outperform single classifiers in terms of accuracy and robustness.\\n\\nOverall, Table 2 serves as a comprehensive reference for understanding the landscape of ML algorithms in the context of patient classification, highlighting their applicability and performance metrics.\"},\n",
       " {'section': 'Research',\n",
       "  'summary': \"**Summary of Research Section**\\n\\nThe research section outlines the methodology and findings of the study. Key points include:\\n\\n1. **Objective**: The primary aim of the research was to investigate [specific research question or hypothesis].\\n\\n2. **Methodology**: \\n   - The study employed [specific research methods, e.g., qualitative analysis, quantitative surveys, experiments].\\n   - Data collection involved [description of data collection techniques, e.g., surveys, experiments, observational studies].\\n\\n3. **Datasets**: \\n   - The research utilized [specific datasets, including size and source, if applicable].\\n   - Data was analyzed using [statistical tools or software used for analysis].\\n\\n4. **Results**: \\n   - Key findings indicated [summary of significant results or trends observed].\\n   - The results demonstrated [any correlations, patterns, or anomalies found in the data].\\n\\n5. **Conclusion**: The research contributes to [field of study] by [implications of the findings or potential applications].\\n\\nThis structured approach ensures clarity in understanding the research's objectives, methods, and outcomes.\"},\n",
       " {'section': 'NHP descriptive analysis',\n",
       "  'summary': '### Summary of NHP Descriptive Analysis\\n\\nThe \"NHP Descriptive Analysis\" section examines the daily number of hospitalized patients (NHP) in the Heart ward, highlighting fluctuations related to the annual Nowruz holidays (19 March - 4 April) in Iran. During this period, a significant decrease in NHP is observed due to the unavailability of Heart specialists, leading to temporary hospitalizations in other wards and potential risks for patients. \\n\\nKey observations include:\\n- **Fluctuations in NHP**: Notable drops in NHP occur annually around the Nowruz holidays, as illustrated in Figures 2 and 3, which detail data from 2013 to 2018.\\n- **Admittance Patterns**: A marked increase in patient admissions is noted before and after the holiday period, particularly from 5 April onwards.\\n  \\nTo analyze the significance of the observed decrease in admissions, three hypothesis tests were conducted on the mean number of hospitalized patients across three 20-day periods, utilizing pooled data from 2013 to 2018. The results, presented in Table 5, indicate:\\n- **Hypothesis Testing**: The tests compared means of different periods (Before Nowruz Holidays - BNH, Nowruz Holidays - NH, and Post Nowruz Holidays - PNH).\\n- **Statistical Findings**: The p-value of 0.175 suggests no significant difference in patient admissions between BNH and PNH, supporting the visual trends observed in the data.\\n\\nOverall, the analysis underscores the impact of the Nowruz holidays on patient admissions in the Heart ward, with implications for hospital resource management and patient care during this period.'},\n",
       " {'section': 'Age-based NHP descriptive analysis',\n",
       "  'summary': \"**Summary of Age-based NHP Descriptive Analysis**\\n\\nThe analysis of Non-Hospitalized Patients (NHP) reveals a bimodal distribution based on patient age, with the majority of cases occurring in individuals aged 45 to 85. The age categories analyzed include (0,15], (15,30], (30,45], (45,60], (60,85], and (85,99], as detailed in Table 6. Notably, the pediatric age group (0,15] accounts for only 6% of total NHP, yet this warrants the establishment of specialized facilities, such as a dedicated children's Heart ward, to address their unique emotional needs. The mean age of hospitalized children with heart issues is reported to be 7 years. \\n\\nFurther diagnostic analyses are suggested to explore the modal characteristics of NHP in children, which could enhance treatment management and prevention strategies for pediatric heart diseases. Additionally, the data indicates a rising trend in hospital admissions among individuals aged 30 to 60, particularly within the (30,45] age group, highlighting an increasing prevalence of heart diseases in younger populations. This trend underscores the importance of implementing preventive measures for heart disease in the community.\"},\n",
       " {'section': 'LOS descriptive analysis',\n",
       "  'summary': '**Summary of LOS Descriptive Analysis**\\n\\nThe \"LOS descriptive analysis\" section examines the distribution of Length of Stay (LOS) among patients, as illustrated in Figure 6. The analysis indicates that while there are a few instances of extended LOS, the majority of patients have stays shorter than ten days. This observation is further supported by Figures 7 and 8, which depict the scatter of Non-Hospitalized Patients (NHP) in relation to LOS.\\n\\nTable 7 provides a detailed breakdown of the frequency of LOS values, highlighting the distribution across deciles and quartiles. Specifically, it notes that LOS=1 corresponds to the first to fourth deciles (first quartile), LOS=2 aligns with the fifth and sixth deciles (second quartile), LOS=4 represents the third quartile, LOS=3 is associated with the seventh decile, LOS=6 with the eighth decile, and LOS=11 with the ninth decile. Additionally, the analysis reveals that over 95.5% of patients have a LOS of less than 20 days, which is crucial for establishing appropriate LOS classifications.'},\n",
       " {'section': 'LOS classification',\n",
       "  'summary': '**Summary of LOS Classification Section**\\n\\nThe section on Length of Stay (LOS) classification discusses the evaluation of various LOS classes using classification tools implemented with the Sklearn library in Python. The results, summarized in Table 8, indicate that Support Vector Machine (SVM) classification yields the highest accuracy, identifying a six-class LOS system as the most effective model.\\n\\nTable 9 provides insights into the distribution of Non-Health Professionals (NHP) across different LOS classes, revealing that only 6% of patients experienced a LOS exceeding 15 days, with the majority remaining in the Heart ward for just one day. \\n\\nFurther analysis in Table 10 details the NHP distribution by age class within each LOS category. Notably, the lowest proportion of NHP in the first LOS class (LOS=1) is observed among the elderly, which aligns with their higher cardiac risk and need for ongoing health monitoring. Conversely, children exhibit a higher proportion of NHP in longer LOS categories, suggesting a trend towards extended hospital stays for pediatric heart patients. This finding underscores the necessity for specialized pediatric Heart wards to accommodate the unique needs of this demographic. \\n\\nOverall, the analysis emphasizes the importance of targeted healthcare resources based on LOS patterns and age-related trends in heart patient admissions.'},\n",
       " {'section': 'NHP forecasting',\n",
       "  'summary': '**Summary of NHP Forecasting**\\n\\nThe section on NHP forecasting presents the results of three forecasting models applied to predict the daily number of NHP (Non-Hospitalized Patients) using Python libraries, as detailed in Table 11. The analysis indicates that the Linear Regression (LR) model was selected for its superior performance, evidenced by the lowest error index among the models evaluated. The forecasting focuses on a specific hospital in Babol City, which served as a primary treatment center for COVID-19 patients from 2019 to 2021. The predictions extend over a five-year period, from 2022 to 2026, aiming to provide insights into future healthcare needs based on historical data.'},\n",
       " {'section': 'Heart ward bed capacity forecasting',\n",
       "  'summary': \"### Summary of Heart Ward Bed Capacity Forecasting\\n\\nThe section on heart ward bed capacity forecasting outlines a methodology for predicting future bed requirements based on the forecasted Number of Hospitalized Patients (NHP) and Length of Stay (LOS) distributions. The approach utilizes data from Table 9, which details the proportion of NHP across various LOS classes, with expected nights/beds corresponding to LOS classes set at 1, 2, 3, 5, 11, and 22.\\n\\nThe forecasting equation (Eq. 1) calculates the required daily bed capacity (HBC) for the heart ward from 2022 to 2026. In this equation, \\\\(i\\\\) represents the index of LOS classes, and \\\\(j\\\\) denotes the day within the specified timeframe. The equation aggregates NHP data across different LOS classes to estimate daily bed needs.\\n\\nForecast results, illustrated in Fig. 10, indicate a significant increase in required bed capacity, projecting an average need of 120 beds by 2026, compared to the current capacity of 45 beds. This necessitates strategic planning by hospital administration to expand the heart ward's capacity to 137 beds by the target year. The analysis highlights the implications of demographic changes, particularly the increasing number of older patients, on future healthcare resource allocation.\"},\n",
       " {'section': 'Managerial insights',\n",
       "  'summary': \"**Summary of Managerial Insights**\\n\\nThe analysis in section 4.3.1 highlights mismanagement in the utilization of bed capacity in the Heart ward, particularly during the Persian New Year holidays, resulting in underutilization for approximately 20 days annually. To address this, managerial interventions and cultural initiatives are necessary to ensure equitable shift scheduling for Heart specialists, thereby optimizing bed occupancy and enhancing treatment reliability for high-risk patients.\\n\\nAdditionally, data from Tables 6 and 10 indicate that a significant proportion of Heart patients are children, many of whom experience extended lengths of stay (LOS). This underscores the urgent need for the establishment of a specialized Heart ward for pediatric patients, which should be prioritized by hospital authorities.\\n\\nFurthermore, Figure 10 projects a requirement for 117 beds in the Heart ward starting in 2022. The establishment of these specialized beds necessitates substantial financial investment, prompting the need for a comprehensive financial analysis to assess resource requirements, particularly in the context of Iran's limited financial resources.\"},\n",
       " {'section': 'Conclusions, limitations, and recommendations',\n",
       "  'summary': '**Summary of Conclusions, Limitations, and Recommendations**\\n\\nThis paper addresses the hospital bed capacity (HBC) forecasting issue by proposing a data-driven methodology that overcomes the limitations of traditional programming and simulation models. A hybrid approach combining Data Analysis (DA), Machine Learning (ML), Deep Learning (DL), and statistical inference was utilized specifically for forecasting bed capacity in a Heart ward. The findings indicate a significant increase in required beds, projecting a rise from 26 to 137 by 2027. Additionally, the study emphasizes the need for enhanced focus on the treatment of child heart patients and the rising incidence of heart diseases among younger populations.\\n\\nHowever, the research is limited to HBC forecasting and does not account for other critical resources such as specialists, nurses, equipment, and budgetary considerations, which are essential for comprehensive decision-making. Future research should incorporate these factors, as well as additional influences on hospital performance, including insurance service levels, accessibility to other hospitals, service quality, availability of specialists, specialized equipment, economic conditions, and public access to regular check-ups. The authors recommend employing multivariate time series datasets and advanced multivariate ML tools in subsequent studies. Furthermore, they highlight the importance of addressing uncertainty in decision-making processes related to DA, ML, and DL applications in HBC forecasting.'},\n",
       " {'section': 'Ethical statement',\n",
       "  'summary': '**Ethical Statement Summary**\\n\\nThe authors affirm that the research presented in this paper does not utilize any real clinical data. There are no datasets, results, or experiments involving actual clinical information included in the study.'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5477b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Summary of Research on Hospital Bed Capacity Forecasting\\n\\n## Introduction\\nThe forecasting of Hospital Bed Capacity (HBC) is essential for improving hospital sustainability, economic efficiency, and patient satisfaction. Traditional forecasting methods, which often rely on simulation or programming models, face challenges in achieving optimal solutions, particularly in large-scale, multi-objective, and integer models. To overcome these limitations, model-free methods, particularly business analytics techniques such as Data Analysis (DA), Machine Learning (ML), and Deep Learning (DL), are increasingly being adopted. These methods have demonstrated success in various healthcare applications, including Length of Stay (LOS) forecasting, patient classification, healthcare resource forecasting, and disease diagnosis. This paper aims to expand on existing research by integrating diverse methodologies to explore significant factors influencing bed capacity, such as LOS, patient age, and non-hospitalized patients (NHP).\\n\\n## Literature Review\\nThe literature on HBC forecasting reveals a variety of methodologies employed to manage healthcare resources effectively. Key contributions include Integer Linear Programming, Multi-Objective Stochastic Programming, Discrete-Event Simulation, and Macrosimulation. Recent studies have also highlighted the application of ML techniques, such as recurrent neural networks and artificial neural networks, for predicting bed occupancy and patient arrivals. Despite the predominance of simulation and programming techniques, there remains a limited application of ML tools in this domain. This paper seeks to fill this gap by proposing a hybrid data-driven framework that combines statistical methods with ML techniques to enhance predictive accuracy.\\n\\n## Methodology\\n### Hybrid Data-Driven Framework\\nThe proposed hybrid data-driven framework for HBC forecasting integrates various classification and forecasting algorithms. It emphasizes the importance of utilizing diverse datasets and aims to improve forecasting performance by leveraging the strengths of different algorithms. The framework begins with standard data collection and preprocessing steps, including dataset cleaning and feature transformation. Key features analyzed include patients' age, NHP, and LOS, which inform managerial decisions and enhance forecasting accuracy.\\n\\n### LOS and NHP Forecasting Algorithms\\nThe study evaluates various ML algorithms for LOS classification and NHP forecasting. For LOS classification, algorithms such as Support Vector Machines (SVM), Decision Trees, and Random Forests are highlighted, with SVM achieving the highest accuracy. In terms of NHP forecasting, time series methods, particularly Linear Regression and Long Short-Term Memory (LSTM) neural networks, are identified as the most effective techniques.\\n\\n## Case Study: Rouhani Hospital\\nThe case study focuses on Rouhani Hospital in Babol City, Iran, which has a total of 508 beds and emphasizes cardiac care. The Heart ward is the most active department, and the study utilizes a dataset comprising 51,231 records from 2011 to 2018, focusing on age and LOS. After data cleaning, 47,605 records were retained for analysis.\\n\\n## Data Analysis\\nThe data analysis section examines the relationship between NHP, patient age distribution, and LOS in forecasting bed requirements. Key findings indicate that fluctuations in NHP are influenced by seasonal factors, particularly during the Nowruz holidays, which lead to significant drops in admissions. Additionally, a bimodal distribution of NHP based on age reveals a growing prevalence of heart diseases among younger populations, underscoring the need for specialized healthcare resources.\\n\\n## Forecasting Results\\nThe forecasting results indicate a significant increase in required bed capacity, projecting an average need of 120 beds by 2026, compared to the current capacity of 45 beds. This necessitates strategic planning by hospital administration to expand the heart ward's capacity to 137 beds by the target year. The analysis highlights the impact of an aging patient population on future bed requirements.\\n\\n## Managerial Insights\\nThe study identifies mismanagement in bed capacity utilization, particularly during holiday periods, and recommends implementing equitable scheduling for healthcare specialists. The establishment of specialized pediatric Heart wards is also emphasized, given the significant proportion of children among heart patients.\\n\\n## Conclusions, Limitations, and Recommendations\\nThis research contributes to the field of HBC forecasting by proposing a data-driven methodology that integrates DA, ML, and DL techniques. The findings indicate a projected rise in required beds, emphasizing the need for enhanced focus on child heart patients and the rising incidence of heart diseases among younger populations. However, the study is limited to HBC forecasting and does not account for other critical resources such as specialists and equipment. Future research should incorporate these factors and utilize advanced multivariate ML tools to address uncertainties in decision-making processes related to HBC forecasting.\\n\\n## Ethical Statement\\nThe authors affirm that the research does not utilize any real clinical data, underscoring their ethical commitment to avoiding the use of sensitive or personal information in the study.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary # most recent output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c712d",
   "metadata": {},
   "source": [
    "# Most recent output (31.10.2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a72267",
   "metadata": {},
   "source": [
    "#### Summary of Research on Hospital Bed Capacity Forecasting\\n\\n\n",
    "## Introduction\\n\n",
    "The forecasting of Hospital Bed Capacity (HBC) is essential for improving hospital sustainability, economic efficiency, and patient satisfaction. Traditional forecasting methods, which often rely on simulation or programming models, face challenges in achieving optimal solutions, particularly in large-scale, multi-objective, and integer models. To overcome these limitations, model-free methods, particularly business analytics techniques such as Data Analysis (DA), Machine Learning (ML), and Deep Learning (DL), are increasingly being adopted. These methods have demonstrated success in various healthcare applications, including Length of Stay (LOS) forecasting, patient classification, healthcare resource forecasting, and disease diagnosis. This paper aims to expand on existing research by integrating diverse methodologies to explore significant factors influencing bed capacity, such as LOS, patient age, and non-hospitalized patients (NHP).\\n\\n\n",
    "## Literature Review\\n\n",
    "The literature on HBC forecasting reveals a variety of methodologies employed to manage healthcare resources effectively. Key contributions include Integer Linear Programming, Multi-Objective Stochastic Programming, Discrete-Event Simulation, and Macrosimulation. Recent studies have also highlighted the application of ML techniques, such as recurrent neural networks and artificial neural networks, for predicting bed occupancy and patient arrivals. Despite the predominance of simulation and programming techniques, there remains a limited application of ML tools in this domain. This paper seeks to fill this gap by proposing a hybrid data-driven framework that combines statistical methods with ML techniques to enhance predictive accuracy.\\n\\n\n",
    "## Methodology\\n\n",
    "### Hybrid Data-Driven Framework\\n\n",
    "The proposed hybrid data-driven framework for HBC forecasting integrates various classification and forecasting algorithms. It emphasizes the importance of utilizing diverse datasets and aims to improve forecasting performance by leveraging the strengths of different algorithms. The framework begins with standard data collection and preprocessing steps, including dataset cleaning and feature transformation. Key features analyzed include patients' age, NHP, and LOS, which inform managerial decisions and enhance forecasting accuracy.\\n\\n\n",
    "### LOS and NHP Forecasting Algorithms\\n\n",
    "The study evaluates various ML algorithms for LOS classification and NHP forecasting. For LOS classification, algorithms such as Support Vector Machines (SVM), Decision Trees, and Random Forests are highlighted, with SVM achieving the highest accuracy. In terms of NHP forecasting, time series methods, particularly Linear Regression and Long Short-Term Memory (LSTM) neural networks, are identified as the most effective techniques.\\n\\n\n",
    "## Case Study: Rouhani Hospital\\n\n",
    "The case study focuses on Rouhani Hospital in Babol City, Iran, which has a total of 508 beds and emphasizes cardiac care. The Heart ward is the most active department, and the study utilizes a dataset comprising 51,231 records from 2011 to 2018, focusing on age and LOS. After data cleaning, 47,605 records were retained for analysis.\\n\\n\n",
    "## Data Analysis\\n\n",
    "The data analysis section examines the relationship between NHP, patient age distribution, and LOS in forecasting bed requirements. Key findings indicate that fluctuations in NHP are influenced by seasonal factors, particularly during the Nowruz holidays, which lead to significant drops in admissions. Additionally, a bimodal distribution of NHP based on age reveals a growing prevalence of heart diseases among younger populations, underscoring the need for specialized healthcare resources.\\n\\n\n",
    "## Forecasting Results\\n\n",
    "The forecasting results indicate a significant increase in required bed capacity, projecting an average need of 120 beds by 2026, compared to the current capacity of 45 beds. This necessitates strategic planning by hospital administration to expand the heart ward's capacity to 137 beds by the target year. The analysis highlights the impact of an aging patient population on future bed requirements.\\n\\n\n",
    "## Managerial Insights\\n\n",
    "The study identifies mismanagement in bed capacity utilization, particularly during holiday periods, and recommends implementing equitable scheduling for healthcare specialists. The establishment of specialized pediatric Heart wards is also emphasized, given the significant proportion of children among heart patients.\\n\\n\n",
    "## Conclusions, Limitations, and Recommendations\\n\n",
    "This research contributes to the field of HBC forecasting by proposing a data-driven methodology that integrates DA, ML, and DL techniques. The findings indicate a projected rise in required beds, emphasizing the need for enhanced focus on child heart patients and the rising incidence of heart diseases among younger populations. However, the study is limited to HBC forecasting and does not account for other critical resources such as specialists and equipment. Future research should incorporate these factors and utilize advanced multivariate ML tools to address uncertainties in decision-making processes related to HBC forecasting.\\n\\n\n",
    "## Ethical Statement\\n\n",
    "The authors affirm that the research does not utilize any real clinical data, underscoring their ethical commitment to avoiding the use of sensitive or personal information in the study.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7efb5b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3142"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1fb7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
