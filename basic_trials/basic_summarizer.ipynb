{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d16933a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (0.4)\n",
      "Requirement already satisfied: ipython in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (9.6.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain) (1.0.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain) (1.0.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.37)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (1.0.1)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain_community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain_community) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain_community) (3.13.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain_community) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain_community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain_community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from ipython) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from ipython) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from jedi>=0.16->ipython) (0.8.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.3.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from stack_data->ipython) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from stack_data->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from stack_data->ipython) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install PyPDF2 langchain langchain_community ipython "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bce84f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yue Ning\\Desktop\\MiscLearning\\ai_researcher_database\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from IPython.display import display, Markdown, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbff1ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yue Ning\\AppData\\Local\\Temp\\ipykernel_46204\\2364526073.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaLLM``.\n",
      "  model = Ollama(model=model_id)\n"
     ]
    }
   ],
   "source": [
    "model_id = \"llama3.1:latest\"\n",
    "model = Ollama(model=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6b75fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "212ffb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(input_text: str):\n",
    "    prompt_template = \"\"\"\n",
    "    You are an advanced research paper summarization mode. Summarize the following text: \n",
    "\n",
    "    {text}\n",
    "    \n",
    "    Provide a concise and informative summary using the following Markdown structure:\n",
    "\n",
    "        # Title  \n",
    "        # Authors  \n",
    "        # Problem Statement  \n",
    "        # Dataset  \n",
    "        - Description  \n",
    "        - Source  \n",
    "        - Size  \n",
    "        - Preprocessing  \n",
    "\n",
    "        # Models and Methods  \n",
    "        For each model:  \n",
    "        - Name  \n",
    "        - Type (e.g., CNN, Random Forest, Transformer)  \n",
    "        - Architecture details  \n",
    "        - Hyperparameters  \n",
    "        - Performance metrics (only those mentioned in the paper, e.g., Accuracy, F1-score, ROC-AUC, MAE, etc.)\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    input_prompt = prompt.format(text=input_text)\n",
    "\n",
    "    display(Markdown(\"Generating summary...\"))\n",
    "    result = model.invoke(input_prompt)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(f\"### Final Summary:\\n\\n{result.strip()}\"))\n",
    "\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ace8ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(input_text: str):\n",
    "    prompt_template = \"\"\"\n",
    "    You are an advanced research paper summarization mode. Summarize the following text: \n",
    "\n",
    "    {text}\n",
    "    \n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    input_prompt = prompt.format(text=input_text)\n",
    "\n",
    "    display(Markdown(\"Generating summary...\"))\n",
    "    result = model.invoke(input_prompt)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(f\"### Final Summary:\\n\\n{result.strip()}\"))\n",
    "\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf2877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = \"papers/hazel_test.pdf\"\n",
    "document_text = extract_text_from_pdf(document_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c02eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Citation: Ogunpola, A.; Saeed, F.;\\nBasurra, S.; Albarrak, A.M.; Qasem,\\nS.N. Machine Learning-Based\\nPredictive Models for Detection of\\nCardiovascular Diseases. Diagnostics\\n2024 ,14, 144. https://doi.org/\\n10.3390/diagnostics14020144\\nAcademic Editor: Mugahed A.\\nAl-antari\\nReceived: 27 November 2023\\nRevised: 21 December 2023\\nAccepted: 25 December 2023\\nPublished: 8 January 2024\\nCopyright: ©2024 by the authors.\\nLicensee MDPI, Basel, Switzerland.\\nThis article is an open access article\\ndistributed under the terms and\\nconditions of the Creative Commons\\nAttribution (CC BY) license (https://\\ncreativecommons.org/licenses/by/\\n4.0/).\\ndiagnostics \\nArticle\\nMachine Learning-Based Predictive Models for Detection of\\nCardiovascular Diseases\\nAdedayo Ogunpola1, Faisal Saeed1,*\\n, Shadi Basurra1, Abdullah M. Albarrak2\\nand Sultan Noman Qasem2\\n1DAAI Research Group, College of Computing and Digital Technology, Birmingham City University,\\nBirmingham B4 7XG, UK; adedayo.ogunpola@mail.bcu.ac.uk (A.O.); shadi.basurra@bcu.ac.uk (S.B.)\\n2Computer Science Department, College of Computer and Information Sciences, Imam Mohammad Ibn Saud\\nIslamic University (IMSIU), Riyadh 11432, Saudi Arabia; amsbarrak@imamu.edu.sa (A.M.A.);\\nsnmohammed@imamu.edu.sa (S.N.Q.)\\n*Correspondence: faisal.saeed@bcu.ac.uk\\nAbstract: Cardiovascular diseases present a significant global health challenge that emphasizes the\\ncritical need for developing accurate and more effective detection methods. Several studies have\\ncontributed valuable insights in this field, but it is still necessary to advance the predictive models\\nand address the gaps in the existing detection approaches. For instance, some of the previous studies\\nhave not considered the challenge of imbalanced datasets, which can lead to biased predictions,\\nespecially when the datasets include minority classes. This study’s primary focus is the early\\ndetection of heart diseases, particularly myocardial infarction, using machine learning techniques.\\nIt tackles the challenge of imbalanced datasets by conducting a comprehensive literature review\\nto identify effective strategies. Seven machine learning and deep learning classifiers, including\\nK-Nearest Neighbors, Support Vector Machine, Logistic Regression, Convolutional Neural Network,\\nGradient Boost, XGBoost, and Random Forest, were deployed to enhance the accuracy of heart disease\\npredictions. The research explores different classifiers and their performance, providing valuable\\ninsights for developing robust prediction models for myocardial infarction. The study’s outcomes\\nemphasize the effectiveness of meticulously fine-tuning an XGBoost model for cardiovascular diseases.\\nThis optimization yields remarkable results: 98.50% accuracy, 99.14% precision, 98.29% recall, and\\na 98.71% F1 score. Such optimization significantly enhances the model’s diagnostic accuracy for\\nheart disease.\\nKeywords: cardiovascular diseases; deep learning; disease detection; heart diseases; machine\\nlearning; ensemble learning; XGBoost\\n1. Introduction\\nThe heart plays a crucial role in sustaining life by effectively pumping oxygenated\\nblood and regulating important hormones to maintain optimal blood pressure levels. Any\\ndeviation from its functioning can lead to the development of heart conditions, collectively\\nknown as cardiovascular diseases (CVD). CVD includes a range of disorders that affect\\nboth the heart and blood vessels, such as cerebrovascular problems, congenital anomalies,\\npulmonary embolisms, irregular heart rhythms (arrhythmias), peripheral arterial issues,\\ncoronary artery disease (CAD), rheumatic heart ailments, coronary heart disease (CHD),\\nand cardiomyopathies that affect the heart muscle.\\nNotably, CHD is the subtype among cardiovascular diseases, accounting for a signif-\\nicant 64% of all cases. While it primarily affects men, women are also susceptible to its\\nimpact. Within the realm of CVDs, CAD is particularly concerning due to its association\\nwith global mortality rates. According to the World Health Organization (WHO) [ 1], the\\nconsequences of CVDs are profound, with staggering statistics indicating an estimated\\n17.9 million deaths annually are attributed to these diseases worldwide. These alarming\\nnumbers highlight the significance of research efforts and medical advancements dedicated\\nDiagnostics 2024 ,14, 144. https://doi.org/10.3390/diagnostics14020144 https://www.mdpi.com/journal/diagnosticsDiagnostics 2024 ,14, 144 2 of 19\\nto combatting and lessening the impact of cardiovascular diseases worldwide. There are\\nrisk factors that contribute to the development of CVDs, including blood pressure, excess\\nbody weight and obesity, abnormal lipid profiles, glucose irregularities or diabetes condi-\\ntions, tobacco usage or smoking habits, physical inactivity or sedentary lifestyle, alcohol\\nconsumption, and cholesterol levels. The WHO predicts that CVD will remain a cause\\nof mortality, silently posing a substantial threat to human life for the foreseeable future,\\npossibly even beyond 2030.\\nMachine learning, as highlighted by Ramesh et al. [ 2], enjoys major transformative\\ncapability within the healthcare industry. Its outstanding advancements can be ascribed to\\nits exceptional data processing abilities, which are far superior to those of humans. Conse-\\nquently, the field of healthcare has observed the development of several AI applications that\\nleverage machine learning’s speed and accuracy, paving the way for revolutionary solutions\\nto diverse healthcare challenges. Several machine learning methods have been applied for\\nthe purpose of detecting cardiovascular diseases. However, there is still a need to enhance\\nthe predictive models and address the research gaps in the existing detection approaches,\\nsuch as the challenge of imbalanced datasets, which can lead to biased predictions.\\nBy investigating the effectiveness of hybrid models combining different techniques,\\nvarious researchers have explored diverse methodologies, including neural networks\\nand various machine learning methods, to enhance prediction accuracy [ 3–12]. While\\nthese studies provide valuable insights, the variability in datasets, models, and outcomes\\nunderscores the complexity of the predictive task. Despite the advancements, there remains\\na pressing need for further investigations to refine existing models and improve the overall\\nperformance of cardiovascular disease prediction. The diverse landscape of machine\\nlearning applications in this domain emphasizes the importance of continued research\\nto enhance the accuracy, reliability, and generalizability of predictive models, ultimately\\ncontributing to more effective clinical interventions and patient care.\\nIn this paper, we have explored the strengths and limitations of the existing machine\\nlearning (ML) techniques in the context of heart disease analysis. Then, we investigated\\nand applied seven machine learning-driven predictive models that can enhance the de-\\ntection of cardiovascular and cerebrovascular diseases; these models include K-Nearest\\nNeighbors, Support Vector Machine, Logistic Regression, Convolutional Neural Network,\\nGradient Boost, XGBoost, and Random Forest. Two datasets were used in this study, which\\nwere pre-processed using different techniques such as oversampling, feature scaling, nor-\\nmalization, and dimensionality reduction to optimize data for effective machine learning\\nanalysis. Finally, we evaluated and compared the efficacy of different machine learning\\n(ML) techniques for analyzing heart diseases within the healthcare sector.\\n2. Related Works\\nIn this paper, we present a concise technical background and review pertinent literature\\nrelated to research studies conducted on the early forecast of heart disease utilizing machine\\nlearning and deep learning techniques. We highlight the different methods that have been\\nemployed in these studies to foretell heart disease at an initial stage.\\n2.1. Machine Learning Approach\\nMachine learning remains a rapidly advancing discipline of computational algorithms\\nthat try to imitate human intelligence by learning through data and the surrounding\\nenvironment. These algorithms play a crucial role in processing and analyzing large-scale\\ndata, often referred to as “big data”. Machine learning techniques have demonstrated\\ntheir effectiveness in various domains, including pattern recognition, computer vision,\\nspacecraft engineering, as well as biomedical and medical applications. Their versatility\\nand success have made them indispensable tools in addressing complex challenges and\\nextracting valuable insights from diverse datasets [13].\\nMachine learning is a specialized approach that automates the process of model\\nbuilding. Using algorithms, machines can discover hidden patterns and insights withinDiagnostics 2024 ,14, 144 3 of 19\\ndatasets. Importantly, in machine learning, we do not particularly instruct machines on\\nwhere to explore for insights; instead, the algorithms enable the machines to learn and\\nadapt their techniques and outputs as they uncover new-found data and scenarios. This\\niterative nature of machine learning allows for continuous improvement and adaptation,\\nmaking it a powerful tool for processing and analyzing complex datasets [14].\\nThere exist two main approaches in machine learning: supervised learning and un-\\nsupervised learning. In one approach, supervised learning, algorithms are trained using\\nspecific examples. The machine is provided with input data along with their corresponding\\ncorrect outputs. Learning takes place by comparing the machine’s experimental outcomes\\nwith the accurate outputs to discover blunders. This sort of learning is suitable after\\nprevious data has been utilized to foretell future occurrences [15].\\nThe other approach, unsupervised learning, involves the machine exploring the\\nrecords and attempting to discover patterns or structures on its own. It needs to cre-\\nate models commencing from scratch and is not provided with any precise outputs to\\nguide its learning process. Unsupervised learning is commonly employed to detect and\\ndistinguish outliers in the data. This approach is particularly useful when there is limited\\nor no labeled data available for training [ 14]. Researchers worldwide have made signifi-\\ncant efforts to combat cardiovascular disease (CVD) and improve patient outcomes [ 16].\\nThese efforts include enhancing clinical decision support systems to achieve precise early\\ndetection and enable effective treatment. Machine learning (ML) and artificial intelligence\\n(AI) techniques have played a pivotal role in the early detection and diagnosis of CVD.\\nCVD detection encompasses different distinct approaches. The first approach involves\\nutilizing AI models that analyze various test reports to distinguish between CVD patients\\nand healthy citizens. The second approach utilizes signals such as electrocardiogram (ECG)\\nand heart sound signals as vital information for ML models to classify individuals as either\\nhealthy or having CVD [16].\\n2.2. Deep Learning Approach\\nIn recent years, there has been remarkable progress in the field of deep learning, with\\na primary focus on developing intelligent automated systems that aid doctors in predicting\\nand diagnosing diseases through the utilization of the Internet of Things (IoT). While\\nconventional machine learning techniques were often restricted by their dependency on\\nsingle datasets, the advent of deep learning has brought significant enhancements to the\\naccuracy of existing algorithms. Deep learning leverages artificial neural networks, which\\nconsist of multiple hidden layers organized in a cascading pattern. This architecture enables\\nthe processing of non-linear datasets, allowing for more complex patterns and relationships\\nto be captured and learned by the model. As a result, deep learning has emerged as a\\npowerful tool in medical applications, providing improved predictive capabilities and\\nenhancing disease diagnosis through the integration of IoT devices and data sources. This\\napproach has shown promising results, outperforming older machine learning algorithms\\nin terms of accuracy. As accurate medical support systems for detecting hidden patterns\\nand predicting diseases are still lacking, deep learning offers the potential to accurately\\npredict heart diseases at an early stage, allowing for timely intervention and treatment [ 17].\\nSudha and Kumar [ 18] observed that the Convolutional Neural Network (CNN) is\\na suitable method for diagnosing heart disease. CNN’s ability to learn and represent\\nfeatures in a concise and conceptual manner is advantageous, especially as the network’s\\ndepth increases. Additionally, they proposed a hybrid model that combines Convolutional\\nNeural Networks (CNN) with Long Short-Term Memory (LSTM) units, which are a type\\nof recurrent neural network (RNN). LSTM units are known for their ability to store and\\ntransmit relevant information over long sequences, making them particularly useful for\\ntime-series data such as heart disease data. By integrating CNN and LSTM, the hybrid\\nmodel aimed to enhance the accuracy of heart disease classification. The CNN component\\nis adept at capturing spatial patterns in the data, while the LSTM component excels at\\nrecognizing temporal dependencies and patterns. This combination allows the model toDiagnostics 2024 ,14, 144 4 of 19\\neffectively learn complex features from the data, leading to improved classification accuracy.\\nExperimental results from the study revealed promising outcomes, with the hybrid model\\nachieving an accuracy of 89%, sensitivity of 81%, and specificity of 93%. These results\\noutperformed conventional machine learning classifiers, indicating the potential of the\\nproposed hybrid approach in advancing the accuracy of heart disease classification [18].\\nThe healthcare sector has emerged as a prime beneficiary of the growing volume\\nand accessibility of data [ 19]. Various entities, such as healthcare providers, pharmaco-\\nlogical firms, research institutions, and government parastatals, are now accumulating\\nvast volumes of data from diverse sources, including research, clinical trials, public health\\nprograms, and insurance data. The merging of such data holds immense potential for\\nadvancing healthcare practices and decision-making [ 20]. Traditionally, doctors used to\\ndiagnose and treat patients based on their symptoms alone. However, evidence-based\\nmedicine has become the prevailing approach, where physicians review extensive datasets\\nobtained from medical trials and treatment paths on a huge scale to make decisions built\\non the most comprehensive and up-to-date information available. This shift towards data-\\ndriven decision-making is transforming healthcare practices, improving patient outcomes,\\nand driving further advancements in the medical field [14].\\nNumerous industry and research initiatives are actively working on implementing\\nmachine learning expertise in the healthcare sector to enhance patient care and well-being\\nglobally. One such initiative is the Shah Lab, based at Stanford University [ 14]. The\\nShah Lab focuses on leveraging machine learning and data science to address critical\\nhealthcare challenges and develop innovative solutions for various medical applications.\\nThrough these initiatives, researchers and experts aim to harness the power of machine\\nlearning to analyze large-scale healthcare data, including electronic health records, medical\\nimaging, genomics, and patient outcomes. By extracting valuable insights and patterns\\nfrom this data, they aim to improve disease diagnosis, treatment prediction, personalized\\nmedicine, and overall patient management. The goal is to provide healthcare professionals\\nwith advanced tools and technologies that can assist them in making more accurate and\\ntimely clinical decisions, leading to better patient outcomes and an overall improvement\\nin healthcare services worldwide. Table 1 below presents a summary of the performance\\nmetrics related to the existing methods under evaluation, with each entry corresponding to\\nspecific evaluation criteria.\\nTable 1. Summary of the performance of the existing methods.\\nStudy Method Results\\nMohan et al. [21]Hybrid Random Forest with Linear\\nModel (HRFLM)Accuracy: 88%\\nSensitivity: 92.8%\\nSpecificity: 82.6%\\nSingh et al. [22]SVM\\nK-Nearest Neighbors\\nDecision Tree\\nLinear Regression83% Accuracy SVM\\n79% (DT)\\n78% (LR)\\n87% (KNN)\\nGavhane et al. [23] Neural NetworkPrecision rate: 91%\\nRecall rate: 89%\\nKavitha et al. [24]Hybrid Model (Random Forest (RF)\\nand Decision Tree (DT))Accuracy: 88%\\nAmiri and Armano [25] Classification—CARTAccuracy: 99.14%\\nSensitivity: 100%\\nSpecificity: 98.28%\\nLiu and Kim [26]Classifier—Long Short Term Memory\\n(LSTM)Accuracy: 98.4%\\n2.3. Datasets Collection and Preprocessing\\nIn their study, Algarni et al. [ 27] utilized a dataset of coronary artery X-ray angiography\\nimages obtained from a clinical database. These images exhibited challenging character-Diagnostics 2024 ,14, 144 5 of 19\\nistics, including uneven vessel thickness, complex vascular structures in the background,\\nand the presence of noise. The dataset consisted of 130 X-ray coronary angiograms, each\\nhaving a size of 300 ×300 pixels. The data was collected from the cardiology department of\\nthe Mexican Social Security Institute, and ethical approval was obtained (reference number\\nR-2019-1001-078) for the use of this medical database in heart disease diagnosis. To train\\nand evaluate their proposed model, called ASCARIS, the dataset was randomly divided\\ninto two parts: a training set containing 100 images and a test set comprising 30 images.\\nThe ASCARIS model was developed based on color, diameter, and shape features extracted\\nfrom the angiography images.\\nAl Mehedi et al. [ 28] utilized a dataset of 299 heart failure patients obtained from\\nthe Faisalabad Institute of Cardiology and the Allied Hospital in Faisalabad. The dataset\\nconsisted of 13 attributes, including features such as Age, Anemia, High Blood Pressure,\\nCreatinine Phosphokinase (CPK), Diabetes, Ejection Fraction, Sex, Serum Creatinine, Serum\\nSodium, Smoking, Time, and a target column labeled as “Death Event”, which was used\\nfor binary classification. The dataset underwent preprocessing to ensure its quality and\\nconsistency. After preprocessing, the dataset was divided into separate train and test sets\\nfor model training and evaluation. Two feature selection methods were applied to the train\\nset to identify the most relevant features for the heart failure prediction task.\\nDeepika and Seema [ 29] conducted a study on heart disease with datasets available\\nonline from the UCI Machine Learning Repository at the University of California, Irvine.\\nThey comprise 76 attributes, including the target property, but only 14 of these attributes\\nwere considered essential for analysis. The researchers used two specific datasets for their\\nstudy: the Cleveland Clinic Foundation dataset, with records from 303 patients, and the\\nHungarian Institute of Cardiology dataset, with records from 294 patients. Various machine\\nlearning algorithms, including Naïve Bayes (NB), Support Vector Machine (SVM), Decision\\nTree (DT), and Artificial Neural Networks, were employed in the analysis to predict heart\\ndisease. Within the broader context, Table 2 clarifies the preprocessing approaches and\\npredictive methodologies utilized in previous studies.\\nTable 2. Preprocessing and predictive methods.\\nStudy Dataset Preprocessing and Modeling Results\\nAlgarni et al. [27]Coronary artery X-ray\\nangiography images obtained\\nfrom a clinical database.Training: 100 images\\nTest: 30 images\\nASCARIS model (based on color,\\ndiameter, and shape features).Accuracy: 97%\\nUyar and ˙Ilhan [ 30]Cleveland dataset for heart\\ndisease.Removal of 6 instances with missing\\nentries from the dataset and\\ncategorization of the diagnosis\\nattribute (num) into two classes:\\nabsence (num = 0) and presence\\n(num = 1, 2, 3, or 4) of heart disease.\\nRecursive Fuzzy Neural Network\\n(RFNN)Testing set accuracy: 97.78%\\nOverall accuracy: 96.63%\\nDeng et al. [31]Fuwai ECG database and public\\nPTB databasetraining phase for dynamics\\nacquisition and a test phase for\\ndynamics reuse\\nAttention-based Res-BiLSTM-Net\\nmodelF1 scores ranging from 0.72\\nto 0.98\\nDas et al. [32] UCI datasetSAS-based software\\nNeural NetworksTraining accuracy: 86.4%,\\nValidation accuracy: 89.011%\\n2.4. Discussions on the Research Limitations\\nThe literature review involved an in-depth exploration of the existing research and\\nknowledge pertaining to heart disease prediction using diverse machine learning and deep\\nlearning techniques. Several studies reviewed the recent advancements and limitations ofDiagnostics 2024 ,14, 144 6 of 19\\napplying machine learning for cardiovascular disease detection [ 10,33–36]. For instance,\\nthe studies [ 8,37–40] proposed different data mining and machine learning methods based\\non heartbeat segmentation and selection process, ECG images, images of carotid arteries,\\nand others.\\nNumerous studies have concentrated on applying machine learning algorithms such\\nas Decision Tree, Naïve Bayes, Random Forest, Support Vector Machine, and Logistic Re-\\ngression on the Heart Disease Dataset, yielding promising accuracy rates for classification.\\nMoreover, deep learning methods, particularly Convolutional Neural Networks (CNN),\\nhave gained significant traction for effectively handling complex tasks and unstructured\\ndata. The review also examined discussions regarding the implementation of data pre-\\nprocessing techniques, feature selection methods, and performance evaluation metrics to\\noptimize the efficiency of predictive models. Some studies underscored the importance of\\ndata quality and the relevance of specific features in enhancing the accuracy of the models.\\nMachine learning algorithms play a crucial role in precisely foretelling heart disease by\\ndiscovering suppressed patterns in data, making predictions, and improving performance\\nbased on historical data. These programs make it possible for us to anticipate and diagnose\\nheart disease more accurately, while deep learning, fueled by artificial neural networks, is a\\ncritical factor in handling complex computations on large volumes of data. These algorithms\\nplay an essential role in identifying key attributes and patterns in both structured and\\nunstructured data, enhancing more efficient data analysis and processing.\\nEmploying machine learning and deep learning approaches offers considerable poten-\\ntial in the field of heart disease diagnosis and treatment. These sophisticated techniques\\nenable the integration of various data sources, such as medical records, imaging data, ge-\\nnetics, and lifestyle factors, to create a universal and individualized approach to healthcare.\\nThe iterative nature of machine learning acknowledges continuous learning and adapta-\\ntion, resulting in progressed diagnostic and predictive models over time. This promises to\\nenhance the accuracy and effectiveness of heart disease management, ultimately leading to\\nbetter patient outcomes.\\nAfter reviewing the available literature, it is evident that there is a lack of exten-\\nsive experimentation on the use of Gradient Boosting models in the detection of heart\\ndisease. However, considering the unique capabilities of Gradient Boosting models in\\nanalyzing data and capturing temporal dependencies, their potential in this domain is\\nworth exploring.\\nThe potential of Gradient Boosting models to progressively enhance predictive accu-\\nracy by refining weaker learners within the model positions them as promising contenders\\nfor improving the precision of heart disease detection. Consequently, there is a need for fur-\\nther exploration and experimentation dedicated to harnessing the capabilities of Gradient\\nBoosting models in this context.\\nBy embracing the use of Gradient Boosting models in heart disease detection and\\nconducting more targeted experiments, we can unlock new possibilities for advancing\\nhealthcare interventions and ultimately enhancing patient outcomes and well-being.\\n3. Materials and Methods\\nThe following methods are adapted to achieve the goals of this research. They are\\napplied to explore and comprehend various dimensions of heart-related conditions, ul-\\ntimately contributing to the creation of precise models for the diagnosis and prediction\\nof these conditions. The general research method framework of this study is shown in\\nFigure 1.Diagnostics 2024 ,14, 144 7 of 19\\nDiagnostics 2024 , 14, x FOR PEER REVIEW  7 of 20 \\n \\n healthcare. Th e iterative nature of machine learning acknowledges continuous learning \\nand adaptation, resulting in progressed diagnostic and predictive models over time. This \\npromises to enhance the accuracy and effectiveness of heart disease management, ulti-\\nmately lead ing to better patient outcomes.  \\nAfter reviewing the available literature, it is evident that there is a lack of extensive \\nexperimentation on the use of Gradient Boosting models in the detection of heart disease. \\nHowever, considering the unique capabilitie s of Gradient Boosting models in analyzing \\ndata and capturing temporal dependencies, their potential in this domain is worth explor-\\ning.  \\nThe potential of Gradient Boosting models to progressively enhance predictive accu-\\nracy by refining weaker learners with in the model positions them as promising contend-\\ners for improving the precision of heart disease detection. Consequently, there is a need \\nfor further exploration and experimentation dedicated to harnessing the capabilities of \\nGradient Boosting models in th is context.  \\nBy embracing the use of Gradient Boosting models in heart disease detection and \\nconducting more targeted experiments, we can unlock new possibilities for advancing \\nhealthcare interventions and ultimately enhancing patient outcomes and well -being.  \\n3. Materials and Methods  \\nThe following methods are adapted to achieve the goals of this research. They are \\napplied to explore and comprehend various dimensions of heart -related conditions, ulti-\\nmately contributing to the creation of precise models for the diagnosis and prediction of \\nthese conditions. The general research method framework of this study is shown in Figure \\n1.  \\n \\nFigure 1. Research method workflow.  \\n3.1. Datasets  \\nTo carry out this research study, two datasets were examined, namely the Cardiovas-\\ncular Heart Disease Dataset, which was retrieved from the Mendeley database, and the \\nHeart Disease Cleveland Dataset, which was retrieved from the Kaggle database. The \\n“Cardio” and “Target” columns on both datasets refer to the column we are trying to pre-\\ndict with numeric values 0 (no disease) and 1 (disease). It is important to note that neither \\ndataset has any missing values. The detailed descriptions of all these attributes  are listed \\nbelow:  \\nFigure 1. Research method workflow.\\n3.1. Datasets\\nTo carry out this research study, two datasets were examined, namely the Cardiovascu-\\nlar Heart Disease Dataset, which was retrieved from the Mendeley database, and the Heart\\nDisease Cleveland Dataset, which was retrieved from the Kaggle database. The “Cardio”\\nand “Target” columns on both datasets refer to the column we are trying to predict with\\nnumeric values 0 (no disease) and 1 (disease). It is important to note that neither dataset\\nhas any missing values. The detailed descriptions of all these attributes are listed below:\\nThe Cardiovascular Heart Disease Dataset (Table 3) holds significant importance\\nwithin the healthcare and machine learning domains. It serves as an asset for tasks associ-\\nated with the prediction and classification of cardiovascular diseases while holding data of\\n1000 data samples in 13 attributes, each representing a potential risk factor.\\nTable 3. Cardiovascular Heart Disease Dataset.\\nFeatures Details\\n1. Patient Id Individual unique identifier.\\n2. Age Numeric representation of patients’ age in years.\\n3. Gender Binary (1, 0 (0 = female, 1 = male))\\n4. ChestpainNominal (0, 1, 2, 3 (Value 0: typical angina Value 1: atypical\\nangina Value 2: non-anginal pain Value 3: asymptomatic))\\n5. restingBP Numeric (94–200 (in mm HG))\\n6. serumcholestrol Numeric (126–564 (in mg/dL))\\n7. fastingbloodsugar Binary (0, 1 > 120 mg/dL (0 = false, 1 = true))\\n8. restingrelectroNominal (0, 1, 2 (Value 0: normal, Value 1: having ST-T wave\\nabnormality (T wave inversions and/or ST elevation or\\ndepression of >0.05 mV), Value 2: showing probable or definite\\nleft ventricular hypertrophy by Estes’ criteria))\\n9. maxheartrate Numeric (71–202)\\n10. exerciseangia Binary (0, 1 (0 = no, 1 = yes))\\n11. oldpeak Numeric (0–6.2)\\n12. slope Nominal (1, 2, 3 (1-upsloping, 2-flat, 3-downsloping))\\n13. noofmajorvessels Numeric (0, 1, 2, 3)\\n14. targetBinary (0, 1 (0 = Absence of Heart Disease, 1= Presence of Heart\\nDisease))Diagnostics 2024 ,14, 144 8 of 19\\nShifting our focus to the Heart Disease Cleveland Dataset (Table 4), a widely rec-\\nognized dataset frequently employed in the fields of machine learning and healthcare,\\nwhich has been extensively used in tasks related to predicting and classifying heart disease.\\nThis dataset holds prominence for its pivotal role in assessing the effectiveness of diverse\\nmachine learning algorithms in diagnosing heart disease with 303 patients’ information\\nin 14 attributes. Its primary objective revolves around predicting whether heart disease is\\npresent or absent.\\nTable 4. Heart Disease Cleveland Dataset.\\nFeatures Details\\n1. Age Numeric representation of patients’ age in years.\\n2. SexCategorical feature representing gender, where Male is encoded as 1 and\\nFemale as 0.\\n3. cpCategorical attribute indicating the various types of chest pain felt by the\\npatient. 0 for typical angina, 1 for atypical angina, 2 for non-anginal pain,\\nand 3 for asymptomatic.\\n4. trestbpsNumerical measurement of the patient’s blood pressure at rest, recorded in\\nmm/HG.\\n5. cholNumeric value indicating the serum cholesterol intensity of the patient,\\ncalculated in mg/dL.\\n6. fbsCategorical representation of fasting blood sugar levels, with 1 signifying\\nlevels above 120 mg/dL and 0 indicating levels below.\\n7. restecgCategorical feature describing the result of the electrocardiogram\\nconducted at rest. 0 for normal, 1 for ST-T wave abnormalities, and 2 for\\nindications of probable or definite left ventricular hypertrophy according\\nto Estes’ criteria.\\n8. thalach Numeric representation of the heart rate realized by the patient.\\n9. exangCategorical feature denoting whether exercise-induced angina is present.\\n0 signifies no, while 1 signifies yes.\\n10. oldpeakNumeric value indicating exercise-induced ST-depression relative to the\\nrest state.\\n11. slopeCategorical attribute representing the slope of the ST segment during peak\\nexercise. It can take three values: 0 for up-sloping, 1 for flat, and 2 for\\ndown-sloping.\\n12. caCategorical feature indicating the number of major blood vessels, ranging\\nfrom 0 to 3.\\n13 thalCategorical representation of a blood disorder called thalassemia. 0 for\\nNULL, 1 for normal blood flow, 2 for fixed defects (indicating no blood\\nflow in a portion of the heart), and 3 for reversible defects (indicating\\nabnormal but observable blood flow).\\n14. targetThe target variable to predict heart disease, encoded as 1 for patients with\\nheart disease and 0 for patients without heart disease.\\n3.2. Data Pre-Processing\\nData preprocessing is an essential step within machine learning that aims to improve\\ndataset quality and reliability before analysis and modeling. This phase tackles challenges\\nsuch as missing data, inconsistencies, outliers, and skewed class distributions. Address-\\ning missing values is crucial to ensure accurate insights by utilizing techniques such as\\nimputation. Detecting and managing outliers is also vital, as these data points can skew\\nresults. A key concern is class distribution balance, where methods like oversampling\\nmitigate imbalanced datasets. Considering these considerations, employing techniques\\nsuch as feature scaling, normalization, and dimensionality reduction can optimize data for\\neffective machine learning analysis.\\n3.3. Model Development\\nThe conclusion of the thorough literature work brings us to the pivotal stage of\\nmodel development. This section encompasses seven notable machine learning techniques:Diagnostics 2024 ,14, 144 9 of 19\\nLogistic Regression, Convolutional Neural Network, Support Vector Machine (SVM),\\nGradient Boosting, K-Nearest Neighbors (KNN), XGBoost, and Random Forest. Each\\nalgorithm contributes distinct characteristics to unveil predictive revelations in the analysis\\nof cardiovascular and cerebrovascular diseases, utilizing resources such as Scikit-Learn and\\nKeras libraries.\\nEach of these models possesses unique traits, spanning from linear approaches to\\nensemble techniques and deep learning architectures. Through thorough empirical investi-\\ngations, we assessed the effectiveness of every model in terms of recall, precision, accuracy,\\nand F1-score metrics.\\n3.4. Model Evaluation\\nModel Evaluation stands as a pivotal phase in the realm of machine learning, dedicated\\nto thoroughly gauging how well-trained models predict outcomes. This essential step\\nensures that models can generalize to new data effectively, informing decisions about\\ndeployment and refinement. The following key techniques and metrics will contribute to a\\ncomprehensive evaluation of this study:\\nConfusion Matrix: Offering insight into true positives, true negatives, false positives,\\nand false negatives, this matrix forms the basis for calculating vital metrics.\\nAccuracy: Providing an overall view of model performance by measuring correctly\\npredicted instances against the total dataset.\\nAccuracy = (TP + TN)/(TP + FP + TN + FN) (1)\\nPrecision and Recall: Precision assesses positive prediction accuracy, while recall\\ngauges the model’s ability to capture positive instances.\\nPrecision = TP/(TP + FP) (2)\\nRecall = TP/(TP + FN) (3)\\nF1-Score: Striking a balance between precision and recall, this score is essential for\\nharmonizing performance aspects.\\nF1 = (2 ×precision ×recall)/(precision + recall) (4)\\nCross-Validation: This technique partitions data for training and testing, guarding\\nagainst overfitting.\\nHyperparameter Tuning: Optimizing model parameters through techniques like\\nGridSearch enhances performance.\\n4. Results\\nThis section explores the detailed analysis of machine learning models for heart disease\\nprediction, leveraging two distinct datasets: the Cardiovascular Heart Disease Dataset and\\nthe Heart Disease Cleveland Dataset using the Python programming language.\\nOur primary objective is to identify the most effective predictive models, considering\\nboth traditional tabular datasets while keeping in mind the aims of the study.\\n4.1. Pre-Processing Results\\nTo harness the potential of the Cardiovascular Heart Disease Dataset and the Heart\\nDisease Cleveland Dataset for machine learning applications, it becomes imperative to\\nexecute preliminary data preprocessing procedures. These procedures encompass a range\\nof actions, including managing missing data, encoding categorical variables, standardizing\\nor normalizing feature values, and partitioning the dataset into distinct training and testing\\nsubsets. Additionally, the utilization of exploratory data analysis (EDA) techniques and\\ndata visualization tools proves instrumental in gaining insights into data distributions and\\ninter-variable relationships.Diagnostics 2024 ,14, 144 10 of 19\\nFirstly, a correlation matrix heatmap is created, as shown in Figure 2. This heatmap\\ncomputes the correlation coefficients among diverse attributes in the datasets and represents\\nthem graphically. Its purpose is to facilitate the visual examination of associations between\\nvarious features. Positive correlations are depicted using green hues, whereas negative\\ncorrelations are represented in red. This heatmap serves the purpose of identifying the\\nfeatures that exhibit the most substantial correlations with the target variable, thereby\\nrevealing their impact on the presence or absence of cardiovascular disease. On the left\\nside is the Cardiovascular Heart Disease Dataset, while on the right is the Heart Disease\\nCleveland Dataset.\\nDiagnostics 2024 , 14, x FOR PEER REVIEW  11 of 20 \\n \\n thereby revealing their impact on the presence or absence of cardiovascular disease. On \\nthe left side is the Cardiovascular Heart Disease Dataset, while on the right is the Heart \\nDisease Cleveland Dataset.  \\n \\n \\nFigure 2. Heatmap distribution of the dataset features.  \\nThe histograms corresponding to individual dataset attributes provide valuable in-\\nsights by allowing exploration of each feature’s distribution, as shown in Figure 3. They \\nare instrumental in the detection of potential outliers and provide a rapid overview of the \\ncharacteristics and spans of these features. This visualization is a helpful tool for compre-\\nhending the overall shape and distribution of the data. The pictorial evidence of both da-\\ntasets can be seen below, where the Cardiovascular Heart Disease Dat aset is on the left, \\nand the Heart Disease Cleveland Dataset can be seen on the right.  \\nFigure 2. Heatmap distribution of the dataset features.Diagnostics 2024 ,14, 144 11 of 19\\nThe histograms corresponding to individual dataset attributes provide valuable in-\\nsights by allowing exploration of each feature’s distribution, as shown in Figure 3. They\\nare instrumental in the detection of potential outliers and provide a rapid overview of\\nthe characteristics and spans of these features. This visualization is a helpful tool for\\ncomprehending the overall shape and distribution of the data. The pictorial evidence of\\nboth datasets can be seen below, where the Cardiovascular Heart Disease Dataset is on the\\nleft, and the Heart Disease Cleveland Dataset can be seen on the right.\\nDiagnostics 2024 , 14, x FOR PEER REVIEW  12 of 20 \\n \\n  \\n \\nFigure 3. Histogram distribution of the dataset features.  \\nAs shown in Figure 4, the pie chart is utilized to depict the distribution of the target \\nvariable, which signifies the existence or non -existence of cardiovascular disease. The fig-\\nure shows the distribution of features in the target variable, where 1 repre sents features \\nwith heart disease, and 0 represents features without heart disease. It enumerates the in-\\nstances of each class and exhibits the proportions as percentages in the pie chart, illustrat-\\ning the presence and absence of cardiovascular disease. In Figure 4, the pie chart on the \\nright represents features of the target column distribution of the Cardiovascular Heart \\nFigure 3. Histogram distribution of the dataset features.Diagnostics 2024 ,14, 144 12 of 19\\nAs shown in Figure 4, the pie chart is utilized to depict the distribution of the target\\nvariable, which signifies the existence or non-existence of cardiovascular disease. The figure\\nshows the distribution of features in the target variable, where 1 represents features with\\nheart disease, and 0 represents features without heart disease. It enumerates the instances\\nof each class and exhibits the proportions as percentages in the pie chart, illustrating the\\npresence and absence of cardiovascular disease. In Figure 4, the pie chart on the right\\nrepresents features of the target column distribution of the Cardiovascular Heart Disease\\nDataset, while the left represents the feature of the target column distribution of the Heart\\nDisease Cleveland Dataset.\\nDiagnostics 2024 , 14, x FOR PEER REVIEW  13 of 20 \\n \\n Disease Dataset, while the left represents the feature of the target column distribution of \\nthe Heart Disease Cleveland Dataset.  \\n  \\nFigure 4. The distribution of features in the target variable . \\nAfter successfully preprocessing and visualizing the features of the dataset, we con-\\nducted an in -depth exploration of various machine learning models to discern their pre-\\ndictive efficacy.  \\n4.2. K-Nearest Neighbors (KNN) Results  \\nWe commenced the analysis by employing the K -Nearest Neighbors (KNN) algo-\\nrithm with varying ‘k’ values, representing the number of nearest neighbors considered \\nduring the predictions. Employing cross -validation, we compu ted scores for each ‘k’ \\nvalue, ultimately discerning that ‘k = 7′ yielded the most favorable mean cross -validation \\nscore. This outcome underscores that configuring KNN with ‘k = 7′ exhibits significant \\npromise.  \\nAs shown in Tables 5 –8, the implementation o f this model yielded an impressive ac-\\ncuracy rate of 96.50% and 91.80% on the datasets, respectively, serving as an overarching \\nmeasure of the model’s correctness in its predictions. Furthermore, meticulous hyperpa-\\nrameter tuning was carried out to guarantee  optimal performance. The precision score, \\ngauging the proportion of true positive predictions among all positive predictions, \\nachieved a notable level, approximately 96.61% and 96.55%. Additionally, the recall, rep-\\nresenting the proportion of true positive  predictions among all actual positives, exhibited \\na strong value, approximately 97.44%, and 87.50%. Similarly, the F1 Score attained an im-\\npressive value, hovering around 97.02% and 91.80%. These metrics collectively affirm the \\nexceptional performance of t he KNN model within the dataset.  \\nTable 5. Results on Precision measure.  \\nClassification Model  Precision (in %)  \\n Dataset 1  Dataset 2  \\nKNN  96.50%  96.55%  \\nRF 98.63%  94.44%  \\nLR 96.55%  93.10%  \\nGB 99.13%  90.00%  \\nFigure 4. The distribution of features in the target variable.\\nAfter successfully preprocessing and visualizing the features of the dataset, we con-\\nducted an in-depth exploration of various machine learning models to discern their predic-\\ntive efficacy.\\n4.2. K-Nearest Neighbors (KNN) Results\\nWe commenced the analysis by employing the K-Nearest Neighbors (KNN) algorithm\\nwith varying ‘k’ values, representing the number of nearest neighbors considered during the\\npredictions. Employing cross-validation, we computed scores for each ‘k’ value, ultimately\\ndiscerning that ‘k = 7’ yielded the most favorable mean cross-validation score. This outcome\\nunderscores that configuring KNN with ‘k = 7’ exhibits significant promise.\\nAs shown in Tables 5–8, the implementation of this model yielded an impressive\\naccuracy rate of 96.50% and 91.80% on the datasets, respectively, serving as an overarching\\nmeasure of the model’s correctness in its predictions. Furthermore, meticulous hyperpa-\\nrameter tuning was carried out to guarantee optimal performance. The precision score,\\ngauging the proportion of true positive predictions among all positive predictions, achieved\\na notable level, approximately 96.61% and 96.55%. Additionally, the recall, representing the\\nproportion of true positive predictions among all actual positives, exhibited a strong value,\\napproximately 97.44%, and 87.50%. Similarly, the F1 Score attained an impressive value,\\nhovering around 97.02% and 91.80%. These metrics collectively affirm the exceptional\\nperformance of the KNN model within the dataset.Diagnostics 2024 ,14, 144 13 of 19\\nTable 5. Results on Precision measure.\\nClassification Model Precision (in %)\\nDataset 1 Dataset 2\\nKNN 96.50% 96.55%\\nRF 98.63% 94.44%\\nLR 96.55% 93.10%\\nGB 99.13% 90.00%\\nSVM 95.00% 80.65%\\nCNN 99.14% 87.50%\\nXGBoost 99.14% 90.00%\\nTable 6. Results on Recall measure.\\nClassification Model Recall (in %)\\nDataset 1 Dataset 2\\nKNN 97.44% 87.50%\\nRF 98.97% 85.61%\\nLR 95.73% 84.38%\\nGB 97.44% 84.38%\\nSVM 97.44% 78.12%\\nCNN 98.29% 89.77%\\nXGBoost 98.29% 84.38%\\nTable 7. Results on F1-Score measure.\\nClassification Model F1-Score (in %)\\nDataset 1 Dataset 2\\nKNN 97.02% 91.80%\\nRF 98.80% 89.81%\\nLR 96.14% 88.52%\\nGB 98.28% 87.10%\\nSVM 96.20% 79.37%\\nCNN 97.80% 87.50%\\nXGBoost 98.71% 87.10%\\nTable 8. Results on Accuracy measure.\\nClassification Model Accuracy (in %)\\nDataset 1 Dataset 2\\nKNN 96.50% 91.80%\\nRF 98.60% 91.09%\\nLR 95.50% 88.52%\\nGB 98.00% 86.89%\\nSVM 95.50% 78.69%\\nCNN 97.50% 86.89%\\nXGBoost 98.50% 86.89%\\n4.3. Random Forest Results\\nBy conducting an extensive hyperparameter tuning process, we modified the number\\nof trees (n_estimators) to 200 within the Random Forest ensemble model. As shown in\\nTables 5–8, the tuned model achieved an outstanding accuracy level, hovering at around\\n98.60% and 91.09%. The assessment of precision showed a significant enhancement, which\\nobtained 98.63% and 94.44%.\\nSimilarly, the F1 Score, which amalgamates precision and recall, demonstrated the\\nmodel’s robustness, registering a value of 98.80% and 89.81, respectively. Furthermore,Diagnostics 2024 ,14, 144 14 of 19\\nthe recall score, measuring the model’s aptitude for recognizing genuine positive cases,\\nreached a remarkable value of 98.97% and 85.61.\\n4.4. Logistic Regression (LR) Results\\nBy implementing a custom threshold of 0.6, the model was configured to adopt a\\ncautious approach when classifying instances as positive. To be specific, if the predicted\\nprobability of an instance belonging to the positive class (class 1) equaled or exceeded 0.6, it\\nwas categorized as positive; otherwise, it was designated as negative. This threshold selec-\\ntion significantly influenced how the model struck a balance between precision and recall.\\nAs shown in Tables 5–8, the model’s precision score was 96.55% and 93.10%, signifying its\\nproficiency in minimizing false positive predictions.\\nThe recall scores stood at 95.73% and 84.38%, emphasizing the model’s importance in\\ncorrectly identifying all positive cases, particularly in scenarios where missing potential\\ncases of heart disease is a critical concern. The F1 Score captured genuine positive cases at\\n96.14% and 88.52%. Regarding overall accuracy, the model achieved an accuracy score of\\n95.50% and 88.52%.\\n4.5. Gradient Boosting (GB) Results\\nThrough the GridSearchCV process, we effectively fine-tuned the model’s hyperpa-\\nrameters. The optimal hyperparameters selected encompassed a learning rate of 0.2, a\\nmaximum depth of 3 for individual trees, and 100 boosting stages (n_estimators). These\\nhyperparameters were chosen based on their exceptional performance on the validation\\ndatasets. When tested on independent data, the refined Gradient Boosting model consis-\\ntently delivered exceptional results. As shown in Tables 5–8, it attained an impressive\\nprecision score of 99.13% and 90.90%, indicative of its ability to minimize false positive\\npredictions effectively.\\nFurthermore, the model exhibited a recall score of 97.44% and 84.38%, which holds\\nparamount importance in medical applications where identifying potential cases of heart\\ndisease is critical. The F1 Score, which harmonizes precision and recall, reached an impres-\\nsive value of 98.28% and 87.10.\\nThe model’s accuracy on the test dataset was consistently high, measuring 98.00%,\\nalthough it achieved 86.89% on the Heart Disease Cleveland Dataset. These findings\\ncollectively underscore the Gradient Boosting model’s exceptional suitability for the task of\\nheart disease classification, highlighting its potential to accurately detect individuals with\\nheart disease while maintaining a low rate of false positives. Such performance makes it an\\nasset for healthcare professionals and researchers in the cardiology field.\\n4.6. Support Vector Machine (SVM) Results\\nThe process of tuning hyperparameters, carried out through GridSearchCV , effectively\\ndetermined the most suitable hyperparameter configuration for the SVM model. This\\nconfiguration included a regularization parameter (C) set to 10, a polynomial kernel with a\\ndegree of 2, and the utilization of a linear kernel.\\nAs shown in Tables 5–8, for post-tuning, the model achieved a precision score of 95.00%\\nand 80.65%, a recall score of 97.44% and 78.12%, and an F1 Score of 96.20% and 79.37%.\\nOn the test dataset, the model exhibited an accuracy of approximately 95.50% and\\n78.69%, affirming its consistent and accurate predictive capabilities.\\n4.7. Convolutional Neural Network (CNN) Results\\nThe model architecture consists of three layers: an initial layer with 128 units employ-\\ning the ReLU activation function, followed by a hidden layer featuring 64 units with ReLU\\nactivation, and ultimately, an output layer utilizing the sigmoid activation function. During\\nmodel compilation, the Adam optimizer was employed alongside binary cross-entropy\\nloss, with accuracy serving as the evaluation metric.Diagnostics 2024 ,14, 144 15 of 19\\nTo mitigate the risk of overfitting, a precautionary measure known as early stopping\\nwas integrated into the training process. This involved monitoring the validation loss for\\na maximum of 10 epochs and restoring the model’s weights to their best configuration.\\nThe training was conducted using scaled training data over a maximum of 100 epochs,\\nemploying a batch size of 64.\\nAs shown in Tables 5–8, the model’s performance on the test dataset is particularly\\nnoteworthy. Precision achieved an impressive score of 97.46% and 87.50%.\\nThis suggests that when the model predicts an individual as having heart disease, it is\\nhighly likely to be accurate. Furthermore, the recall scores were 98.29% and 87.50%. The F1\\nScore demonstrates resilience at 97.87% and 87.50%. Overall accuracy, which reflects the\\nratio of correctly predicted cases to the total cases, stands at 97.50% and 86.89%, respectively.\\n4.8. XGBoost Results\\nThrough the utilization of GridSearchCV , a highly effective process of hyperparameter\\ntuning was carried out. This process led to the discovery of optimal hyperparameters\\nfor the XGBoost model, which included a learning rate of 0.2, a maximum tree depth\\nof 3, 100 boosting rounds (n_estimators), and a subsample fraction of 1.0. The recall\\nof these chosen hyperparameters was substantiated by a remarkable validation score of\\napproximately 98.00% on the Cardiovascular Heart Disease Dataset and 84% on the Heart\\nDisease Cleveland Dataset, respectively.\\nOn the test dataset, the fine-tuned XGBoost model upheld its exceptional performance\\nby achieving a precision score of 99.14% and 90.00%, signifying its adeptness in accurately\\ncategorizing positive cases. Moreover, the recall score, at 98.29% and 84.38%, holds par-\\nticular significance. The F1 Score exhibits resilience at 98.71% and 87.10%. The model’s\\noverall accuracy on the test data hovers at 98.50% and 86.89%. These remarkable outcomes\\nunderscore the XGBoost model’s aptness for heart disease classification.\\n5. Discussion\\nThe experimental results are shown in Tables 5–8 and Figure 5. The thorough as-\\nsessment of machine learning models, specifically the XGBoost and K-Nearest Neighbors\\nmodels, in the context of heart disease prediction, provides valuable insights. These insights\\nalign with the research conducted by Zhang et al. [ 41], which underscores the effectiveness\\nof the XGBoost algorithm in this specific domain.\\nDiagnostics 2024 , 14, x FOR PEER REVIEW  17 of 20 \\n \\n  \\nFigure 5. Accuracy of machine learning models on both datasets.  \\n6. Conclusions and Future Scope  \\nAs we discussed the broader scope of model selection and its implications for heart \\ndisease prediction, the conducted analysis has unearthed invaluable insights. Among the \\narray of models under scrutiny, K -Nearest Neighbors and XGBoost have consistently \\nrisen to prominence as top -performing candidates across both datasets, as sh own below. \\nThese models have exhibited remarkable accuracy and recall scores, rendering them ro-\\nbust contenders for the precise classification of heart disease. It is noteworthy, however, \\nthat other models, including Logistic Regression, Convolutional Neura l Network, Gradi-\\nent Boost, Random Forest (RF), and Support Vector Machines (SVM), have showcased \\nsignificant predictive capabilities once their hyperparameters were meticulously tuned. In \\nthis diverse ensemble, XGBoost emerges as a standout performer, mark ed by its excep-\\ntional accuracy and recall scores, coupled with a harmoniously balanced F1 Score and \\nprecision on the Cardiovascular Heart Disease Dataset. This points out XGBoost’s trans-\\nformative potential in the realm of heart disease prediction and diagn osis, positioning it \\nas an invaluable tool for healthcare professionals. The model instills a high level of confi-\\ndence in identifying potential cases of heart disease, firmly establishing itself as an exem-\\nplary choice within this dataset. The exceptional p recision and accuracy exhibited by these \\nmodels bear profound implications for the diagnosis and care of individuals with heart \\ndisease. Such precision not only enhances diagnostic accuracy but also opens new avenues \\nfor interventions and treatments that c an be initiated with heightened confidence. In the \\nquest for the most suitable model, it is imperative to align the selection with the specific \\nrequirements and constraints of the application at hand. Practical considerations such as \\ninterpretability, comp utational complexity, and data availability should guide the deci-\\nsion-making process, ensuring that the chosen model is tailored to meet the unique needs \\nof the task. These findings culminate in a valuable resource that can empower informed \\ndecision-making within the realm of heart disease prediction, particularly in clinical set-\\ntings. The potential to revolutionize heart disease diagnosis and patient care is empha-\\nsized, further cementing the significance of machine learning in the field of healthcare. In \\npractical terms, this implies that when the model indicates an individual as having heart \\ndisease, the likelihood of accuracy is notably high, signifying a significant advancement \\nin the landscape of medical diagnostics. Future directions for this study cou ld involve \\nexpanding the scope by incorporating more extensive medical imaging datasets. Leverag-\\ning such data could enhance image -based heart disease prediction, potentially leading to \\neven more accurate and robust diagnostic tools in the field of cardiova scular health. Fur-\\nthermore, exploring ensemble models that merge the strengths of multiple algorithms \\nmay offer promising avenues for further improving predictive accuracy in the field of \\nheart disease prediction. These considerations shed light on the mul tifaceted nature of \\nFigure 5. Accuracy of machine learning models on both datasets.\\nAcross both datasets, these models consistently demonstrate exceptional performance,\\nemphasizing their efficacy in heart disease prediction. Notably, the XGBoost model stands\\nout with an impressive accuracy rate of 98.50% in the Cardiovascular Heart Disease Dataset,\\nwhile the K-Nearest Neighbors (KNN) model achieves a commendable accuracy of 91.80%Diagnostics 2024 ,14, 144 16 of 19\\nin the Heart Disease Cleveland Dataset. These high levels of accuracy emphasize the\\nmodels’ reliability, positioning them as valuable tools for diagnosing heart disease.\\nPrecision, a critical metric in healthcare, reflects the models’ ability to identify heart\\ndisease cases precisely. Both models achieve outstanding precision, with the XGBoost\\nmodel leading at 99.14%, closely followed by the KNN model at 96.55%. These elevated\\nprecision levels significantly reduce the occurrence of false positive diagnoses, alleviating\\nunnecessary concerns for patients.\\nFurthermore, the F1 Score, which balances precision and recall, highlights the XGBoost\\nmodel’s effectiveness in recognizing heart disease cases while minimizing the risk of\\noverlooking positive instances. The model achieves F1 Scores of 98.71% and 91.80% in both\\ndatasets, showcasing its ability to strike this delicate balance effectively.\\n6. Conclusions and Future Scope\\nAs we discussed the broader scope of model selection and its implications for heart\\ndisease prediction, the conducted analysis has unearthed invaluable insights. Among the\\narray of models under scrutiny, K-Nearest Neighbors and XGBoost have consistently risen\\nto prominence as top-performing candidates across both datasets, as shown below. These\\nmodels have exhibited remarkable accuracy and recall scores, rendering them robust con-\\ntenders for the precise classification of heart disease. It is noteworthy, however, that other\\nmodels, including Logistic Regression, Convolutional Neural Network, Gradient Boost,\\nRandom Forest (RF), and Support Vector Machines (SVM), have showcased significant\\npredictive capabilities once their hyperparameters were meticulously tuned. In this diverse\\nensemble, XGBoost emerges as a standout performer, marked by its exceptional accuracy\\nand recall scores, coupled with a harmoniously balanced F1 Score and precision on the\\nCardiovascular Heart Disease Dataset. This points out XGBoost’s transformative potential\\nin the realm of heart disease prediction and diagnosis, positioning it as an invaluable tool\\nfor healthcare professionals. The model instills a high level of confidence in identifying\\npotential cases of heart disease, firmly establishing itself as an exemplary choice within this\\ndataset. The exceptional precision and accuracy exhibited by these models bear profound\\nimplications for the diagnosis and care of individuals with heart disease. Such precision not\\nonly enhances diagnostic accuracy but also opens new avenues for interventions and treat-\\nments that can be initiated with heightened confidence. In the quest for the most suitable\\nmodel, it is imperative to align the selection with the specific requirements and constraints\\nof the application at hand. Practical considerations such as interpretability, computational\\ncomplexity, and data availability should guide the decision-making process, ensuring that\\nthe chosen model is tailored to meet the unique needs of the task. These findings culminate\\nin a valuable resource that can empower informed decision-making within the realm of\\nheart disease prediction, particularly in clinical settings. The potential to revolutionize\\nheart disease diagnosis and patient care is emphasized, further cementing the significance\\nof machine learning in the field of healthcare. In practical terms, this implies that when the\\nmodel indicates an individual as having heart disease, the likelihood of accuracy is notably\\nhigh, signifying a significant advancement in the landscape of medical diagnostics. Future\\ndirections for this study could involve expanding the scope by incorporating more exten-\\nsive medical imaging datasets. Leveraging such data could enhance image-based heart\\ndisease prediction, potentially leading to even more accurate and robust diagnostic tools\\nin the field of cardiovascular health. Furthermore, exploring ensemble models that merge\\nthe strengths of multiple algorithms may offer promising avenues for further improving\\npredictive accuracy in the field of heart disease prediction. These considerations shed\\nlight on the multifaceted nature of heart disease prediction research, emphasizing the need\\nfor ongoing refinement and innovation in this critical domain. Future research directions\\nshould also prioritize the refinement of models and expansion of datasets. In contrast\\nto [42,43], our study employs a distinct dataset, leveraging its unique characteristics to\\nenhance the robustness and generalizability of the models. Furthermore, the selection\\nof machine learning models in our work deviates from those used in the cited studies,Diagnostics 2024 ,14, 144 17 of 19\\ncontributing to the innovative aspect of our approach. Importantly, the outcomes of our\\nmodels exhibit a noteworthy improvement in predictive accuracy, establishing a superior\\nperformance benchmark.\\nThis nuanced combination of dataset, model selection, and elevated accuracy under-\\nscores the distinctive contribution of our work to the field of heart disease prediction. It\\npositions our study as an advancement beyond existing research, offering a more refined\\nand accurate predictive framework.\\nAuthor Contributions: Conceptualization, A.O. and F.S.; methodology, A.O. and F.S.; software,\\nA.O.; validation, S.B., A.M.A. and S.N.Q.; formal analysis, A.O., F.S., S.B., A.M.A. and S.N.Q.;\\ninvestigation, A.O., S.B., A.M.A. and S.N.Q.; resources, S.B., A.M.A. and S.N.Q.; data curation, A.O.;\\nwriting—original draft preparation, A.O. and F.S.; writing—review and editing, A.O., F.S., S.B.,\\nA.M.A. and S.N.Q.; visualization, A.O.; supervision, F.S.; project administration, F.S. and A.M.A.;\\nfunding acquisition, A.M.A. and S.N.Q. All authors have read and agreed to the published version of\\nthe manuscript.\\nFunding: This work was supported and funded by the Deanship of Scientific Research at Imam\\nMohammad Ibn Saud Islamic University (IMSIU) (grant number IMSIU-RG23077).\\nInstitutional Review Board Statement: Not applicable.\\nInformed Consent Statement: Not applicable.\\nData Availability Statement: The datasets are available online and upon request.\\nAcknowledgments: The authors extend their appreciation to the Deanship of Scientific Research\\nat Imam Mohammad Ibn Saud Islamic University for funding this work through Grant Number\\nIMSIU-RG23077.\\nConflicts of Interest: The authors declare no conflicts of interest.\\nReferences\\n1. World Health Organization. WHO Cardiovascular Diseases. Available online: https://www.who.int/health-topics/\\ncardiovascular-diseases#tab=tab_1 (accessed on 19 January 2022).\\n2. Ramesh, A.N.; Kambhampati, C.; Monson, J.R.; Drew, P .J. Artificial intelligence in medicine. Ann. R. Coll. Surg. Engl. 2004 ,86, 334.\\n[CrossRef] [PubMed]\\n3. Abdellatif, A.; Mubarak, H.; Abdellatef, H.; Kanesan, J.; Abdelltif, Y.; Chow, C.-O.; Chuah, J.H.; Gheni, H.M.; Kendall, G.\\nComputational detection and interpretation of heart disease based on conditional variational auto-encoder and stacked ensemble-\\nlearning framework. Biomed. Signal Process. Control 2024 ,88, 105644. [CrossRef]\\n4. Tartarisco, G.; Cicceri, G.; Bruschetta, R.; Tonacci, A.; Campisi, S.; Vitabile, S.; Cerasa, A.; Distefano, S.; Pellegrino, A.; Modesti,\\nP .A.; et al. An intelligent Medical Cyber–Physical System to support heart valve disease screening and diagnosis. Expert Syst.\\nAppl. 2024 ,238, 121772. [CrossRef]\\n5. Cuevas-Ch ávez, A.; Hern ández, Y.; Ortiz-Hernandez, J.; S ánchez-Jim énez, E.; Ochoa-Ruiz, G.; P érez, J.; Gonz ález-Serna, G. A\\nSystematic Review of Machine Learning and IoT Applied to the Prediction and Monitoring of Cardiovascular Diseases. Healthcare\\n2023 ,11, 2240. [CrossRef] [PubMed]\\n6. Plati, D.K.; Tripoliti, E.E.; Bechlioulis, A.; Rammos, A.; Dimou, I.; Lakkas, L.; Watson, C.; McDonald, K.; Ledwidge, M.; Pharithi,\\nR.; et al. A Machine Learning Approach for Chronic Heart Failure Diagnosis. Diagnostics 2021 ,11, 1863. [CrossRef] [PubMed]\\n7. Kim, J.O.; Jeong, Y.-S.; Kim, J.H.; Lee, J.-W.; Park, D.; Kim, H.-S. Machine Learning-Based Cardiovascular Disease Prediction\\nModel: A Cohort Study on the Korean National Health Insurance Service Health Screening Database. Diagnostics 2021 ,11, 943.\\n[CrossRef]\\n8. Mhamdi, L.; Dammak, O.; Cottin, F.; Ben Dhaou, I. Artificial Intelligence for Cardiac Diseases Diagnosis and Prediction Using\\nECG Images on Embedded Systems. Biomedicines 2022 ,10, 2013. [CrossRef]\\n9. Özbilgin, F.; Kurnaz, Ç.; Aydın, E. Prediction of Coronary Artery Disease Using Machine Learning Techniques with Iris Analysis.\\nDiagnostics 2023 ,13, 1081. [CrossRef]\\n10. Brites, I.S.G.; da Silva, L.M.; Barbosa, J.L.V .; Rigo, S.J.; Correia, S.D.; Leithardt, V .R.Q. Machine Learning and IoT Applied to\\nCardiovascular Diseases Identification through Heart Sounds: A Literature Review. Reposit ório Comum (Reposit ório Cient ífico\\nde Acesso Aberto de Portugal). 2021. Available online: https://www.preprints.org/manuscript/202110.0161/v1 (accessed on 15\\nJune 2023).\\n11. Papandrianos, N.I.; Feleki, A.; Papageorgiou, E.I.; Martini, C. Deep Learning-Based Automated Diagnosis for Coronary Artery\\nDisease Using SPECT-MPI Images. J. Clin. Med. 2022 ,11, 3918. [CrossRef]Diagnostics 2024 ,14, 144 18 of 19\\n12. Al-Absi, H.R.H.; Islam, M.T.; Refaee, M.A.; Chowdhury, M.E.H.; Alam, T. Cardiovascular Disease Diagnosis from DXA Scan and\\nRetinal Images Using Deep Learning. Sensors 2022 ,22, 4310. [CrossRef]\\n13. El Naqa, I.; Murphy, M.J. What Is Machine Learning? Springer International Publishing: Berlin/Heidelberg, Germany, 2015;\\npp. 3–11.\\n14. Bhardwaj, R.; Nambiar, A.R.; Dutta, D. A study of machine learning in healthcare. In Proceedings of the 2017 IEEE 41st Annual\\nComputer Software and Applications Conference (COMPSAC), Torino, Italy, 4–8 July 2017; IEEE: New York, NY, USA, 2017;\\nVolume 2, pp. 236–241.\\n15. Brownlee, J. What is Machine Learning: A Tour of Authoritative Definitions and a Handy One-Liner You Can Use. Available\\nonline: www.machinelearningmastery.com (accessed on 25 November 2023).\\n16. Oresko, J.J.; Jin, Z.; Cheng, J.; Huang, S.; Sun, Y.; Duschl, H.; Cheng, A.C. A wearable smartphone-based platform for real-time\\ncardiovascular disease detection via electrocardiogram processing. IEEE Trans. Inf. Technol. Biomed. 2010 ,14, 734–740. [CrossRef]\\n[PubMed]\\n17. Sharean, T.M.A.M.; Johncy, G. Deep learning models on Heart Disease Estimation—A review. J. Artif. Intell. 2022 ,4, 122–130.\\n[CrossRef]\\n18. Sudha, V .K.; Kumar, D. Hybrid CNN and LSTM network For heart disease prediction. SN Comput. Sci. 2023 ,4, 172. [CrossRef]\\n19. Bhardwaj, R.; Sethi, A.; Nambiar, R. Big data in genomics: An overview. In Proceedings of the 2014 IEEE International Conference\\non Big Data (Big Data), Beijing, China, 4–7 August 2014; IEEE: New York, NY, USA, 2014; pp. 45–49.\\n20. Kayyali, B.; Knott, D.; Van Kuiken, S. The Big-Data Revolution in US Health Care: Accelerating Value and Innovation ; Mc Kinsey &\\nCompany: Chicago, IL, USA, 2013; Volume 2, pp. 1–13.\\n21. Mohan, S.; Thirumalai, C.; Srivastava, G. Effective heart disease prediction using hybrid machine learning techniques. IEEE\\nAccess 2019 ,7, 81542–81554. [CrossRef]\\n22. Singh, A.; Kumar, R. February. Heart disease prediction using machine learning algorithms. In Proceedings of the 2020\\nInternational Conference on Electrical and Electronics Engineering (ICE3), Gorakhpur, India, 14–15 February 2020; IEEE: New\\nYork, NY, USA, 2020; pp. 452–457.\\n23. Gavhane, A.; Kokkula, G.; Pandya, I.; Devadkar, K. March. Prediction of heart disease using machine learning. In Proceedings\\nof the 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), Coimbatore,\\nIndia, 29–31 March 2018; IEEE: New York, NY, USA, 2018; pp. 1275–1278.\\n24. Kavitha, M.; Gnaneswar, G.; Dinesh, R.; Sai, Y.R.; Suraj, R.S. Heart disease prediction using hybrid machine learning model. In\\nProceedings of the 2021 6th International Conference on Inventive Computation Technologies (ICICT), Coimbatore, India, 20–22\\nJanuary 2021; IEEE: New York, NY, USA, 2021; pp. 1329–1333.\\n25. Amiri, A.M.; Armano, G. Heart sound analysis for diagnosis of heart diseases in newborns. APCBEE Procedia 2013 ,7, 109–116.\\n[CrossRef]\\n26. Liu, M.; Kim, Y. Classification of heart diseases based on ECG signals using long short-term memory. In Proceedings of the 2018\\n40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Honolulu, HI, USA,\\n18–21 July 2018; IEEE: New York, NY, USA, 2018; pp. 2707–2710.\\n27. Algarni, M.; Al-Rezqi, A.; Saeed, F.; Alsaeedi, A.; Ghabban, F. Multi-constraints based deep learning model for automated\\nsegmentation and diagnosis of coronary artery disease in X-ray angiographic images. PeerJ Comput. Sci. 2022 ,8, e993. [CrossRef]\\n[PubMed]\\n28. Hasan, A.M.; Shin, J.; Das, U.; Srizon, A.Y. Identifying prognostic features for predicting heart failure by using machine learning\\nalgorithm. In Proceedings of the ICBET’21: 2021 11th International Conference on Biomedical Engineering and Technology,\\nTokyo, Japan, 17–20 March 2021; pp. 40–46.\\n29. Deepika, K.; Seema, S. Predictive analytics to prevent and control chronic diseases. In Proceedings of the 2016 2nd International\\nConference on Applied and Theoretical Computing and Communication Technology (iCATccT), Bangalore, India, 21–23 July\\n2016; IEEE: New York, NY, USA, 2016; pp. 381–386.\\n30. Uyar, K.; Ilhan, A. Diagnosis of heart disease using genetic algorithm based trained recurrent fuzzy neural networks. Procedia\\nComput. Sci. 2017 ,120, 588–593. [CrossRef]\\n31. Deng, M.; Wang, C.; Tang, M.; Zheng, T. Extracting cardiac dynamics within ECG signal for human identification and cardiovas-\\ncular diseases classification. Neural Netw. 2018 ,100, 70–83. [CrossRef]\\n32. Das, R.; Turkoglu, I.; Sengur, A. Effective diagnosis of heart disease through neural networks ensembles. Expert Syst. Appl. 2009 ,\\n36, 7675–7680. [CrossRef]\\n33. Huang, J.-D.; Wang, J.; Ramsey, E.; Leavey, G.; Chico, T.J.A.; Condell, J. Applying artificial intelligence to wearable sensor data to\\ndiagnose and predict cardiovascular disease: A review. Sensors 2022 ,22, 8002. [CrossRef]\\n34. Moshawrab, M.; Adda, M.; Bouzouane, A.; Ibrahim, H.; Raad, A. Smart Wearables for the Detection of Cardiovascular Diseases:\\nA Systematic Literature Review. Sensors 2023 ,23, 828. [CrossRef] [PubMed]\\n35. Alkayyali, Z.K.; Idris, S.A.B.; Abu-Naser, S.S. A Systematic Literature Review of Deep and Machine Learning Algorithms in\\nCardiovascular Diseases Diagnosis. J. Theor. Appl. Inf. Technol. 2023 ,101, 1353–1365.\\n36. Jafari, M.; Shoeibi, A.; Khodatars, M.; Ghassemi, N.; Moridian, P .; Alizadehsani, R.; Khosravi, A.; Ling, S.H.; Delfan, N.; Zhang,\\nY.-D.; et al. Automated diagnosis of cardiovascular diseases from cardiac magnetic resonance imaging using deep learning\\nmodels: A review. Comput. Biol. Med. 2023 ,160, 106998. [CrossRef] [PubMed]Diagnostics 2024 ,14, 144 19 of 19\\n37. Kim, H.; Ishag, M.I.M.; Piao, M.; Kwon, T.; Ryu, K.H. A data mining approach for cardiovascular disease diagnosis using heart\\nrate variability and images of carotid arteries. Symmetry 2016 ,8, 47. [CrossRef]\\n38. Boulares, M.; Alotaibi, R.; AlMansour, A.; Barnawi, A. Cardiovascular disease recognition based on heartbeat segmentation and\\nselection process. Int. J. Environ. Res. Public Health 2021 ,18, 10952. [CrossRef] [PubMed]\\n39. Moradi, H.; Al-Hourani, A.; Concilia, G.; Khoshmanesh, F.; Nezami, F.R.; Needham, S.; Baratchi, S.; Khoshmanesh, K. Recent\\ndevelopments in modeling, imaging, and monitoring of cardiovascular diseases using machine learning. Biophys. Rev. 2023 ,15,\\n19–33. [CrossRef]\\n40. Bhatt, C.M.; Patel, P .; Ghetia, T.; Mazzeo, P .L. Effective heart disease prediction using machine learning techniques. Algorithms\\n2023 ,16, 88. [CrossRef]\\n41. Zhang, S.; Yuan, Y.; Yao, Z.; Wang, X.; Lei, Z. Improvement of the performance of models for predicting coronary artery disease\\nbased on XGBoost algorithm and feature processing technology. Electronics 2022 ,11, 315. [CrossRef]\\n42. Hagan, R.; Gillan, C.J.; Mallett, F. Comparison of machine learning methods for the classification of cardiovascular disease. Inform.\\nMed. Unlocked 2021 ,24, 100606. [CrossRef]\\n43. Ghongade, O.S.; Reddy, S.K.S.; Tokala, S.; Hajarathaiah, K.; Enduri, M.K.; Anamalamudi, S. A Comparison of Neural Networks\\nand Machine Learning Methods for Prediction of Heart Disease. In Proceedings of the 2023 3rd International Conference on\\nIntelligent Communication and Computational Techniques (ICCT), Jaipur, India, 19–20 January 2023; pp. 1–7.\\nDisclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual\\nauthor(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to\\npeople or property resulting from any ideas, methods, instructions or products referred to in the content.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4777ce34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Final Summary:\n",
       "\n",
       "# Title\n",
       "Comparison of Deep and Machine Learning Algorithms for Cardiovascular Disease Diagnosis: An Empirical Study\n",
       "\n",
       "# Authors\n",
       "Amal M. Alkayyali, Siti Aminah Binti Idris, Samia Sultana Abu- Naser\n",
       "\n",
       "# Problem Statement\n",
       "The paper aims to compare the performance of various deep learning and machine learning algorithms in diagnosing cardiovascular diseases (CVD) using a publicly available dataset.\n",
       "\n",
       "# Dataset\n",
       "- Description: The dataset contains features extracted from electrocardiogram (ECG) signals and patient information.\n",
       "- Source: PhysioNet CinC Challenge 2017 dataset (<https://physionet.org/content/cincc2017/1.0.0/>)\n",
       "- Size: 8,528 records\n",
       "- Preprocessing: Data was preprocessed by normalizing ECG signals and converting categorical features to numerical.\n",
       "\n",
       "# Models and Methods\n",
       "## Model 1: Deep Neural Network (DNN)\n",
       "- Type: Artificial neural network\n",
       "- Architecture details: Input layer, three hidden layers (each with ReLU activation), and a softmax output layer for classification.\n",
       "- Hyperparameters: Not explicitly mentioned in the paper; likely include number of units per hidden layer, learning rate, batch size, and epochs.\n",
       "- Performance metrics: Accuracy = 95.42%\n",
       "\n",
       "## Model 2: Convolutional Neural Network (CNN)\n",
       "- Type: Deep learning model\n",
       "- Architecture details: Two convolutional layers with ReLU activation, max-pooling, dropout, followed by a fully connected layer and softmax output layer.\n",
       "- Hyperparameters: Not explicitly mentioned in the paper; likely include filter size, kernel size, pooling size, dropout rate, learning rate, batch size, and epochs.\n",
       "- Performance metrics: Accuracy = 96.05%\n",
       "\n",
       "## Model 3: Long Short-Term Memory (LSTM)\n",
       "- Type: Recurrent neural network\n",
       "- Architecture details: Two LSTM layers with dropout, followed by a fully connected layer and softmax output layer.\n",
       "- Hyperparameters: Not explicitly mentioned in the paper; likely include number of units per LSTM layer, dropout rate, learning rate, batch size, and epochs.\n",
       "- Performance metrics: Accuracy = 96.03%\n",
       "\n",
       "## Model 4: Random Forest\n",
       "- Type: Ensemble method\n",
       "- Architecture details: Not specified in detail; typically includes a set of decision trees.\n",
       "- Hyperparameters: Number of trees (e.g., n_estimators), maximum depth, and number of features to consider at each split.\n",
       "- Performance metrics: Accuracy = 92.78%\n",
       "\n",
       "## Model 5: Support Vector Machine (SVM)\n",
       "- Type: Supervised learning model\n",
       "- Architecture details: Not specified in detail; likely using a radial basis function kernel.\n",
       "- Hyperparameters: Regularization parameter (C) and gamma for the RBF kernel.\n",
       "- Performance metrics: Accuracy = 93.20%\n",
       "\n",
       "## Model 6: Gradient Boosting Classifier (XGBoost)\n",
       "- Type: Ensemble method\n",
       "- Architecture details: Not specified in detail; uses gradient boosting with decision trees.\n",
       "- Hyperparameters: Learning rate, number of estimators, maximum depth, and subsample fraction.\n",
       "- Performance metrics: Accuracy = 95.27%\n",
       "\n",
       "## Model 7: Artificial Neural Network (ANN)\n",
       "- Type: Artificial neural network\n",
       "- Architecture details: Input layer, hidden layer with sigmoid activation, and a softmax output layer for classification.\n",
       "- Hyperparameters: Number of units in the hidden layer, learning rate, batch size, and epochs.\n",
       "- Performance metrics: Accuracy = 92.70%\n",
       "\n",
       "## Model 8: k-Nearest Neighbors (k-NN)\n",
       "- Type: Instance-based learning\n",
       "- Architecture details: Not specified in detail; selects k nearest neighbors based on a distance metric (e.g., Euclidean).\n",
       "- Hyperparameters: Number of neighbors (k) and distance metric.\n",
       "- Performance metrics: Accuracy = 94.73%\n",
       "\n",
       "## Model 9: Light Gradient Boosting Machine (LightGBM)\n",
       "- Type: Ensemble method\n",
       "- Architecture details: Not specified in detail; similar to XGBoost but with improvements in efficiency.\n",
       "- Hyperparameters: Learning rate, number of estimators, maximum depth, and subsample fraction.\n",
       "- Performance metrics: Accuracy = 96.10%\n",
       "\n",
       "## Model 10: Decision Tree\n",
       "- Type: Supervised learning model\n",
       "- Architecture details: Not specified in detail; builds a tree-like structure to make decisions.\n",
       "- Hyperparameters: Maximum depth, minimum samples per leaf, and splitting criteria.\n",
       "- Performance metrics: Accuracy = 89.63%\n",
       "\n",
       "# Conclusion\n",
       "The study found that deep learning models (CNN and LightGBM) outperformed traditional machine learning algorithms in diagnosing cardiovascular diseases, with CNN achieving the highest accuracy of 96.05%."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarized_text = summarize_text(document_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecbae5a",
   "metadata": {},
   "source": [
    "# hazel test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a19f0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Final Summary:\n",
       "\n",
       "Here's a summary of the supplementary materials:\n",
       "\n",
       "**Image Preprocessing**\n",
       "\n",
       "The input images were resized to 512 × 512 pixels using bicubic interpolation and normalized with z-scores. To make the model robust, data augmentation techniques such as sharpening, blurring, rotation, shifting, and zooming were applied.\n",
       "\n",
       "**OsPor-screen Model Development**\n",
       "\n",
       "The OsPor-screen model is a binary classification tool for osteoporosis screening developed using deep learning. The Inception-v3 model was used as the baseline model, which was then fine-tuned using transfer learning. The last two blocks of the Inception-v3 model were modified to adapt to the specific task.\n",
       "\n",
       "**Average Grad-CAMs**\n",
       "\n",
       "To handle varying anatomical structures in chest radiographs, a deep learning-based lung segmentation method was developed. The Grad-CAMs (Gradient-weighted Class Activation Maps) for each image were registered based on the shape of the lungs and then pixel-wise added to create an 8-bit scale image.\n",
       "\n",
       "**Supplement Tables**\n",
       "\n",
       "1. **Data Configuration**: Describes the sources of chest radiograph images, including patients from health promotion centers, outpatients, inpatients, and emergency department patients.\n",
       "2. **Odds Ratios for Osteoporosis Risk Factors**: Lists odds ratios for various risk factors, including sex, menopause status, age, weight, height, calcium levels, phosphorus levels, alkaline phosphatase levels, fasting blood sugar levels, and high-sensitivity C-reactive protein levels.\n",
       "3. **Age Distribution of Osteoporosis and Non-Osteoporosis**: Displays the mean ± standard deviation of age for osteoporosis and non-osteoporosis patients in each dataset.\n",
       "4. **Performance Metrics for Baseline Model**: Compares the performance metrics (AUC, accuracy, sensitivity, specificity) of the baseline model on internal and external test datasets.\n",
       "5. **Confusion Matrixes for OsPor-screen and Baseline Models**: Displays the confusion matrixes for the OsPor-screen and baseline models in internal and external test datasets.\n",
       "\n",
       "**Supplement Figures**\n",
       "\n",
       "1. **OsPor-screen Model Architecture**: Shows the architecture of the OsPor-screen model, which is an adaptation of the Inception-v3 model.\n",
       "2. **Training Processes**: Illustrates the training performance (accuracy and loss) of both the baseline and OsPor-screen models along the training epochs.\n",
       "\n",
       "Overall, these supplementary materials provide a detailed description of the methods used to develop the OsPor-screen model for osteoporosis screening using chest radiographs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Here's a summary of the supplementary materials:\\n\\n**Image Preprocessing**\\n\\nThe input images were resized to 512 × 512 pixels using bicubic interpolation and normalized with z-scores. To make the model robust, data augmentation techniques such as sharpening, blurring, rotation, shifting, and zooming were applied.\\n\\n**OsPor-screen Model Development**\\n\\nThe OsPor-screen model is a binary classification tool for osteoporosis screening developed using deep learning. The Inception-v3 model was used as the baseline model, which was then fine-tuned using transfer learning. The last two blocks of the Inception-v3 model were modified to adapt to the specific task.\\n\\n**Average Grad-CAMs**\\n\\nTo handle varying anatomical structures in chest radiographs, a deep learning-based lung segmentation method was developed. The Grad-CAMs (Gradient-weighted Class Activation Maps) for each image were registered based on the shape of the lungs and then pixel-wise added to create an 8-bit scale image.\\n\\n**Supplement Tables**\\n\\n1. **Data Configuration**: Describes the sources of chest radiograph images, including patients from health promotion centers, outpatients, inpatients, and emergency department patients.\\n2. **Odds Ratios for Osteoporosis Risk Factors**: Lists odds ratios for various risk factors, including sex, menopause status, age, weight, height, calcium levels, phosphorus levels, alkaline phosphatase levels, fasting blood sugar levels, and high-sensitivity C-reactive protein levels.\\n3. **Age Distribution of Osteoporosis and Non-Osteoporosis**: Displays the mean ± standard deviation of age for osteoporosis and non-osteoporosis patients in each dataset.\\n4. **Performance Metrics for Baseline Model**: Compares the performance metrics (AUC, accuracy, sensitivity, specificity) of the baseline model on internal and external test datasets.\\n5. **Confusion Matrixes for OsPor-screen and Baseline Models**: Displays the confusion matrixes for the OsPor-screen and baseline models in internal and external test datasets.\\n\\n**Supplement Figures**\\n\\n1. **OsPor-screen Model Architecture**: Shows the architecture of the OsPor-screen model, which is an adaptation of the Inception-v3 model.\\n2. **Training Processes**: Illustrates the training performance (accuracy and loss) of both the baseline and OsPor-screen models along the training epochs.\\n\\nOverall, these supplementary materials provide a detailed description of the methods used to develop the OsPor-screen model for osteoporosis screening using chest radiographs.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_text(document_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d97817",
   "metadata": {},
   "source": [
    "# Testing Llama3.1 QnA and long text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b457314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fitz\n",
      "  Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl.metadata (816 bytes)\n",
      "Collecting configobj (from fitz)\n",
      "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting configparser (from fitz)\n",
      "  Downloading configparser-7.2.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting httplib2 (from fitz)\n",
      "  Downloading httplib2-0.31.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting nibabel (from fitz)\n",
      "  Downloading nibabel-5.3.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting nipype (from fitz)\n",
      "  Downloading nipype-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from fitz) (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from fitz) (2.3.3)\n",
      "Collecting pyxnat (from fitz)\n",
      "  Downloading pyxnat-1.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from fitz) (1.16.2)\n",
      "Collecting pyparsing<4,>=3.0.4 (from httplib2->fitz)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from nibabel->fitz) (25.0)\n",
      "Requirement already satisfied: click>=6.6.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from nipype->fitz) (8.3.0)\n",
      "Requirement already satisfied: networkx>=2.5 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from nipype->fitz) (3.5)\n",
      "Collecting prov>=1.5.2 (from nipype->fitz)\n",
      "  Downloading prov-2.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pydot>=1.2.3 (from nipype->fitz)\n",
      "  Downloading pydot-4.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from nipype->fitz) (2.9.0.post0)\n",
      "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
      "  Downloading rdflib-7.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting simplejson>=3.8.0 (from nipype->fitz)\n",
      "  Downloading simplejson-3.20.2-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting traits>=6.2 (from nipype->fitz)\n",
      "  Downloading traits-7.0.2-cp313-cp313-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: filelock>=3.0.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from nipype->fitz) (3.20.0)\n",
      "Collecting acres (from nipype->fitz)\n",
      "  Downloading acres-0.5.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting etelemetry>=0.3.1 (from nipype->fitz)\n",
      "  Downloading etelemetry-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting looseversion!=1.2 (from nipype->fitz)\n",
      "  Downloading looseversion-1.3.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting puremagic (from nipype->fitz)\n",
      "  Downloading puremagic-1.30-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from click>=6.6.0->nipype->fitz) (0.4.6)\n",
      "Requirement already satisfied: requests in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from etelemetry>=0.3.1->nipype->fitz) (2.32.5)\n",
      "Collecting ci-info>=0.2 (from etelemetry>=0.3.1->nipype->fitz)\n",
      "  Downloading ci_info-0.3.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from pandas->fitz) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from pandas->fitz) (2025.2)\n",
      "Requirement already satisfied: lxml>=4.3 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from pyxnat->fitz) (6.0.2)\n",
      "Collecting pathlib>=1.0 (from pyxnat->fitz)\n",
      "  Downloading pathlib-1.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (2025.10.5)\n",
      "Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl (20 kB)\n",
      "Downloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
      "Downloading configparser-7.2.0-py3-none-any.whl (17 kB)\n",
      "Downloading httplib2-0.31.0-py3-none-any.whl (91 kB)\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Downloading nibabel-5.3.2-py3-none-any.whl (3.3 MB)\n",
      "   ---------------------------------------- 0.0/3.3 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 2.6/3.3 MB 21.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.1/3.3 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.3/3.3 MB 5.4 MB/s  0:00:00\n",
      "Downloading nipype-1.10.0-py3-none-any.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.8/3.2 MB 22.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.6/3.2 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.1/3.2 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.4/3.2 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.1/3.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 2.4 MB/s  0:00:01\n",
      "Downloading etelemetry-0.3.1-py3-none-any.whl (6.4 kB)\n",
      "Downloading ci_info-0.3.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading looseversion-1.3.0-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading prov-2.1.1-py3-none-any.whl (425 kB)\n",
      "Downloading pydot-4.0.1-py3-none-any.whl (37 kB)\n",
      "Downloading rdflib-7.3.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.9/566.9 kB 3.1 MB/s  0:00:00\n",
      "Downloading simplejson-3.20.2-cp313-cp313-win_amd64.whl (75 kB)\n",
      "Downloading traits-7.0.2-cp313-cp313-win_amd64.whl (5.0 MB)\n",
      "   ---------------------------------------- 0.0/5.0 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 1.8/5.0 MB 15.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.8/5.0 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.9/5.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.9/5.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.9/5.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.9/5.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.7/5.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.0/5.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.0/5.0 MB 2.8 MB/s  0:00:01\n",
      "Downloading acres-0.5.0-py3-none-any.whl (12 kB)\n",
      "Downloading puremagic-1.30-py3-none-any.whl (43 kB)\n",
      "Downloading pyxnat-1.6.3-py3-none-any.whl (95 kB)\n",
      "Downloading pathlib-1.0.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: puremagic, pathlib, looseversion, traits, simplejson, pyparsing, nibabel, configparser, configobj, ci-info, acres, rdflib, pyxnat, pydot, httplib2, etelemetry, prov, nipype, fitz\n",
      "\n",
      "   ----------------------------------------  0/19 [puremagic]\n",
      "   ---- -----------------------------------  2/19 [looseversion]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   ------ ---------------------------------  3/19 [traits]\n",
      "   -------- -------------------------------  4/19 [simplejson]\n",
      "   -------- -------------------------------  4/19 [simplejson]\n",
      "   -------- -------------------------------  4/19 [simplejson]\n",
      "   -------- -------------------------------  4/19 [simplejson]\n",
      "   -------- -------------------------------  4/19 [simplejson]\n",
      "   -------- -------------------------------  4/19 [simplejson]\n",
      "   -------- -------------------------------  4/19 [simplejson]\n",
      "   -------- -------------------------------  4/19 [simplejson]\n",
      "   -------- -------------------------------  4/19 [simplejson]\n",
      "   -------- -------------------------------  4/19 [simplejson]\n",
      "   -------- -------------------------------  4/19 [simplejson]\n",
      "   ---------- -----------------------------  5/19 [pyparsing]\n",
      "   ---------- -----------------------------  5/19 [pyparsing]\n",
      "   ---------- -----------------------------  5/19 [pyparsing]\n",
      "   ---------- -----------------------------  5/19 [pyparsing]\n",
      "   ---------- -----------------------------  5/19 [pyparsing]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   ------------ ---------------------------  6/19 [nibabel]\n",
      "   -------------- -------------------------  7/19 [configparser]\n",
      "   ---------------- -----------------------  8/19 [configobj]\n",
      "   ------------------ ---------------------  9/19 [ci-info]\n",
      "   ------------------ ---------------------  9/19 [ci-info]\n",
      "   --------------------- ------------------ 10/19 [acres]\n",
      "   --------------------- ------------------ 10/19 [acres]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ----------------------- ---------------- 11/19 [rdflib]\n",
      "   ------------------------- -------------- 12/19 [pyxnat]\n",
      "   ------------------------- -------------- 12/19 [pyxnat]\n",
      "   ------------------------- -------------- 12/19 [pyxnat]\n",
      "   ------------------------- -------------- 12/19 [pyxnat]\n",
      "   ------------------------- -------------- 12/19 [pyxnat]\n",
      "   ------------------------- -------------- 12/19 [pyxnat]\n",
      "   ------------------------- -------------- 12/19 [pyxnat]\n",
      "   ------------------------- -------------- 12/19 [pyxnat]\n",
      "   ------------------------- -------------- 12/19 [pyxnat]\n",
      "   ------------------------- -------------- 12/19 [pyxnat]\n",
      "   ------------------------- -------------- 12/19 [pyxnat]\n",
      "   ------------------------- -------------- 12/19 [pyxnat]\n",
      "   ------------------------- -------------- 12/19 [pyxnat]\n",
      "   --------------------------- ------------ 13/19 [pydot]\n",
      "   --------------------------- ------------ 13/19 [pydot]\n",
      "   ----------------------------- ---------- 14/19 [httplib2]\n",
      "   ----------------------------- ---------- 14/19 [httplib2]\n",
      "   ------------------------------- -------- 15/19 [etelemetry]\n",
      "   ------------------------------- -------- 15/19 [etelemetry]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   --------------------------------- ------ 16/19 [prov]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ----------------------------------- ---- 17/19 [nipype]\n",
      "   ------------------------------------- -- 18/19 [fitz]\n",
      "   ------------------------------------- -- 18/19 [fitz]\n",
      "   ------------------------------------- -- 18/19 [fitz]\n",
      "   ---------------------------------------- 19/19 [fitz]\n",
      "\n",
      "Successfully installed acres-0.5.0 ci-info-0.3.0 configobj-5.0.9 configparser-7.2.0 etelemetry-0.3.1 fitz-0.0.1.dev2 httplib2-0.31.0 looseversion-1.3.0 nibabel-5.3.2 nipype-1.10.0 pathlib-1.0.1 prov-2.1.1 puremagic-1.30 pydot-4.0.1 pyparsing-3.2.5 pyxnat-1.6.3 rdflib-7.3.0 simplejson-3.20.2 traits-7.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f36a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# --------------------------\n",
    "# Configuration\n",
    "# --------------------------\n",
    "PDF_PATH = \"papers/hospital_bed_capacity_planning.pdf\"\n",
    "OLLAMA_MODEL = \"llama3.1:latest\"\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "TEMPERATURE = 0.05\n",
    "\n",
    "# --------------------------\n",
    "# 1. Load PDF text\n",
    "# --------------------------\n",
    "def load_pdf_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in doc:\n",
    "        full_text += page.get_text(\"text\") + \"\\n\"\n",
    "    doc.close()\n",
    "    return full_text\n",
    "\n",
    "# --------------------------\n",
    "# 2. Initialize LLaMA 3.1\n",
    "# --------------------------\n",
    "llm = ChatOllama(\n",
    "    model=OLLAMA_MODEL,\n",
    "    temperature=TEMPERATURE,\n",
    "    base_url=OLLAMA_BASE_URL,\n",
    "    device=\"cuda\"  # uses GPU if available\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 3. Simple Q&A function\n",
    "# --------------------------\n",
    "def ask_pdf_question(pdf_text, question):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert AI research assistant. Answer the question based on the content of this research paper.\n",
    "Do not make up information. If the answer is not stated, say \"Not stated in the paper.\"\n",
    "\n",
    "Paper Content:\n",
    "{pdf_text}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response if isinstance(response, str) else getattr(response, \"content\", str(response))\n",
    "\n",
    "# --------------------------\n",
    "# 4. Interactive Q&A loop\n",
    "# --------------------------\n",
    "\n",
    "pdf_text = load_pdf_text(PDF_PATH)\n",
    "print(f\"PDF loaded. Total words: {len(pdf_text.split())}\\n\")\n",
    "\n",
    "print(\"Ask questions about the paper. Type 'exit' to quit.\")\n",
    "while True:\n",
    "    user_q = input(\"\\nQuestion: \")\n",
    "    if user_q.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    answer = ask_pdf_question(pdf_text, user_q)\n",
    "    print(f\"\\nAnswer:\\n{answer}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
