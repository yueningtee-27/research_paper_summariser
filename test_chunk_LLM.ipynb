{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece3d569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading PDF: papers/ml_model_cardio_disease_detection.pdf\n",
      "[INFO] Loaded 19 pages (71347 characters)\n",
      "[INFO] Detected 60 section(s): ['Abstract', 'Methods', 'Results', 'Introduction', 'Methods', 'Methods', 'Background', 'Methods', 'Result', 'Results', 'Method', 'Results', 'Results', 'Methods', 'Methods', 'Method', 'Results', 'Background', 'Methods', 'Methods', 'Results', 'Methods', 'Methods', 'Methods', 'Experiments', 'Methods', 'Methods', 'Method', 'Experiments', 'Methods', 'Methods', 'Method', 'Method', 'Method', 'Result', 'Results', 'Methods', 'Conclusion', 'Results', 'Results', 'Results', 'Results', 'Results', 'Results', 'Results', 'Results', 'Results', 'Results', 'Results', 'Results', 'Results', 'Results', 'Results', 'Results', 'Discussion', 'Results', 'Methodology', 'Methods', 'Methods', 'Methods']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# 🧠 Step 1: Setup Model\n",
    "# -----------------------------\n",
    "llm = ChatOllama(model=\"qwen2.5:7b\", temperature=0.2)\n",
    "\n",
    "# -----------------------------\n",
    "# 📄 Step 2: Load PDF\n",
    "# -----------------------------\n",
    "pdf_path = \"papers/ml_model_cardio_disease_detection.pdf\"\n",
    "print(f\"[INFO] Loading PDF: {pdf_path}\")\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "full_text = \"\\n\".join([d.page_content for d in docs])\n",
    "print(f\"[INFO] Loaded {len(docs)} pages ({len(full_text)} characters)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 🧩 Step 3: Detect Sections\n",
    "# -----------------------------\n",
    "\n",
    "SECTION_PATTERNS = [\n",
    "    r\"abstract\",\n",
    "    r\"introduction\",\n",
    "    r\"related work\",\n",
    "    r\"background\",\n",
    "    r\"methods?\",\n",
    "    r\"methodology\",\n",
    "    r\"experiments?\",\n",
    "    r\"results?\",\n",
    "    r\"discussion\",\n",
    "    r\"conclusion\",\n",
    "]\n",
    "\n",
    "def split_by_sections(text):\n",
    "    # Apply the case-insensitive flag globally at the start\n",
    "    pattern = r\"(?i)\\b(\" + \"|\".join(SECTION_PATTERNS) + r\")\\b\"\n",
    "    \n",
    "    matches = list(re.finditer(pattern, text))\n",
    "    sections = []\n",
    "\n",
    "    if not matches:\n",
    "        sections.append({\"section_name\": \"Full Paper\", \"content\": text})\n",
    "        return sections\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        start = match.end()\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "        section_name = match.group(1).strip().title()\n",
    "        sections.append({\n",
    "            \"section_name\": section_name,\n",
    "            \"content\": text[start:end].strip()\n",
    "        })\n",
    "\n",
    "    return sections\n",
    "\n",
    "sections = split_by_sections(full_text)\n",
    "print(f\"[INFO] Detected {len(sections)} section(s): {[s['section_name'] for s in sections]}\")\n",
    "\n",
    "# # -----------------------------\n",
    "# # 🧠 Step 4: Define Summarization Prompt\n",
    "# # -----------------------------\n",
    "# section_prompt = PromptTemplate.from_template(\"\"\"\n",
    "# You are an AI research assistant.\n",
    "# Summarize the following section of a scientific paper.\n",
    "\n",
    "# Focus on:\n",
    "# - Key ideas and objectives\n",
    "# - Data and methods used\n",
    "# - Metrics and results\n",
    "# - Limitations if any\n",
    "\n",
    "# Section Name: {section_name}\n",
    "# Section Text:\n",
    "# {context}\n",
    "\n",
    "# Output format:\n",
    "# ## {section_name}\n",
    "# <concise academic summary>\n",
    "# \"\"\")\n",
    "\n",
    "# # -----------------------------\n",
    "# # 🧮 Step 5: Summarize Each Section\n",
    "# # -----------------------------\n",
    "# summaries = []\n",
    "# for sec in tqdm(sections, desc=\"Summarizing sections\"):\n",
    "#     prompt_filled = section_prompt.format(\n",
    "#         section_name=sec[\"section_name\"],\n",
    "#         context=sec[\"content\"][:6000]  # truncate to stay within context limits\n",
    "#     )\n",
    "#     summary = llm.invoke(prompt_filled)\n",
    "#     summaries.append(f\"## {sec['section_name']}\\n{summary.strip()}\\n\")\n",
    "#     print(f\"\\n[DEBUG] Finished summarizing section: {sec['section_name']}\")\n",
    "\n",
    "# # -----------------------------\n",
    "# # 🧩 Step 6: Combine into Final Structured Summary\n",
    "# # -----------------------------\n",
    "# final_summary = \"# Research Paper Summary\\n\\n\" + \"\\n\".join(summaries)\n",
    "\n",
    "# # Save output\n",
    "# output_path = \"outputs/structured_summary.md\"\n",
    "# import os\n",
    "# os.makedirs(\"outputs\", exist_ok=True)\n",
    "# with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(final_summary)\n",
    "\n",
    "# print(f\"\\n✅ Structured summary saved to: {output_path}\")\n",
    "# print(\"\\n--- Preview ---\")\n",
    "# print(\"\\n\".join(final_summary.splitlines()[:30]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6da772",
   "metadata": {},
   "source": [
    "# trial 2 \n",
    "RAG FOR STRUCTURED SECTION SUMMARIES \n",
    "- ingest pDF into a vector database for easy section text retrieval \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d71babd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:19: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\Yue Ning\\AppData\\Local\\Temp\\ipykernel_42724\\3333503276.py:19: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  chunks = load_and_chunk_pdf(\"papers\\ml_model_cardio_disease_detection.pdf\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from tiktoken import get_encoding\n",
    "\n",
    "def load_and_chunk_pdf(pdf_path, chunk_size=2500, overlap=200):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()\n",
    "    full_text = \"\\n\".join([p.page_content for p in pages])\n",
    "    \n",
    "    enc = get_encoding(\"cl100k_base\")\n",
    "    tokens = enc.encode(full_text)\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size - overlap):\n",
    "        chunk_text = enc.decode(tokens[i:i + chunk_size])\n",
    "        chunks.append(chunk_text)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "chunks = load_and_chunk_pdf(\"papers\\ml_model_cardio_disease_detection.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13265a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks) # 8 chunks of chunk size 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32fbcade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' implies that when the model indicates an individual as having heart \\ndisease, the likelihood of accuracy is notably high, signifying a significant advancement \\nin the landscape of medical diagnostics. Future directions for this study cou ld involve \\nexpanding the scope by incorporating more extensive medical imaging datasets. Leverag-\\ning such data could enhance image-based heart disease prediction, potentially leading to \\neven more accurate and robust diagnostic tools in the field of cardiovascular health. Fur-\\nthermore, exploring ensemble models that merge the strengths of multiple algorithms \\nmay offer promising avenues for further improving predictive accuracy in the field of \\nheart disease prediction. These considerations shed light on the mul tifaceted nature of \\nFigure 5. Accuracy of machine learning models on both datasets.\\nAcross both datasets, these models consistently demonstrate exceptional performance,\\nemphasizing their efficacy in heart disease prediction. Notably, the XGBoost model stands\\nout with an impressive accuracy rate of 98.50% in the Cardiovascular Heart Disease Dataset,\\nwhile the K-Nearest Neighbors (KNN) model achieves a commendable accuracy of 91.80%\\nDiagnostics 2024, 14, 144 16 of 19\\nin the Heart Disease Cleveland Dataset. These high levels of accuracy emphasize the\\nmodels’ reliability, positioning them as valuable tools for diagnosing heart disease.\\nPrecision, a critical metric in healthcare, reflects the models’ ability to identify heart\\ndisease cases precisely. Both models achieve outstanding precision, with the XGBoost\\nmodel leading at 99.14%, closely followed by the KNN model at 96.55%. These elevated\\nprecision levels significantly reduce the occurrence of false positive diagnoses, alleviating\\nunnecessary concerns for patients.\\nFurthermore, the F1 Score, which balances precision and recall, highlights the XGBoost\\nmodel’s effectiveness in recognizing heart disease cases while minimizing the risk of\\noverlooking positive instances. The model achieves F1 Scores of 98.71% and 91.80% in both\\ndatasets, showcasing its ability to strike this delicate balance effectively.\\n6. Conclusions and Future Scope\\nAs we discussed the broader scope of model selection and its implications for heart\\ndisease prediction, the conducted analysis has unearthed invaluable insights. Among the\\narray of models under scrutiny, K-Nearest Neighbors and XGBoost have consistently risen\\nto prominence as top-performing candidates across both datasets, as shown below. These\\nmodels have exhibited remarkable accuracy and recall scores, rendering them robust con-\\ntenders for the precise classification of heart disease. It is noteworthy, however, that other\\nmodels, including Logistic Regression, Convolutional Neural Network, Gradient Boost,\\nRandom Forest (RF), and Support Vector Machines (SVM), have showcased significant\\npredictive capabilities once their hyperparameters were meticulously tuned. In this diverse\\nensemble, XGBoost emerges as a standout performer, marked by its exceptional accuracy\\nand recall scores, coupled with a harmoniously balanced F1 Score and precision on the\\nCardiovascular Heart Disease Dataset. This points out XGBoost’s transformative potential\\nin the realm of heart disease prediction and diagnosis, positioning it as an invaluable tool\\nfor healthcare professionals. The model instills a high level of confidence in identifying\\npotential cases of heart disease, firmly establishing itself as an exemplary choice within this\\ndataset. The exceptional precision and accuracy exhibited by these models bear profound\\nimplications for the diagnosis and care of individuals with heart disease. Such precision not\\nonly enhances diagnostic accuracy but also opens new avenues for interventions and treat-\\nments that can be initiated with heightened confidence. In the quest for the most suitable\\nmodel, it is imperative to align the selection with the specific requirements and constraints\\nof the application at hand. Practical considerations such as interpretability, computational\\ncomplexity, and data availability should guide the decision-making process, ensuring that\\nthe chosen model is tailored to meet the unique needs of the task. These findings culminate\\nin a valuable resource that can empower informed decision-making within the realm of\\nheart disease prediction, particularly in clinical settings. The potential to revolutionize\\nheart disease diagnosis and patient care is emphasized, further cementing the significance\\nof machine learning in the field of healthcare. In practical terms, this implies that when the\\nmodel indicates an individual as having heart disease, the likelihood of accuracy is notably\\nhigh, signifying a significant advancement in the landscape of medical diagnostics. Future\\ndirections for this study could involve expanding the scope by incorporating more exten-\\nsive medical imaging datasets. Leveraging such data could enhance image-based heart\\ndisease prediction, potentially leading to even more accurate and robust diagnostic tools\\nin the field of cardiovascular health. Furthermore, exploring ensemble models that merge\\nthe strengths of multiple algorithms may offer promising avenues for further improving\\npredictive accuracy in the field of heart disease prediction. These considerations shed\\nlight on the multifaceted nature of heart disease prediction research, emphasizing the need\\nfor ongoing refinement and innovation in this critical domain. Future research directions\\nshould also prioritize the refinement of models and expansion of datasets. In contrast\\nto [42,43], our study employs a distinct dataset, leveraging its unique characteristics to\\nenhance the robustness and generalizability of the models. Furthermore, the selection\\nof machine learning models in our work deviates from those used in the cited studies,\\nDiagnostics 2024, 14, 144 17 of 19\\ncontributing to the innovative aspect of our approach. Importantly, the outcomes of our\\nmodels exhibit a noteworthy improvement in predictive accuracy, establishing a superior\\nperformance benchmark.\\nThis nuanced combination of dataset, model selection, and elevated accuracy under-\\nscores the distinctive contribution of our work to the field of heart disease prediction. It\\npositions our study as an advancement beyond existing research, offering a more refined\\nand accurate predictive framework.\\nAuthor Contributions: Conceptualization, A.O. and F.S.; methodology, A.O. and F.S.; software,\\nA.O.; validation, S.B., A.M.A. and S.N.Q.; formal analysis, A.O., F.S., S.B., A.M.A. and S.N.Q.;\\ninvestigation, A.O., S.B., A.M.A. and S.N.Q.; resources, S.B., A.M.A. and S.N.Q.; data curation, A.O.;\\nwriting—original draft preparation, A.O. and F.S.; writing—review and editing, A.O., F.S., S.B.,\\nA.M.A. and S.N.Q.; visualization, A.O.; supervision, F.S.; project administration, F.S. and A.M.A.;\\nfunding acquisition, A.M.A. and S.N.Q. All authors have read and agreed to the published version of\\nthe manuscript.\\nFunding: This work was supported and funded by the Deanship of Scientific Research at Imam\\nMohammad Ibn Saud Islamic University (IMSIU) (grant number IMSIU-RG23077).\\nInstitutional Review Board Statement: Not applicable.\\nInformed Consent Statement: Not applicable.\\nData Availability Statement: The datasets are available online and upon request.\\nAcknowledgments: The authors extend their appreciation to the Deanship of Scientific Research\\nat Imam Mohammad Ibn Saud Islamic University for funding this work through Grant Number\\nIMSIU-RG23077.\\nConflicts of Interest: The authors declare no conflicts of interest.\\nReferences\\n1. World Health Organization. WHO Cardiovascular Diseases. Available online: https://www.who.int/health-topics/\\ncardiovascular-diseases#tab=tab_1 (accessed on 19 January 2022).\\n2. Ramesh, A.N.; Kambhampati, C.; Monson, J.R.; Drew, P .J. Artificial intelligence in medicine.Ann. R. Coll. Surg. Engl.2004, 86, 334.\\n[CrossRef] [PubMed]\\n3. Abdellatif, A.; Mubarak, H.; Abdellatef, H.; Kanesan, J.; Abdelltif, Y.; Chow, C.-O.; Chuah, J.H.; Gheni, H.M.; Kendall, G.\\nComputational detection and interpretation of heart disease based on conditional variational auto-encoder and stacked ensemble-\\nlearning framework. Biomed. Signal Process. Control2024, 88, 105644. [CrossRef]\\n4. Tartarisco, G.; Cicceri, G.; Bruschetta, R.; Tonacci, A.; Campisi, S.; Vitabile, S.; Cerasa, A.; Distefano, S.; Pellegrino, A.; Modesti,\\nP .A.; et al. An intelligent Medical Cyber–Physical System to support heart valve disease screening and diagnosis.Expert Syst.\\nAppl. 2024, 238, 121772. [CrossRef]\\n5. Cuevas-Chávez, A.; Hernández, Y.; Ortiz-Hernandez, J.; Sánchez-Jiménez, E.; Ochoa-Ruiz, G.; Pérez, J.; González-Serna, G. A\\nSystematic Review of Machine Learning and IoT Applied to the Prediction and Monitoring of Cardiovascular Diseases. Healthcare\\n2023, 11, 2240. [CrossRef] [PubMed]\\n6. Plati, D.K.; Tripoliti, E.E.; Bechlioulis, A.; Rammos, A.; Dimou, I.; Lakkas, L.; Watson, C.; McDonald, K.; Ledwidge, M.; Pharithi,\\nR.; et al. A Machine Learning Approach for Chronic Heart Failure Diagnosis. Diagnostics 2021, 11, 1863. [CrossRef] [PubMed]\\n7. Kim, J.O.; Jeong, Y.-S.; Kim, J.H.; Lee, J.-W.; Park, D.; Kim, H.-S. Machine Learning-Based Cardiovascular Disease Prediction\\nModel: A Cohort Study on the Korean National Health Insurance Service Health Screening Database. Diagnostics 2021, 11, 943.\\n[CrossRef]\\n8. Mhamdi, L.; Dammak, O.; Cottin, F.; Ben Dhaou, I. Artificial Intelligence for Cardiac Diseases Diagnosis and Prediction Using\\nECG Images on Embedded Systems. Biomedicines 2022, 10, 2013. [CrossRef]\\n9. Özbilgin, F.; Kurnaz, Ç.; Aydın, E. Prediction of Coronary Artery Disease Using Machine Learning Techniques with Iris Analysis.\\nDiagnostics 2023, 13, 1081. [CrossRef]\\n10. Brites, I.S.G.; da Silva, L.M.; Barbosa, J.L.V .; Rigo, S.J.; Correia, S.D.; Leithardt, V .R.Q. Machine Learning and IoT Applied to\\nCardiovascular Diseases Identification through Heart Sounds: A Literature Review. Repositório Comum (Repositório Científico\\nde Acesso Aberto de Portugal). 2021. Available online: https://www.preprints.org/manuscript/202110.0161/v1 (accessed on 15\\nJune 2023).\\n11. Papandrianos, N.I.; Feleki, A.; Papageorgiou, E.I.; Martini, C. Deep Learning-Based Automated Diagnosis for Coronary Artery\\nDisease Using SPECT-MPI Images. J. Clin. Med.2022, 11, 3918. [CrossRef]\\nDiagnostics 2024, 14, 144 18 of 19\\n12. Al-Absi, H.R.H.; Islam, M.T.; Refaee, M.A.; Chowdhury, M.E.H.; Alam, T. Cardiovascular Disease Diagnosis from DXA Scan and\\nRetinal Images Using Deep Learning. Sensors 2022, 22, 4310. [CrossRef]\\n13. El Naqa, I.; Murphy, M.J. What Is Machine Learning?Springer International Publishing: Berlin/Heidelberg,'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7271da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from sentence-transformers) (2.9.0+cu128)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.7.2-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yue ning\\desktop\\misclearning\\ai_researcher_database\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.5)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Using cached scikit_learn-1.7.2-cp313-cp313-win_amd64.whl (8.7 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached scipy-1.16.2-cp313-cp313-win_amd64.whl (38.5 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sentence-transformers\n",
      "\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence-transformers]\n",
      "   ---------------------------------------- 5/5 [sentence-transformers]\n",
      "\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 sentence-transformers-5.1.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f11d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load embedding model (local, free)\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed_chunks(chunks):\n",
    "    embeddings = embed_model.encode(chunks, convert_to_numpy=True)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "embeddings = embed_chunks(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51104ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install faiss-cpu\n",
    "import faiss\n",
    "\n",
    "def create_faiss_index(embeddings):\n",
    "    dimension = embeddings.shape[1] # Get dimensionality of embedding\n",
    "    index = faiss.IndexFlatL2(dimension) # Create index that uses Euclidean distance \n",
    "    index.add(embeddings) # Add precomputed embeddings (one per PDF chunk) into index\n",
    "    return index \n",
    "\n",
    "index = create_faiss_index(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a52730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_queries = {\n",
    "    \"Problem Statement\": \"What research problem does this paper address?\",\n",
    "    \"Dataset\": \"Which datasets are used in the experiments?\",\n",
    "    \"Methodology\": \"Describe the model or methods used.\",\n",
    "    \"Evaluation\": \"List the metrics and results of the models tested.\",\n",
    "    \"Limitations\": \"What are the limitations mentioned?\",\n",
    "    \"Future Work\": \"What future work is proposed?\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7292cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(query, index, chunks, top_k=3):\n",
    "    query_emb = embed_model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_emb, top_k) # gives top 3 most similar chunks (lowest L2 distance)\n",
    "    print(f\"Retrieved indices: {indices}\")\n",
    "    retrieved_texts = [chunks[i] for i in indices[0]]\n",
    "    return retrieved_texts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dff019ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# 🧠 Step 1: Setup Model\n",
    "# -----------------------------\n",
    "llm = ChatOllama(model=\"qwen:32b\", temperature=0.2)\n",
    "\n",
    "\n",
    "llm_section_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an AI research assistant.\n",
    "\n",
    "From the following text, generate a concise, structured summary for the section: {section_name}\n",
    "\n",
    "Text:\n",
    "{context}\n",
    "\n",
    "Write in clear academic style.\n",
    "\"\"\")\n",
    "\n",
    "llm_section_chain = llm_section_prompt | llm | StrOutputParser()\n",
    "\n",
    "def summarize_section(section_name, retrieved_texts):\n",
    "    context = \"\\n\\n\".join(retrieved_texts)\n",
    "    summary = llm_section_chain.invoke({\n",
    "        \"section_name\": section_name,\n",
    "        \"context\": context\n",
    "    })\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88b50dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section: Problem Statement\n",
      "Query: What research problem does this paper address?\n",
      "Retrieved indices: [[7 6 5]]\n",
      "## Problem Statement\n",
      "The World Health Organization (WHO) highlights cardiovascular diseases as a significant global health concern, emphasizing the need for innovative approaches to detection and management. Artificial intelligence (AI), particularly machine learning, has emerged as a powerful tool in this domain, enabling more accurate and efficient diagnosis.\n",
      "\n",
      "Recent studies have demonstrated the potential of AI in detecting and interpreting heart disease through various methods, such as conditional variational auto-encoders, stacked ensemble-learning frameworks, and intelligent medical cyber-physical systems. These advancements can support early identification and monitoring of conditions like heart valve diseases, improving patient outcomes.\n",
      "\n",
      "Machine learning algorithms have also proven effective in chronic heart failure diagnosis, leveraging large datasets to identify patterns and risk factors. In a cohort study using the Korean National Health Insurance Service Health Screening Database, machine learning models were able to predict cardiovascular disease with notable accuracy. Furthermore, AI-based approaches are being applied to electrocardiogram (ECG) images and heart sounds analysis, enabling early detection of cardiac issues on embedded systems.\n",
      "\n",
      "Deep learning techniques have shown promise in diagnosing coronary artery disease through non-invasive imaging methods like single-photon emission computed tomography myocardial perfusion imaging (SPECT-MPI). These advanced algorithms can analyze complex medical images with high precision, contributing to more accurate diagnoses and personalized treatment plans.\n",
      "\n",
      "Innovative research also explores the integration of machine learning with Internet of Things (IoT) technologies, allowing for continuous monitoring and real-time analysis of patients' health data. This integration has the potential to revolutionize cardiovascular disease management by enabling early intervention and proactive care.\n",
      "\n",
      "However, as AI and machine learning continue to evolve in the field of cardiology, it is crucial to address concerns regarding data privacy, algorithm interpretability, and the need for large, diverse datasets to ensure generalizability and robustness of these models. Future research should focus on refining existing algorithms, expanding datasets, and exploring ensemble models that merge multiple approaches to further enhance predictive accuracy.\n",
      "\n",
      "In conclusion, machine learning plays a pivotal role in advancing heart disease diagnosis and management, offering significant potential to improve patient outcomes and reduce the burden of cardiovascular diseases worldwide. By embracing AI technologies and fostering interdisciplinary collaboration, the healthcare sector can continue to make strides in this critical domain.\n"
     ]
    }
   ],
   "source": [
    "final_summary = {}\n",
    "for section, query in section_queries.items():\n",
    "    print(f\"Section: {section}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    retrieved = retrieve_chunks(query, index, chunks, top_k=3)\n",
    "    final_summary[section] = summarize_section(section, retrieved)\n",
    "    break\n",
    "\n",
    "# Optional: Combine into a single formatted string\n",
    "structured_summary = \"\\n\\n\".join([f\"## {s}\\n{final_summary[s]}\" for s in final_summary])\n",
    "print(structured_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea8cc1",
   "metadata": {},
   "source": [
    "# Hybrid GPT+style summarization pipeline \n",
    "Model : Qwen:32B (ollama) model\n",
    "Embeddings: Ollama embeddings\n",
    "Vector database: FAISS\n",
    "\n",
    "**What it does (high level)**\n",
    "\n",
    "- Load a PDF and chunk it (page-aware, token-based)\n",
    "\n",
    "- Create Ollama embeddings for each chunk and store them in FAISS\n",
    "\n",
    "- For each target section (Problem, Dataset, Methodology, Evaluation, Limitations, Future work), it:\n",
    "    - Runs a semantic retrieval (top-k)\n",
    "    - Optionally reranks retrieved chunks using the LLM for higher precision\n",
    "    - Summarizes the retrieved context with a section-specific prompt\n",
    "\n",
    "- Combines all section outputs into a single polished final summary (one more LLM pass)\n",
    "\n",
    "- Logs pages/chunk indices and provides short previews for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3787f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ollama langchain-community langchain faiss-cpu tiktoken pypdf\n",
    "# or faiss-gpu if you've GPU and compatible build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3276dc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "Initializing Ollama embeddings and LLM wrappers...\n",
      "Done.\n",
      "\n",
      "Loading PDF: papers/hospital_bed_capacity_planning.pdf\n",
      "Total pages loaded: 8\n",
      "Total tokens in PDF (approx): 7411\n",
      "Created 17 chunks (chunk_size=512, overlap=50)\n",
      "Embedding chunks with Ollama embeddings (this may take a while)...\n",
      "  ▸ Embedded 17/17 chunks\n",
      "Embedding dimension: 768\n",
      "FAISS index built. Total vectors in index: 17\n",
      "\n",
      "--- Section: Title & Authors ---\n",
      "Retrieved (idx, pages): [(9, (3, 3)), (4, (1, 1)), (10, (3, 5)), (11, (5, 5))]\n",
      "After rerank (idx, pages): [(11, (5, 5)), (9, (3, 3))]\n",
      "  -> idx 11 pages 5-5 (preview): 'is et al. (2022) [62] ✓\\nVieira et al. (2023) [63] ✓\\nAlvarez-Chaves et al. (2023) [64] ✓ ✓\\nThis paper ✓ ✓ ✓\\nTable 4\\nThe considered periods for testing the significance of NHP fluctuations.\\nNo Period Ab'\n",
      "  -> idx 9 pages 3-3 (preview): ' ✓ ✓ ✓\\nNas and Koyuncu (2019) ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓\\nLaghmati et al. (2020) [41] ✓ ✓ ✓ ✓\\nFathi et al. (2020) [42] ✓\\nManiruzzaman et al (2020) [43] ✓ ✓ ✓\\nRahman et al. (2020) [38] ✓\\nBadriyah et al. (2020) [44'\n",
      "Section summary preview: **Title & Authors**\n",
      "\n",
      "This paper presents a study on the fluctuations of New Hospitalization Patients (NHP) in the Heart ward. The authors are not explicitly mentioned in the provided context.\n",
      "\n",
      "The references cited in this section include:\n",
      "\n",
      "* is et al. (2022)\n",
      "* Vieira et al. (2023)\n",
      "* Alvarez-Chaves e...\n",
      "\n",
      "\n",
      "--- Section: Problem Statement ---\n",
      "Retrieved (idx, pages): [(10, (3, 5)), (4, (1, 1)), (15, (6, 7)), (7, (2, 2))]\n",
      "After rerank (idx, pages): [(10, (3, 5)), (4, (1, 1)), (15, (6, 7)), (7, (2, 2))]\n",
      "  -> idx 10 pages 3-5 (preview): ' mean of hospitalized patients during three 20-\\nday periods, as presented in Table 4, to investigate the significance of\\nfalling in admittance during this period.\\nThe sample corresponding to each peri'\n",
      "  -> idx 4 pages 1-1 (preview): '\\net al. (2021) used an incremental Poisson model on the previous\\npatients’ statistics to establish a Mont-Carlo simulation model for a 10-\\nday prediction of needed beds in various wards of A hospital '\n",
      "  -> idx 15 pages 6-7 (preview): ' in each Age class per LOS class.\\nIn Table 10, the lowest proportion of NHP from the first class\\nof LOS, LOS=1, comes from the eldest people’s class which seems\\nreasonable because of the more Heart ri'\n",
      "  -> idx 7 pages 2-2 (preview): '2) ✓\\nLatruwe et al. (2023) ✓\\nGarcia-Vincuna et al.\\n(2023)\\n✓ ✓\\nRedondo et al. (2023) ✓\\nBekker et al. (2023) ✓\\nWidyasari et al. (2023) ✓ ✓\\nJohnson et al. (2023) ✓\\nThis paper ✓ ✓ ✓ ✓ ✓ ✓\\nmathematical mod'\n",
      "Section summary preview: **Problem Statement**\n",
      "\n",
      "The problem statement revolves around predicting hospital bed capacity and demand for patients with heart conditions. The objective is to develop a framework that forecasts the number of patients (NHP) and length of stay (LOS) to determine the required beds in the Heart ward.\n",
      "...\n",
      "\n",
      "\n",
      "--- Section: Dataset ---\n",
      "Retrieved (idx, pages): [(4, (1, 1)), (5, (1, 1)), (3, (1, 1)), (14, (6, 6))]\n",
      "After rerank (idx, pages): [(5, (1, 1)), (3, (1, 1)), (4, (1, 1)), (14, (6, 6))]\n",
      "  -> idx 5 pages 1-1 (preview): ' the USA [19]. Latruwe et al. (2023) proposed a\\nsimulation model called the ProMoBed, for inpatient hospitals’ bed\\ncapacity forecasting. They used LOS, seasonality, and admission data\\nto simulate a st'\n",
      "  -> idx 3 pages 1-1 (preview): ' and\\nMasmoudi (2012) studied the bed capacity of 157 public hospitals in\\nTunisia when the demand for beds is random using a multi-objective\\nstochastic programming model to allocate the beds to the hos'\n",
      "  -> idx 4 pages 1-1 (preview): '\\net al. (2021) used an incremental Poisson model on the previous\\npatients’ statistics to establish a Mont-Carlo simulation model for a 10-\\nday prediction of needed beds in various wards of A hospital '\n",
      "  -> idx 14 pages 6-6 (preview): 'Fig. 6 represents the patients’ LOS distribution.\\nIn Fig. 6, only a few LOSs are too long, and most seem to be less\\nthan ten days. This claim is verified in Figs. 7 and 8, representing the\\nscatter of '\n",
      "Section summary preview: **Dataset**\n",
      "\n",
      "The dataset used in this research is a collection of various sources, including:\n",
      "\n",
      "* Time series data on occupied beds from Kutafina et al. (2019) with 353,520 records\n",
      "* Patient data from Schiele et al. (2021) with 6,000 patients' data from 2010 to 2016 in an ICU scheduling problem in Ge...\n",
      "\n",
      "\n",
      "--- Section: Methodology ---\n",
      "Retrieved (idx, pages): [(4, (1, 1)), (7, (2, 2)), (5, (1, 1)), (0, (0, 0))]\n",
      "After rerank (idx, pages): [(0, (0, 0)), (7, (2, 2)), (4, (1, 1)), (5, (1, 1))]\n",
      "  -> idx 0 pages 0-0 (preview): 'Healthcare Analytics 4 (2023) 100245\\nContents lists available at ScienceDirect\\nHealthcare Analytics\\njournal homepage: www.elsevier.com/locate/health\\nA forecasting approach for hospital bed capacity pl'\n",
      "  -> idx 7 pages 2-2 (preview): '2) ✓\\nLatruwe et al. (2023) ✓\\nGarcia-Vincuna et al.\\n(2023)\\n✓ ✓\\nRedondo et al. (2023) ✓\\nBekker et al. (2023) ✓\\nWidyasari et al. (2023) ✓ ✓\\nJohnson et al. (2023) ✓\\nThis paper ✓ ✓ ✓ ✓ ✓ ✓\\nmathematical mod'\n",
      "  -> idx 4 pages 1-1 (preview): '\\net al. (2021) used an incremental Poisson model on the previous\\npatients’ statistics to establish a Mont-Carlo simulation model for a 10-\\nday prediction of needed beds in various wards of A hospital '\n",
      "  -> idx 5 pages 1-1 (preview): ' the USA [19]. Latruwe et al. (2023) proposed a\\nsimulation model called the ProMoBed, for inpatient hospitals’ bed\\ncapacity forecasting. They used LOS, seasonality, and admission data\\nto simulate a st'\n",
      "Section summary preview: **Methodology**\n",
      "\n",
      "This study proposes a data-driven approach to forecast Hospital Bed Capacity (HBC) using Machine Learning (ML) and Deep Learning (DL). The methodology involves:\n",
      "\n",
      "1. **Data Collection**: A dataset of 51,231 records is used for analysis.\n",
      "2. **Data Preprocessing**: Data cleaning and fe...\n",
      "\n",
      "\n",
      "--- Section: Evaluation & Metrics ---\n",
      "Retrieved (idx, pages): [(10, (3, 5)), (1, (0, 0)), (5, (1, 1)), (14, (6, 6))]\n",
      "After rerank (idx, pages): [(10, (3, 5)), (1, (0, 0)), (5, (1, 1)), (14, (6, 6))]\n",
      "  -> idx 10 pages 3-5 (preview): ' mean of hospitalized patients during three 20-\\nday periods, as presented in Table 4, to investigate the significance of\\nfalling in admittance during this period.\\nThe sample corresponding to each peri'\n",
      "  -> idx 1 pages 0-0 (preview): ' approach to this problem is\\nusing simulation or programming models involving several issues, such\\nas the need for some assumptions on attributes of some quantities,\\nfor example, the probability distr'\n",
      "  -> idx 5 pages 1-1 (preview): ' the USA [19]. Latruwe et al. (2023) proposed a\\nsimulation model called the ProMoBed, for inpatient hospitals’ bed\\ncapacity forecasting. They used LOS, seasonality, and admission data\\nto simulate a st'\n",
      "  -> idx 14 pages 6-6 (preview): 'Fig. 6 represents the patients’ LOS distribution.\\nIn Fig. 6, only a few LOSs are too long, and most seem to be less\\nthan ten days. This claim is verified in Figs. 7 and 8, representing the\\nscatter of '\n",
      "Section summary preview: **Evaluation & Metrics**\n",
      "\n",
      "The evaluation of bed capacity forecasting models is a crucial aspect of this research. The authors propose a hybrid approach combining data analysis (DA), machine learning (ML), deep learning (DL), statistical inference, and mathematical modeling to forecast hospital bed o...\n",
      "\n",
      "\n",
      "--- Section: Limitations ---\n",
      "Retrieved (idx, pages): [(3, (1, 1)), (15, (6, 7)), (4, (1, 1)), (5, (1, 1))]\n",
      "After rerank (idx, pages): [(5, (1, 1)), (3, (1, 1)), (4, (1, 1))]\n",
      "  -> idx 5 pages 1-1 (preview): ' the USA [19]. Latruwe et al. (2023) proposed a\\nsimulation model called the ProMoBed, for inpatient hospitals’ bed\\ncapacity forecasting. They used LOS, seasonality, and admission data\\nto simulate a st'\n",
      "  -> idx 3 pages 1-1 (preview): ' and\\nMasmoudi (2012) studied the bed capacity of 157 public hospitals in\\nTunisia when the demand for beds is random using a multi-objective\\nstochastic programming model to allocate the beds to the hos'\n",
      "  -> idx 4 pages 1-1 (preview): '\\net al. (2021) used an incremental Poisson model on the previous\\npatients’ statistics to establish a Mont-Carlo simulation model for a 10-\\nday prediction of needed beds in various wards of A hospital '\n",
      "Section summary preview: **Limitations**\n",
      "\n",
      "The reviewed literature on Hospital Bed Capacity (HBC) forecasting highlights several limitations:\n",
      "\n",
      "* **Limited application of Machine Learning (ML) tools**: Only three researchers applied ML tools to HBC planning, using time series data on occupied beds and ignoring direct effects ...\n",
      "\n",
      "\n",
      "--- Section: Future Work ---\n",
      "Retrieved (idx, pages): [(4, (1, 1)), (7, (2, 2)), (3, (1, 1)), (5, (1, 1))]\n",
      "After rerank (idx, pages): [(4, (1, 1)), (7, (2, 2)), (3, (1, 1)), (5, (1, 1))]\n",
      "  -> idx 4 pages 1-1 (preview): '\\net al. (2021) used an incremental Poisson model on the previous\\npatients’ statistics to establish a Mont-Carlo simulation model for a 10-\\nday prediction of needed beds in various wards of A hospital '\n",
      "  -> idx 7 pages 2-2 (preview): '2) ✓\\nLatruwe et al. (2023) ✓\\nGarcia-Vincuna et al.\\n(2023)\\n✓ ✓\\nRedondo et al. (2023) ✓\\nBekker et al. (2023) ✓\\nWidyasari et al. (2023) ✓ ✓\\nJohnson et al. (2023) ✓\\nThis paper ✓ ✓ ✓ ✓ ✓ ✓\\nmathematical mod'\n",
      "  -> idx 3 pages 1-1 (preview): ' and\\nMasmoudi (2012) studied the bed capacity of 157 public hospitals in\\nTunisia when the demand for beds is random using a multi-objective\\nstochastic programming model to allocate the beds to the hos'\n",
      "  -> idx 5 pages 1-1 (preview): ' the USA [19]. Latruwe et al. (2023) proposed a\\nsimulation model called the ProMoBed, for inpatient hospitals’ bed\\ncapacity forecasting. They used LOS, seasonality, and admission data\\nto simulate a st'\n",
      "Section summary preview: **Future Work**\n",
      "\n",
      "The reviewed literature highlights several areas for future research:\n",
      "\n",
      "1. **Integration of LOS and NHP**: Most studies focus on either LOS or NHP forecasting, but not both simultaneously. Future work should investigate the direct effects of LOS and NHP on HBC planning.\n",
      "2. **Long-ter...\n",
      "\n",
      "\n",
      "\n",
      "==== FINAL SUMMARY (first 1500 chars) ====\n",
      "\n",
      "**Title:** Predicting Hospital Bed Capacity: A Machine Learning Approach to Forecasting Length of Stay and Number of Hospitalized Patients\n",
      "\n",
      "**Abstract:**\n",
      "\n",
      "This study presents a comprehensive framework for predicting hospital bed capacity using machine learning (ML) and deep learning (DL) algorithms. The proposed approach aims to forecast the number of hospitalized patients (NHP) and length of stay (LOS) in the Heart ward, considering factors such as patient demographics, LOS classification, and NHP distribution. The study employs a hybrid approach combining data analysis, ML, DL, statistical inference, and mathematical modeling to improve hospital bed capacity forecasting.\n",
      "\n",
      "**Introduction:**\n",
      "\n",
      "Hospital bed capacity planning is a critical challenge in healthcare systems worldwide. Accurate forecasting of NHP and LOS is essential for ensuring adequate bed capacity and reducing the risk of overcrowding. However, existing studies have limitations, including limited application of ML tools, insufficient consideration of significant factors, short-term focus, and limited geographic scope.\n",
      "\n",
      "**Methodology:**\n",
      "\n",
      "This study proposes a data-driven approach to forecast hospital bed capacity using ML and DL algorithms. The methodology involves:\n",
      "\n",
      "1. Data collection: A dataset of 51,231 records is used for analysis.\n",
      "2. Data preprocessing: Data cleaning and feature transformations are performed.\n",
      "3. LOS classification: Five ML algorithms (Bayesian Network, K-Nearest Neighbor, Support Vector Mach...\n",
      "\n",
      "\n",
      "Pipeline completed in 401.99 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Hybrid RAG + Sectioned Summarizer for research papers\n",
    "# Works with: Ollama (Qwen-32B), Ollama embeddings, FAISS\n",
    "# Author: ChatGPT (adapted for your environment)\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "from tiktoken import get_encoding\n",
    "\n",
    "# langchain / ollama imports\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# --------------------------\n",
    "# Configuration\n",
    "# --------------------------\n",
    "PDF_PATH = \"papers/hospital_bed_capacity_planning.pdf\"  # change path\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "EMBEDDING_MODEL_NAME = \"nomic-embed-text\"  # adjust if different on your Ollama\n",
    "LLM_MODEL_NAME = \"llama3.1:latest\"           # your Qwen model in Ollama\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Chunking / retrieval hyperparams tuned for Qwen-32B\n",
    "CHUNK_SIZE = 512      # tokens per chunk (reduced for embedding model compatibility)\n",
    "CHUNK_OVERLAP = 50\n",
    "TOP_K = 4             # number of chunks to retrieve for each section\n",
    "RERANK_WITH_LLM = True  # set True to use LLM-based reranker (more precise, more compute)\n",
    "\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# --------------------------\n",
    "# Initialize Ollama clients (LangChain wrappers)\n",
    "# --------------------------\n",
    "print(\"Initializing Ollama embeddings and LLM wrappers...\")\n",
    "embedding_model = OllamaEmbeddings(model=EMBEDDING_MODEL_NAME, base_url=OLLAMA_BASE_URL)\n",
    "llm = ChatOllama(model=LLM_MODEL_NAME, temperature=0.05, base_url=OLLAMA_BASE_URL, device=DEVICE)\n",
    "print(\"Done.\\n\")\n",
    "\n",
    "# --------------------------\n",
    "# Utility: Load & chunk PDF (page-aware)\n",
    "# --------------------------\n",
    "def load_and_chunk_pdf(pdf_path, chunk_size=CHUNK_SIZE, overlap=CHUNK_OVERLAP):\n",
    "    print(f\"Loading PDF: {pdf_path}\")\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()  # list of Page objects with .page_content\n",
    "    page_texts = [p.page_content for p in pages[:-3]]\n",
    "    print(f\"Total pages loaded: {len(page_texts)}\")\n",
    "\n",
    "    # Join with page separators to keep page breaks\n",
    "    full_text_with_pages = \"\\n\\n[PAGEREF]\\n\\n\".join(page_texts)\n",
    "\n",
    "    enc = get_encoding(\"cl100k_base\")\n",
    "    tokens = enc.encode(full_text_with_pages)\n",
    "    print(f\"Total tokens in PDF (approx): {len(tokens)}\")\n",
    "\n",
    "    # create token-wise chunks, but also record which page ranges each chunk covers\n",
    "    chunks = []\n",
    "    token_to_page = []  # map every token index to page index for biasing\n",
    "    # build token->page mapping by encoding each page separately\n",
    "    page_token_counts = [len(enc.encode(t)) for t in page_texts]\n",
    "    page_start = 0\n",
    "    page_token_starts = []\n",
    "    for cnt in page_token_counts:\n",
    "        page_token_starts.append(page_start)\n",
    "        page_start += cnt\n",
    "\n",
    "    # make chunks using token slices of the full_text (encode/decode)\n",
    "    for i in range(0, len(tokens), chunk_size - overlap):\n",
    "        t_slice = tokens[i:i + chunk_size]\n",
    "        chunk_text = enc.decode(t_slice)\n",
    "        # estimate page span by finding nearest page start\n",
    "        # find first token index's page\n",
    "        start_page = None\n",
    "        end_page = None\n",
    "        # find which page contains token index i and i+len-1 approximate\n",
    "        # naive approach: compare against page_token_starts cumulative\n",
    "        for pi, start_idx in enumerate(page_token_starts):\n",
    "            if i >= start_idx:\n",
    "                start_page = pi\n",
    "            else:\n",
    "                break\n",
    "        # end page\n",
    "        j = i + len(t_slice) - 1\n",
    "        end_page = start_page\n",
    "        for pi, start_idx in enumerate(page_token_starts[start_page:], start=start_page):\n",
    "            if j >= start_idx:\n",
    "                end_page = pi\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        chunks.append({\n",
    "            \"text\": chunk_text,\n",
    "            \"start_token\": i,\n",
    "            \"token_len\": len(t_slice),\n",
    "            \"start_page\": start_page,\n",
    "            \"end_page\": end_page\n",
    "        })\n",
    "\n",
    "    print(f\"Created {len(chunks)} chunks (chunk_size={chunk_size}, overlap={overlap})\")\n",
    "    return chunks\n",
    "\n",
    "# --------------------------\n",
    "# Build FAISS index using Ollama embeddings\n",
    "# --------------------------\n",
    "def build_faiss_index(chunks, embedding_model):\n",
    "    print(\"Embedding chunks with Ollama embeddings (this may take a while)...\")\n",
    "    vectors = []\n",
    "    for i, c in enumerate(chunks):\n",
    "        emb = embedding_model.embed_query(c[\"text\"])\n",
    "        # ensure vector is a list of floats\n",
    "        vec = np.array(emb, dtype=np.float32)\n",
    "        vectors.append(vec)\n",
    "        if (i + 1) % 20 == 0 or (i + 1) == len(chunks):\n",
    "            print(f\"  ▸ Embedded {i+1}/{len(chunks)} chunks\")\n",
    "\n",
    "    embeddings_array = np.vstack(vectors).astype(\"float32\")\n",
    "    d = embeddings_array.shape[1]\n",
    "    print(f\"Embedding dimension: {d}\")\n",
    "\n",
    "    # create FAISS index (simple FlatL2 index - replace with IndexIVFFlat for large corpora)\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(embeddings_array)\n",
    "    print(f\"FAISS index built. Total vectors in index: {index.ntotal}\")\n",
    "    return index, embeddings_array\n",
    "\n",
    "# --------------------------\n",
    "# Retrieval with optional position bias & reranking\n",
    "# --------------------------\n",
    "def retrieve_chunks_for_query(query, index, chunks, embedding_model, top_k=TOP_K, position_bias=True):\n",
    "    q_emb = np.array([embedding_model.embed_query(query)], dtype=\"float32\")\n",
    "    # search larger set then filter/rerank if needed\n",
    "    search_k = max(top_k * 3, top_k + 5)\n",
    "    distances, indices = index.search(q_emb, search_k)\n",
    "    indices = indices[0].tolist()\n",
    "    distances = distances[0].tolist()\n",
    "\n",
    "    # Build candidates with metadata\n",
    "    candidates = []\n",
    "    for idx, dist in zip(indices, distances):\n",
    "        if idx < 0 or idx >= len(chunks):\n",
    "            continue\n",
    "        c = chunks[idx]\n",
    "        candidates.append({\n",
    "            \"idx\": idx,\n",
    "            \"dist\": float(dist),\n",
    "            \"start_page\": c[\"start_page\"],\n",
    "            \"end_page\": c[\"end_page\"],\n",
    "            \"text\": c[\"text\"]\n",
    "        })\n",
    "\n",
    "    # apply position bias: prefer earlier pages for queries like \"problem statement\" or \"abstract\"\n",
    "    if position_bias:\n",
    "        def score_with_bias(item):\n",
    "            # bias factor: earlier pages get lower score (better)\n",
    "            page_bias = (item[\"start_page\"] or 0) * 0.03\n",
    "            return item[\"dist\"] + page_bias\n",
    "        candidates = sorted(candidates, key=score_with_bias)\n",
    "    else:\n",
    "        candidates = sorted(candidates, key=lambda x: x[\"dist\"])\n",
    "\n",
    "    # trim to top_k final\n",
    "    final = candidates[:top_k]\n",
    "    # debug info\n",
    "    print(\"Retrieved (idx, pages):\", [(c[\"idx\"], (c[\"start_page\"], c[\"end_page\"])) for c in final])\n",
    "    return final\n",
    "\n",
    "# Optional LLM-based reranker to improve precision (reranks the candidate texts by asking LLM a short question)\n",
    "def rerank_with_llm(query, candidates, llm, rerank_k=TOP_K):\n",
    "    # prepare a short prompt asking the LLM to score relevance (1-10)\n",
    "    prompt_template = \"\"\"You are a helpful research assistant. Given the question: \"{query}\"\n",
    "For each candidate passage, give a relevance score between 1 (irrelevant) and 10 (directly answers the question).\n",
    "Return lines in the format: score<TAB>passage_index\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Candidates:\n",
    "{listings}\n",
    "\n",
    "Provide only the scored lines.\n",
    "\"\"\"\n",
    "    listings = \"\\n\\n\".join([f\"[{i}] {c['text'][:400].replace('\\\\n',' ')}\" for i, c in enumerate(candidates)])\n",
    "    prompt = prompt_template.format(query=query, listings=listings)\n",
    "    # call LLM to score (small response)\n",
    "    response = llm.invoke(prompt)\n",
    "    text = response if isinstance(response, str) else (response.content if hasattr(response, \"content\") else str(response))\n",
    "    # parse lines\n",
    "    scores = []\n",
    "    for line in text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        # naive parse: first token is score, last token contains [i]\n",
    "        try:\n",
    "            score = float(parts[0])\n",
    "            # find passage index between brackets\n",
    "            idx_token = [p for p in parts if p.startswith(\"[\") and p.endswith(\"]\")]\n",
    "            if idx_token:\n",
    "                pid = int(idx_token[0].strip(\"[]\"))\n",
    "                scores.append((pid, score))\n",
    "        except Exception:\n",
    "            continue\n",
    "    # map back to candidates and sort by score desc\n",
    "    scored = []\n",
    "    for pid, sc in scores:\n",
    "        if 0 <= pid < len(candidates):\n",
    "            scored.append((candidates[pid], sc))\n",
    "    if not scored:\n",
    "        # fallback: return original candidates\n",
    "        return candidates[:rerank_k]\n",
    "    scored_sorted = sorted(scored, key=lambda x: -x[1])\n",
    "    reranked = [item for item, s in scored_sorted][:rerank_k]\n",
    "    # return reranked list\n",
    "    return reranked\n",
    "\n",
    "# --------------------------\n",
    "# Section prompts & summarization\n",
    "# --------------------------\n",
    "SECTION_QUERIES = {\n",
    "    \"Title & Authors\": \"What is the title and who are the authors of the paper? Provide year if present.\",\n",
    "    \"Problem Statement\": \"What research problem or objective does this paper address? Summarize briefly (1-2 sentences).\",\n",
    "    \"Dataset\": \"Which datasets were used in the experiments? Provide names, sizes, sources if available.\",\n",
    "    \"Methodology\": \"Describe the model architecture or methods proposed in the paper. Include algorithm names or key components.\",\n",
    "    \"Evaluation & Metrics\": \"What evaluation metrics and experimental results are reported? Provide numeric values when present.\",\n",
    "    \"Limitations\": \"What limitations or weaknesses do the authors mention?\",\n",
    "    \"Future Work\": \"What future work or extensions do the authors propose?\"\n",
    "}\n",
    "\n",
    "SECTION_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert AI research assistant. Create a concise academic-style summary for the section: \"{section_name}\".\n",
    "\n",
    "Context (retrieved passages):\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "- Extract facts from the context only (do not hallucinate).\n",
    "- If you cannot find explicit info, say \"Not stated in retrieved passages\".\n",
    "- Be concise and include numeric metrics where possible.\n",
    "\"\"\"\n",
    "\n",
    "section_prompt = PromptTemplate.from_template(SECTION_PROMPT_TEMPLATE)\n",
    "section_chain = section_prompt | llm | StrOutputParser()\n",
    "\n",
    "def summarize_section(section_name, query, index, chunks, embedding_model, llm, top_k=TOP_K, rerank=RERANK_WITH_LLM):\n",
    "    print(f\"\\n--- Section: {section_name} ---\")\n",
    "    candidates = retrieve_chunks_for_query(query, index, chunks, embedding_model, top_k=top_k, position_bias=True)\n",
    "    # prepare contexts\n",
    "    if rerank:\n",
    "        reranked = rerank_with_llm(query, candidates, llm, rerank_k=top_k)\n",
    "        candidates = reranked\n",
    "        print(\"After rerank (idx, pages):\", [(c[\"idx\"], (c[\"start_page\"], c[\"end_page\"])) for c in candidates])\n",
    "    context = \"\\n\\n\".join([c[\"text\"] for c in candidates])\n",
    "    # debug: show snippet of retrieved context\n",
    "    for c in candidates:\n",
    "        print(f\"  -> idx {c['idx']} pages {c['start_page']}-{c['end_page']} (preview): {c['text'][:200]!r}\")\n",
    "    # call LLM summarizer for this section\n",
    "    out = section_chain.invoke({\"section_name\": section_name, \"context\": context})\n",
    "    print(f\"Section summary preview: {out[:300]}...\\n\")\n",
    "    return out\n",
    "\n",
    "# --------------------------\n",
    "# Combine section summaries & final polish\n",
    "# --------------------------\n",
    "FINAL_COMBINE_PROMPT = \"\"\"\n",
    "You are an expert AI research assistant. Combine the following section-level summaries into one coherent and well-structured paper summary.\n",
    "Keep the headings and produce a short global conclusion (2-3 sentences) at the end.\n",
    "\n",
    "Section summaries:\n",
    "{sections_text}\n",
    "\n",
    "Combine and output as a clean, academic-style summary.\n",
    "\"\"\"\n",
    "\n",
    "final_prompt = PromptTemplate.from_template(FINAL_COMBINE_PROMPT)\n",
    "final_chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "def combine_and_refine(section_summaries: dict):\n",
    "    sections_text = \"\\n\\n\".join([f\"## {k}\\n{v}\" for k, v in section_summaries.items()])\n",
    "    combined = final_chain.invoke({\"sections_text\": sections_text})\n",
    "    return combined\n",
    "\n",
    "# --------------------------\n",
    "# Full pipeline runner\n",
    "# --------------------------\n",
    "def run_full_pipeline(pdf_path):\n",
    "    # 1) Load & chunk\n",
    "    chunks = load_and_chunk_pdf(pdf_path)\n",
    "    # 2) Build embeddings index\n",
    "    index, embeddings_array = build_faiss_index(chunks, embedding_model)\n",
    "    # 3) For each section: retrieve, rerank, summarize\n",
    "    section_summaries = {}\n",
    "    for sname, sq in SECTION_QUERIES.items():\n",
    "        summary = summarize_section(sname, sq, index, chunks, embedding_model, llm, top_k=TOP_K, rerank=RERANK_WITH_LLM)\n",
    "        section_summaries[sname] = summary\n",
    "\n",
    "    # 4) Combine & final polish\n",
    "    final_summary = combine_and_refine(section_summaries)\n",
    "    return {\n",
    "        \"sections\": section_summaries,\n",
    "        \"final_summary\": final_summary,\n",
    "        \"chunks\": chunks,\n",
    "        \"index\": index\n",
    "    }\n",
    "\n",
    "# --------------------------\n",
    "# Example usage\n",
    "# --------------------------\n",
    "\n",
    "start = time.time()\n",
    "out = run_full_pipeline(PDF_PATH)\n",
    "elapsed = time.time() - start\n",
    "print(\"\\n\\n==== FINAL SUMMARY (first 1500 chars) ====\\n\")\n",
    "print(out[\"final_summary\"][:1500] + \"...\\n\")\n",
    "print(f\"\\nPipeline completed in {elapsed:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb0991a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Title:** Predicting Hospital Bed Capacity: A Machine Learning Approach to Forecasting Length of Stay and Number of Hospitalized Patients\\n\\n**Abstract:**\\n\\nThis study presents a comprehensive framework for predicting hospital bed capacity using machine learning (ML) and deep learning (DL) algorithms. The proposed approach aims to forecast the number of hospitalized patients (NHP) and length of stay (LOS) in the Heart ward, considering factors such as patient demographics, LOS classification, and NHP distribution. The study employs a hybrid approach combining data analysis, ML, DL, statistical inference, and mathematical modeling to improve hospital bed capacity forecasting.\\n\\n**Introduction:**\\n\\nHospital bed capacity planning is a critical challenge in healthcare systems worldwide. Accurate forecasting of NHP and LOS is essential for ensuring adequate bed capacity and reducing the risk of overcrowding. However, existing studies have limitations, including limited application of ML tools, insufficient consideration of significant factors, short-term focus, and limited geographic scope.\\n\\n**Methodology:**\\n\\nThis study proposes a data-driven approach to forecast hospital bed capacity using ML and DL algorithms. The methodology involves:\\n\\n1. Data collection: A dataset of 51,231 records is used for analysis.\\n2. Data preprocessing: Data cleaning and feature transformations are performed.\\n3. LOS classification: Five ML algorithms (Bayesian Network, K-Nearest Neighbor, Support Vector Machine, Decision Tree, and Linear Regression) are applied to classify patients' Length of Stay (LOS).\\n4. NHP forecasting: Three forecasting techniques (Seasonal Autoregressive Integrated Moving Average, Linear Regression, and Long Short-Term Memory Neural Network) are used to forecast the Number of Hospitalized Patients (NHP).\\n5. Mathematical modeling: The results of LOS classification and NHP forecasting are applied to a simple mathematical model to predict required bed capacity.\\n\\n**Evaluation & Metrics:**\\n\\nThe evaluation of bed capacity forecasting models is a crucial aspect of this research. The authors propose a hybrid approach combining data analysis, ML, DL, statistical inference, and mathematical modeling to forecast hospital bed occupancy. The study uses several classification tools coded using the Sklearn library of Python to examine the accuracy of different sets of LOS classes.\\n\\n**Limitations:**\\n\\nThe reviewed literature on Hospital Bed Capacity (HBC) forecasting highlights several limitations:\\n\\n* Limited application of Machine Learning (ML) tools\\n* Insufficient consideration of significant factors\\n* Short-term focus\\n* Limited geographic scope\\n\\n**Future Work:**\\n\\nThe reviewed literature highlights several areas for future research:\\n\\n1. Integration of LOS and NHP\\n2. Long-term forecasting\\n3. Multi-objective optimization\\n4. Real-time data integration\\n5. Scalability and generalizability\\n\\n**Conclusion:**\\n\\nThis study presents a comprehensive framework for predicting hospital bed capacity using ML and DL algorithms. The proposed approach aims to improve HBC forecasting by considering factors such as patient demographics, LOS classification, and NHP distribution. The study highlights the need for further research on HBC forecasting, particularly in incorporating ML tools, considering significant factors, and addressing long-term planning needs.\\n\\n**Global Conclusion:**\\n\\nThe accurate prediction of hospital bed capacity is a critical challenge in healthcare systems worldwide. This study presents a comprehensive framework for predicting hospital bed capacity using machine learning (ML) and deep learning (DL) algorithms. The proposed approach aims to improve hospital bed capacity forecasting by considering factors such as patient demographics, LOS classification, and NHP distribution. The study highlights the need for further research on HBC forecasting, particularly in incorporating ML tools, considering significant factors, and addressing long-term planning needs.\\n\\n**Recommendations:**\\n\\n1. Future studies should investigate the direct effects of LOS and NHP on HBC planning.\\n2. Models that incorporate patient demographics, such as age and comorbidities, should be developed to better understand their impact on HBC planning.\\n3. The application of transfer learning techniques should be explored to adapt existing models to new hospitals or regions with limited data availability.\\n\\n**Future Research Directions:**\\n\\n1. Investigate the use of ensemble methods (e.g., combining multiple ML algorithms) to improve forecasting accuracy.\\n2. Develop models that incorporate patient demographics, such as age and comorbidities, to better understand their impact on HBC planning.\\n3. Explore the application of transfer learning techniques to adapt existing models to new hospitals or regions with limited data availability.\\n\\n**Numeric Metrics:**\\n\\n1. 19 million people were hospitalized worldwide due to Covid-19 (Redondo et al., 2023).\\n2. 353,520 time series records were used in Kutafina et al.'s (2019) study on hospital bed occupancy.\\n3. The ProMoBed model proposed by Latruwe et al. (2023) uses LOS, seasonality, and admission data to simulate a stochastic pattern of demand for beds.\\n\\n**References:**\\n\\nThe references cited in this paper include:\\n\\n* is et al. (2022)\\n* Vieira et al. (2023)\\n* Alvarez-Chaves et al. (2023)\\n* Nas and Koyuncu (2019)\\n* Laghmati et al. (2020)\\n* Fathi et al. (2020)\\n* Maniruzzaman et al (2020)\\n* Rahman et al. (2020)\\n* Badriyah et al. (2020)\\n* Jiande and Chindo (2021)\\n* Gurazada et al. (2022)\\n* Alabbad et al. (2022)\\n* Sultan et al. (2023)\\n* Amin et al (2023)\\n\\nNote: The references are not included in the summary, but they can be found in the original paper.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"final_summary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83315a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c4bac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages loaded: 8\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"papers/hospital_bed_capacity_planning.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load()  # list of Page objects with .page_content\n",
    "page_texts = [p.page_content for p in pages[:-3]]\n",
    "print(f\"Total pages loaded: {len(page_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e9f172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2023-12-04T09:37:14+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2023-12-04T09:37:14+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Healthcare Analytics, 4 (2023) 100245. doi:10.1016/j.health.2023.100245', 'trapped': '/False', 'source': 'papers/hospital_bed_capacity_planning.pdf', 'total_pages': 11, 'page': 0, 'page_label': '1'}, page_content='Healthcare Analytics 4 (2023) 100245\\nContents lists available at ScienceDirect\\nHealthcare Analytics\\njournal homepage: www.elsevier.com/locate/health\\nA forecasting approach for hospital bed capacity planning using machine\\nlearning and deep learning with application to public hospitals\\nYounes Mahmoudian, Arash Nemati∗, Abdul Sattar Safaei\\nDepartment of Industrial Engineering, Babol Noshirvani University of Technology, Babol, Iran\\nA R T I C L E I N F O\\nKeywords:\\nMachine learning\\nDeep learning\\nHospital bed capacity forecasting\\nData analytics\\nClassification\\nStatistical inference\\nA B S T R A C T\\nHospital Bed Capacity (HBC) planning affects economic and social sustainability in healthcare through\\nbed capacity efficiency and medical treatment accessibility. Conventionally, this problem is solved using\\nprogramming or simulation models with assumptions and limits. Forecasting the HBC using time series data\\non bed occupancy has been considered but not with factors such as the Number of Hospitalized Patients\\n(NHP) and patient’s length of stay (LOS). This study proposes a data-driven methodology to forecast the\\nHBC using Machine Learning (ML) and Deep Learning (DL). The LOS classification is performed using several\\nML techniques, including the Bayesian network, K-nearest neighbor, support vector machine, decision tree,\\nand Linear regression. Also, the seasonal autoregressive integrated moving average, linear regression and\\nLong short-term memory neural network are applied for the NHP forecasting. The forecasting and descriptive\\nanalysis outputs based on LOS classes are directly applied to a simple mathematical model to predict the\\nrequired bed capacity. This methodology is applied in a case study in a heart ward at a public hospital. The data\\nset includes 51231 records, and ML and DL algorithms are developed in Python. Results show that the heart\\nward’s bed capacity must be raised from 45 to 137 by 2026. In addition, several managerial recommendations\\nare formulated.\\n1. Introduction\\nThe Hospital Bed Capacity (HBC) forecasting problem has taken\\nsignificant attention because of its effects on the sustainability of\\nhospitals, particularly in terms of hospital economic efficiency, and\\npatient satisfaction [1–7]. The traditional approach to this problem is\\nusing simulation or programming models involving several issues, such\\nas the need for some assumptions on attributes of some quantities,\\nfor example, the probability distribution of some factors [8–11]. In\\naddition, reaching optimum or reasonable solutions is a big challenge\\nof the bed capacity programming models, particularly in the case of\\nlarge-scale, multi-objective, and integer models. Consequently, using\\nmodel-free methods for HBC forecasting seems to be a facilitator.\\nNowadays, business analytics, including Data Analysis (DA), Machine\\nLearning (ML), and Deep Learning (DL) techniques, are widely used as\\nmodel-free methods in different businesses of services and manufactur-\\ning to reach insights on market trends, such as customers’ behavior,\\ncosts, and technology by no reliance on the simulation or mathemat-\\nical models [12–14]. Also, a reasonable number of their successful\\napplications in the healthcare sector, such as Length of Stay (LOS)\\nforecasting, patient classification, healthcare resources forecasting, and\\ndisease diagnosis have been illustrated [15–18]. In recent years, a few\\nresearchers applied some forecaster tools of ML to predict the required\\n∗ Corresponding author.\\nE-mail addresses: younesmahmoudian@nit.ac.ir (Y. Mahmoudian), r.nemati@nit.ac.ir (A. Nemati), s.safaei@nit.ac.ir (A.S. Safaei).\\nbed capacity based on time-series data sets of bed occupancy [19,20].\\nBut they fail to consider the direct impacts of LOS and the Number of\\nHospitalized Patients (NHP) as the most significant factors affecting bed\\noccupancy [21].\\nThis paper deals with the mentioned-above gap by considering\\nLOS and NHP in the data-driven approach of HBC. A hybrid ap-\\nproach, including DA, ML, DL, statistical inference, and mathematical\\nmodel, is proposed to reach a reasonable forecast of bed occupancy in\\nthe future. In this methodology, several algorithms, such as Decision\\nTree (DT), Long Short-Term Memory (LSTM) neural network, Support\\nVector Machine (SVM), Bayesian network (BN), Seasonal Autoregres-\\nsive Integrated Moving Average (SARIMA), and Linear Regression (LR),\\nare applied in the LOS classification and NHP forecasting. Also, DA\\ntechniques are used for investigating the LOS, patients’ ages, and\\nNHP in detail, singularly and simultaneously, to provide beneficial\\nmanagerial insights into the HBC forecasting problem. In brief, using\\nLOS classification and proposing a DA-ML-DL-based framework for\\nHBC forecasting are the main contributions of this paper. This hybrid\\napproach provides many useful descriptive, diagnostics, predictive, and\\nto some extent, prescriptive analytics in the HBC forecasting problem.\\nThis methodology is applied using a real data set of a Heart ward of a\\npublic Hospital in Babol City.\\nhttps://doi.org/10.1016/j.health.2023.100245\\nReceived 22 May 2023; Received in revised form 30 July 2023; Accepted 10 August 2023\\n2772-4425/© 2023 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY license\\n(http://creativecommons.org/licenses/by/4.0/).')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2152d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages loaded: 16\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"papers/ml_model_cardio_disease_detection.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load()  # list of Page objects with .page_content\n",
    "page_texts = [p.page_content for p in pages[:-3]]\n",
    "print(f\"Total pages loaded: {len(page_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae160ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-01-24T17:06:41+08:00', 'author': 'Adedayo Ogunpola, Faisal Saeed, Shadi Basurra, Abdullah M. Albarrak and Sultan Noman Qasem', 'keywords': 'cardiovascular diseases; deep learning; disease detection; heart diseases; machine learning; ensemble learning; XGBoost', 'moddate': '2024-01-24T10:15:42+01:00', 'subject': 'Cardiovascular diseases present a significant global health challenge that emphasizes the critical need for developing accurate and more effective detection methods. Several studies have contributed valuable insights in this field, but it is still necessary to advance the predictive models and address the gaps in the existing detection approaches. For instance, some of the previous studies have not considered the challenge of imbalanced datasets, which can lead to biased predictions, especially when the datasets include minority classes. This study’s primary focus is the early detection of heart diseases, particularly myocardial infarction, using machine learning techniques. It tackles the challenge of imbalanced datasets by conducting a comprehensive literature review to identify effective strategies. Seven machine learning and deep learning classifiers, including K-Nearest Neighbors, Support Vector Machine, Logistic Regression, Convolutional Neural Network, Gradient Boost, XGBoost, and Random Forest, were deployed to enhance the accuracy of heart disease predictions. The research explores different classifiers and their performance, providing valuable insights for developing robust prediction models for myocardial infarction. The study’s outcomes emphasize the effectiveness of meticulously fine-tuning an XGBoost model for cardiovascular diseases. This optimization yields remarkable results: 98.50% accuracy, 99.14% precision, 98.29% recall, and a 98.71% F1 score. Such optimization significantly enhances the model’s diagnostic accuracy for heart disease.', 'title': 'Machine Learning-Based Predictive Models for Detection of Cardiovascular Diseases', 'source': 'papers/ml_model_cardio_disease_detection.pdf', 'total_pages': 19, 'page': 0, 'page_label': '1'}, page_content='Citation: Ogunpola, A.; Saeed, F.;\\nBasurra, S.; Albarrak, A.M.; Qasem,\\nS.N. Machine Learning-Based\\nPredictive Models for Detection of\\nCardiovascular Diseases. Diagnostics\\n2024, 14, 144. https://doi.org/\\n10.3390/diagnostics14020144\\nAcademic Editor: Mugahed A.\\nAl-antari\\nReceived: 27 November 2023\\nRevised: 21 December 2023\\nAccepted: 25 December 2023\\nPublished: 8 January 2024\\nCopyright: © 2024 by the authors.\\nLicensee MDPI, Basel, Switzerland.\\nThis article is an open access article\\ndistributed under the terms and\\nconditions of the Creative Commons\\nAttribution (CC BY) license (https://\\ncreativecommons.org/licenses/by/\\n4.0/).\\ndiagnostics \\nArticle\\nMachine Learning-Based Predictive Models for Detection of\\nCardiovascular Diseases\\nAdedayo Ogunpola 1, Faisal Saeed 1, *\\n , Shadi Basurra 1, Abdullah M. Albarrak 2\\n and Sultan Noman Qasem 2\\n1 DAAI Research Group, College of Computing and Digital Technology, Birmingham City University,\\nBirmingham B4 7XG, UK; adedayo.ogunpola@mail.bcu.ac.uk (A.O.); shadi.basurra@bcu.ac.uk (S.B.)\\n2 Computer Science Department, College of Computer and Information Sciences, Imam Mohammad Ibn Saud\\nIslamic University (IMSIU), Riyadh 11432, Saudi Arabia; amsbarrak@imamu.edu.sa (A.M.A.);\\nsnmohammed@imamu.edu.sa (S.N.Q.)\\n* Correspondence: faisal.saeed@bcu.ac.uk\\nAbstract: Cardiovascular diseases present a significant global health challenge that emphasizes the\\ncritical need for developing accurate and more effective detection methods. Several studies have\\ncontributed valuable insights in this field, but it is still necessary to advance the predictive models\\nand address the gaps in the existing detection approaches. For instance, some of the previous studies\\nhave not considered the challenge of imbalanced datasets, which can lead to biased predictions,\\nespecially when the datasets include minority classes. This study’s primary focus is the early\\ndetection of heart diseases, particularly myocardial infarction, using machine learning techniques.\\nIt tackles the challenge of imbalanced datasets by conducting a comprehensive literature review\\nto identify effective strategies. Seven machine learning and deep learning classifiers, including\\nK-Nearest Neighbors, Support Vector Machine, Logistic Regression, Convolutional Neural Network,\\nGradient Boost, XGBoost, and Random Forest, were deployed to enhance the accuracy of heart disease\\npredictions. The research explores different classifiers and their performance, providing valuable\\ninsights for developing robust prediction models for myocardial infarction. The study’s outcomes\\nemphasize the effectiveness of meticulously fine-tuning an XGBoost model for cardiovascular diseases.\\nThis optimization yields remarkable results: 98.50% accuracy, 99.14% precision, 98.29% recall, and\\na 98.71% F1 score. Such optimization significantly enhances the model’s diagnostic accuracy for\\nheart disease.\\nKeywords: cardiovascular diseases; deep learning; disease detection; heart diseases; machine\\nlearning; ensemble learning; XGBoost\\n1. Introduction\\nThe heart plays a crucial role in sustaining life by effectively pumping oxygenated\\nblood and regulating important hormones to maintain optimal blood pressure levels. Any\\ndeviation from its functioning can lead to the development of heart conditions, collectively\\nknown as cardiovascular diseases (CVD). CVD includes a range of disorders that affect\\nboth the heart and blood vessels, such as cerebrovascular problems, congenital anomalies,\\npulmonary embolisms, irregular heart rhythms (arrhythmias), peripheral arterial issues,\\ncoronary artery disease (CAD), rheumatic heart ailments, coronary heart disease (CHD),\\nand cardiomyopathies that affect the heart muscle.\\nNotably, CHD is the subtype among cardiovascular diseases, accounting for a signif-\\nicant 64% of all cases. While it primarily affects men, women are also susceptible to its\\nimpact. Within the realm of CVDs, CAD is particularly concerning due to its association\\nwith global mortality rates. According to the World Health Organization (WHO) [1], the\\nconsequences of CVDs are profound, with staggering statistics indicating an estimated\\n17.9 million deaths annually are attributed to these diseases worldwide. These alarming\\nnumbers highlight the significance of research efforts and medical advancements dedicated\\nDiagnostics 2024, 14, 144. https://doi.org/10.3390/diagnostics14020144 https://www.mdpi.com/journal/diagnostics')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb63c0d",
   "metadata": {},
   "source": [
    "# GROBID for hospital bed pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c68fc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<TEI xml:space=\"preserve\" xmlns=\"http://www.tei-c.org/ns/1.0\" \n",
      "xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n",
      "xsi:schemaLocation=\"http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd\"\n",
      " xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
      "\t<teiHeader xml:lang=\"en\">\n",
      "\t\t<fileDesc>\n",
      "\t\t\t<titleStmt>\n",
      "\t\t\t\t<title level=\"a\" type=\"main\">A forecasting approach for hospital bed capacity planning using machine learning and deep learning with application to public hospitals</title>\n",
      "\t\t\t</titleStmt>\n",
      "\t\t\t<publicationStmt>\n",
      "\t\t\t\t<publisher/>\n",
      "\t\t\t\t<availability status=\"unknown\"><licence/></availability>\n",
      "\t\t\t</publicationStmt>\n",
      "\t\t\t<sourceDesc>\n",
      "\t\t\t\t<biblStruct>\n",
      "\t\t\t\t\t<analytic>\n",
      "\t\t\t\t\t\t<author>\n",
      "\t\t\t\t\t\t\t<persName><forename type=\"first\">Healthcare</forename><surname>Analytics</surname></persName>\n",
      "\t\t\t\t\t\t\t<affiliation key=\"aff0\">\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"department\">Department of Industrial Engineering</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"institution\">Babol Noshirvani University of Technology</orgName>\n",
      "\t\t\t\t\t\t\t\t<address>\n",
      "\t\t\t\t\t\t\t\t\t<settlement>Babol</settlement>\n",
      "\t\t\t\t\t\t\t\t\t<country key=\"IR\">Iran</country>\n",
      "\t\t\t\t\t\t\t\t</address>\n",
      "\t\t\t\t\t\t\t</affiliation>\n",
      "\t\t\t\t\t\t</author>\n",
      "\t\t\t\t\t\t<author>\n",
      "\t\t\t\t\t\t\t<persName><forename type=\"first\">Younes</forename><surname>Mahmoudian</surname></persName>\n",
      "\t\t\t\t\t\t\t<email>younesmahmoudian@nit.ac.ir</email>\n",
      "\t\t\t\t\t\t\t<affiliation key=\"aff0\">\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"department\">Department of Industrial Engineering</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"institution\">Babol Noshirvani University of Technology</orgName>\n",
      "\t\t\t\t\t\t\t\t<address>\n",
      "\t\t\t\t\t\t\t\t\t<settlement>Babol</settlement>\n",
      "\t\t\t\t\t\t\t\t\t<country key=\"IR\">Iran</country>\n",
      "\t\t\t\t\t\t\t\t</address>\n",
      "\t\t\t\t\t\t\t</affiliation>\n",
      "\t\t\t\t\t\t</author>\n",
      "\t\t\t\t\t\t<author>\n",
      "\t\t\t\t\t\t\t<persName><forename type=\"first\">Arash</forename><surname>Nemati</surname></persName>\n",
      "\t\t\t\t\t\t\t<email>r.nemati@nit.ac.ir</email>\n",
      "\t\t\t\t\t\t\t<affiliation key=\"aff0\">\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"department\">Department of Industrial Engineering</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"institution\">Babol Noshirvani University of Technology</orgName>\n",
      "\t\t\t\t\t\t\t\t<address>\n",
      "\t\t\t\t\t\t\t\t\t<settlement>Babol</settlement>\n",
      "\t\t\t\t\t\t\t\t\t<country key=\"IR\">Iran</country>\n",
      "\t\t\t\t\t\t\t\t</address>\n",
      "\t\t\t\t\t\t\t</affiliation>\n",
      "\t\t\t\t\t\t</author>\n",
      "\t\t\t\t\t\t<author>\n",
      "\t\t\t\t\t\t\t<persName><forename type=\"first\">Abdul</forename><forename type=\"middle\">Sattar</forename><surname>Safaei</surname></persName>\n",
      "\t\t\t\t\t\t\t<email>s.safaei@nit.ac.ir</email>\n",
      "\t\t\t\t\t\t\t<affiliation key=\"aff0\">\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"department\">Department of Industrial Engineering</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"institution\">Babol Noshirvani University of Technology</orgName>\n",
      "\t\t\t\t\t\t\t\t<address>\n",
      "\t\t\t\t\t\t\t\t\t<settlement>Babol</settlement>\n",
      "\t\t\t\t\t\t\t\t\t<country key=\"IR\">Iran</country>\n",
      "\t\t\t\t\t\t\t\t</address>\n",
      "\t\t\t\t\t\t\t</affiliation>\n",
      "\t\t\t\t\t\t</author>\n",
      "\t\t\t\t\t\t<title level=\"a\" type=\"main\">A forecasting approach for hospital bed capacity planning using machine learning and deep learning with application to public hospitals</title>\n",
      "\t\t\t\t\t</analytic>\n",
      "\t\t\t\t\t<monogr>\n",
      "\t\t\t\t\t\t<imprint>\n",
      "\t\t\t\t\t\t\t<date/>\n",
      "\t\t\t\t\t\t</imprint>\n",
      "\t\t\t\t\t</monogr>\n",
      "\t\t\t\t\t<idno type=\"MD5\">EDBD4A2C54BF9F8ADC70CC7CFDC06077</idno>\n",
      "\t\t\t\t\t<idno type=\"DOI\">10.1016/j.health.2023.100245</idno>\n",
      "\t\t\t\t\t<note type=\"submission\">Received 22 May 2023; Received in revised form 30 July 2023; Accepted 10 August 2023</note>\n",
      "\t\t\t\t</biblStruct>\n",
      "\t\t\t</sourceDesc>\n",
      "\t\t</fileDesc>\n",
      "\t\t<encodingDesc>\n",
      "\t\t\t<appInfo>\n",
      "\t\t\t\t<application version=\"0.7.2\" ident=\"GROBID\" when=\"2025-10-29T07:34+0000\">\n",
      "\t\t\t\t\t<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>\n",
      "\t\t\t\t\t<ref target=\"https://github.com/kermitt2/grobid\"/>\n",
      "\t\t\t\t</application>\n",
      "\t\t\t</appInfo>\n",
      "\t\t</encodingDesc>\n",
      "\t\t<profileDesc>\n",
      "\t\t\t<textClass>\n",
      "\t\t\t\t<keywords>Machine learning Deep learning Hospital bed capacity forecasting Data analytics Classification Statistical inference</keywords>\n",
      "\t\t\t</textClass>\n",
      "\t\t\t<abstract>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><p>Hospital Bed Capacity (HBC) planning affects economic and social sustainability in healthcare through bed capacity efficiency and medical treatment accessibility. Conventionally, this problem is solved using programming or simulation models with assumptions and limits. Forecasting the HBC using time series data on bed occupancy has been considered but not with factors such as the Number of Hospitalized Patients (NHP) and patient's length of stay (LOS). This study proposes a data-driven methodology to forecast the HBC using Machine Learning (ML) and Deep Learning (DL). The LOS classification is performed using several ML techniques, including the Bayesian network, K-nearest neighbor, support vector machine, decision tree, and Linear regression. Also, the seasonal autoregressive integrated moving average, linear regression and Long short-term memory neural network are applied for the NHP forecasting. The forecasting and descriptive analysis outputs based on LOS classes are directly applied to a simple mathematical model to predict the required bed capacity. This methodology is applied in a case study in a heart ward at a public hospital. The data set includes 51231 records, and ML and DL algorithms are developed in Python. Results show that the heart ward's bed capacity must be raised from 45 to 137 by 2026. In addition, several managerial recommendations are formulated.</p></div>\n",
      "\t\t\t</abstract>\n",
      "\t\t</profileDesc>\n",
      "\t</teiHeader>\n",
      "\t<text xml:lang=\"en\">\n",
      "\t\t<body>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1.\">Introduction</head><p>The Hospital Bed Capacity (HBC) forecasting problem has taken significant attention because of its effects on the sustainability of hospitals, particularly in terms of hospital economic efficiency, and patient satisfaction <ref type=\"bibr\" target=\"#b0\">[1]</ref><ref type=\"bibr\" target=\"#b1\">[2]</ref><ref type=\"bibr\" target=\"#b2\">[3]</ref><ref type=\"bibr\" target=\"#b3\">[4]</ref><ref type=\"bibr\" target=\"#b4\">[5]</ref><ref type=\"bibr\" target=\"#b5\">[6]</ref><ref type=\"bibr\" target=\"#b6\">[7]</ref>. The traditional approach to this problem is using simulation or programming models involving several issues, such as the need for some assumptions on attributes of some quantities, for example, the probability distribution of some factors <ref type=\"bibr\" target=\"#b7\">[8]</ref><ref type=\"bibr\" target=\"#b8\">[9]</ref><ref type=\"bibr\" target=\"#b9\">[10]</ref><ref type=\"bibr\" target=\"#b10\">[11]</ref>. In addition, reaching optimum or reasonable solutions is a big challenge of the bed capacity programming models, particularly in the case of large-scale, multi-objective, and integer models. Consequently, using model-free methods for HBC forecasting seems to be a facilitator. Nowadays, business analytics, including Data Analysis (DA), Machine Learning (ML), and Deep Learning (DL) techniques, are widely used as model-free methods in different businesses of services and manufacturing to reach insights on market trends, such as customers' behavior, costs, and technology by no reliance on the simulation or mathematical models <ref type=\"bibr\" target=\"#b11\">[12]</ref><ref type=\"bibr\" target=\"#b12\">[13]</ref><ref type=\"bibr\" target=\"#b13\">[14]</ref>. Also, a reasonable number of their successful applications in the healthcare sector, such as Length of Stay (LOS) forecasting, patient classification, healthcare resources forecasting, and disease diagnosis have been illustrated <ref type=\"bibr\" target=\"#b14\">[15]</ref><ref type=\"bibr\" target=\"#b15\">[16]</ref><ref type=\"bibr\" target=\"#b16\">[17]</ref><ref type=\"bibr\" target=\"#b17\">[18]</ref>. In recent years, a few researchers applied some forecaster tools of ML to predict the required The rest of the paper is as follows. Section 2 reviews the corresponding literature, and Section 3 introduces the proposed data-driven methodology. Section 4 contains the computational results of applying the proposed hybrid data-driven approach in the case study, and finally, Section 5 involves the conclusions, limitations, and recommendations for future works.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"2.\">Literature review</head><p>The literature on healthcare centers' bed capacity forecasting is reviewed to clear the paper's contributions and novelty aspects. <ref type=\"bibr\" target=\"#b21\">Bachouch et al. (2012)</ref> considered some limitations, such as budget, shared resources, and beds needed by acute and emergency patients, in the problem of hospital bed planning. Using constraints such as incompatibility between pathologies and continuity of care, an integer linear programming model was proposed, and the results were compared using several solvers such as the CPLEX <ref type=\"bibr\" target=\"#b21\">[22]</ref>. Ben Abdelaziz and Masmoudi (2012) studied the bed capacity of 157 public hospitals in Tunisia when the demand for beds is random using a multi-objective stochastic programming model to allocate the beds to the hospital's departments. In this problem, the three objectives are the total cost of creating new beds, the number of nurses and doctors, and the optimal number of beds <ref type=\"bibr\" target=\"#b10\">[11]</ref>. The healthcare capacities assessment is a matter of great importance in the same vein. <ref type=\"bibr\" target=\"#b22\">Devapriya et al. (2015)</ref> proposed a discrete-event simulation model to determine the required bed capacity using forecasted patients' volume and LOS <ref type=\"bibr\" target=\"#b22\">[23]</ref>. Also, <ref type=\"bibr\">Keegan et al. (2018)</ref> used an expanded HIPPOCRATES macrosimulation method to predict the number of beds needed for public and private hospitals in Ireland by 2030. Baseline year and projected demand and capacity profiles in this analysis are generated through the HIPPOCRATES macro-simulation model of demand and cost of health care developed by the ESRI.</p><p>The emergency department plays a vital role in the hospital because it is the first deal for patients. Therefore, the effective management of the emergency department is significant in improving the quality of service and treatment. Nas and Koyuncu (2019) used ten ML tools to predict the patients' arrival rates. They applied a simulation model to determine the required number of beds in the emergency department by minimizing the LOS in a case study in Turkey <ref type=\"bibr\" target=\"#b23\">[24]</ref>. <ref type=\"bibr\" target=\"#b24\">Kutafina et al. (2019)</ref> predicted hospital bed occupancy using recurrent neural networks based on 353520-time series records and four features from a hospital in Germany. The results show that the proposed ML model is a powerful tool for automatic planning and decision-making on existing bed capacity planning <ref type=\"bibr\" target=\"#b24\">[25]</ref>. <ref type=\"bibr\" target=\"#b25\">Zhu et al. (2020)</ref> developed three mathematical models considering the uncertainty of demand for inpatient beds and the number of periods <ref type=\"bibr\" target=\"#b25\">[26]</ref>. They solved and analyzed these models in a public hospital in China.</p><p>Predicting the required capacity of hospital wards during pandemics, such as Covid-19s, is essential for the hospital. <ref type=\"bibr\" target=\"#b9\">Deschepper et al. (2021)</ref> used an incremental Poisson model on the previous patients' statistics to establish a Mont-Carlo simulation model for a 10day prediction of needed beds in various wards of A hospital in Ghent. <ref type=\"bibr\">Haghshenas et al. (2021)</ref> proposed a bi-objective mixed-integer optimization model for Cancer hospitals' location-allocation problem under bed capacity and efficiency considerations <ref type=\"bibr\" target=\"#b26\">[27]</ref>. They forecasted the cancer incidences in the provinces of Iran in 2040 using LR models to provide a plan for cancer hospitals established in each province in some predefined efficient bed capacities. Also, they applied this forecasting method to determine the demand parameter values in a single objective mathematical model for Cancer-curing supply chain planning <ref type=\"bibr\" target=\"#b27\">[28]</ref>. The healthcare system of a country is very complex and vital, that is why <ref type=\"bibr\" target=\"#b28\">Kabir et al. (2021)</ref> used Recurrent Neural Network (RNN) to predict population growth and applied the Markov decision process to simulate the number of required beds by the next 30 years in a case study of Bangladesh <ref type=\"bibr\" target=\"#b28\">[29]</ref>. <ref type=\"bibr\" target=\"#b8\">Ordu et al. (2021)</ref> proposed a linear programming model for bed capacity and staff requirement planning in a case study in England. They also forecasted the demand for specialists with ML tools and simulated the patients' treatment pathway using a discrete-event simulation model.</p><p>It is crucial to determine the operating room bed capacity according to the critical condition of the patients. <ref type=\"bibr\">Schiele et al. (2021)</ref> predicted the bed occupancy in the Intensive Care Unit (ICU) using an Artificial Neural Network (ANN) algorithm as an ML forecaster and 6000 patients' data from 2010 to 2016 in an ICU scheduling problem in Germany. High traffic of patients in hospitals' wards, in particular the emergency department, affects the capability to provide the optimal level of care. <ref type=\"bibr\" target=\"#b18\">Tello et al. (2022)</ref> predicted weekly hospital bed capacity using LR as a forecaster per cluster of beds/day. They applied the Kmeans clustering method in SVM as the classifier of beds/day factor in a case study in the USA <ref type=\"bibr\" target=\"#b18\">[19]</ref>. <ref type=\"bibr\" target=\"#b7\">Latruwe et al. (2023)</ref> proposed a simulation model called the ProMoBed, for inpatient hospitals' bed capacity forecasting. They used LOS, seasonality, and admission data to simulate a stochastic pattern of demand for beds in a case study in Belgium <ref type=\"bibr\" target=\"#b7\">[8]</ref>. Garcia-Vincuna et al. (2023) initially predicted the LOS using linear and non-linear programming and then simulated the bed prediction for the ICU department <ref type=\"bibr\" target=\"#b29\">[30]</ref>.</p><p>The Covid epidemic sent about 19 million people to hospitals worldwide and showed the importance of forecasting during epidemics. <ref type=\"bibr\">Redondo et al. (2023)</ref> used a discrete simulation model to predict hospital discharges for Covid patients <ref type=\"bibr\" target=\"#b30\">[31]</ref>. <ref type=\"bibr\" target=\"#b31\">Bekker et al. (2023)</ref> proposed a linear programming model for predicting hospital beds in the short term. The model predicts admissions and uses a queue-based model to occupy beds, providing accurate results for three days <ref type=\"bibr\" target=\"#b31\">[32]</ref>. <ref type=\"bibr\" target=\"#b32\">Widyasari et al. (2023)</ref> predicted the bed capacity of Malahayati Hospital in Indonesia using SVM and linear programming <ref type=\"bibr\" target=\"#b32\">[33]</ref>. Covid has put a lot of pressure on healthcare resources worldwide, often challenging hospital capacity and stressing hospital staff, <ref type=\"bibr\" target=\"#b33\">Johnson et al. (2023)</ref> predicted hospital resources using time series. Results showed that statistical forecasting and ML methods can provide valuable predictions to help make resource planning decisions during epidemics <ref type=\"bibr\" target=\"#b33\">[34]</ref>.</p><p>The above-reviewed literature, summarized in Table <ref type=\"table\" target=\"#tab_0\">1</ref>, shows that the commonly used techniques in HBC forecasting have been simulation and programming models. To our best knowledge, only three researchers, including <ref type=\"bibr\">Kutafina</ref>   <ref type=\"formula\">2022</ref>), applied ML tools in the healthcare centers' bed capacity planning. These papers used time series data on occupied beds and forecast the required beds in the short-run future, and ignore the direct effects of LOS and NHP.</p><p>As illustrated in Table <ref type=\"table\" target=\"#tab_0\">1</ref>, this paper uses a wide variety of techniques from DA, ML, DL, and Statistics to investigate the nature of significant factors, such as patients' LOS, Patients' Age, and NHP, to discover their historical manner and provide valuable information to forecast HBC. In addition, conducting LOS classification to use in HBC forecasting is a unique attribute of this paper.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.\">A hybrid data-driven approach to HBC forecasting</head><p>In this section, the framework of the proposed hybrid data-driven approach to HBC forecasting is provided, and some classification and forecasting algorithms are opted according to the corresponding literature.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.1.\">New framework for HBC forecasting</head><p>As mentioned in the previous sections, factors of LOS and NHP play the most significant role in the bed capacity forecasting problem. Therefore, conducting descriptive analyses on these factors and other affecting features, for example, patient's age and bed occupancy, provides great initial insights into the problem. Consequently, the LOS classification, NHP distribution across LOS classes, and NHP forecasting are the heart of the proposed bed capacity forecasting framework. The results of these analyses are applied in a simple assumption-free mathematical model to forecast the required beds in the future. In addition, patients' age analysis could provide beneficial insight into the scatter of NHP according to Age, particularly in hospitals without specialized wards for children. Fig. <ref type=\"figure\" target=\"#fig_1\">1</ref> represents the structure and steps of the proposed framework.</p><p>According to Fig. <ref type=\"figure\" target=\"#fig_1\">1</ref>, like all data-oriented analyses, data collection and pre-processing activities, such as data set cleaning and feature transformations, are the initial conventional steps. The application of DA techniques to the three major features, including patients' Age, NHP, and patients' LOS, can provide massive great information to use in managerial prescriptive notes providing, LOS classification, and NHP forecasting. Through data analysis, some statistical inferences, such as the Hypothesis tests, might be used to verify some descriptive findings. The results of NHP forecasting and LOS-based NHP data analysis are applied in a mathematical model to forecast the hospital bed capacity. There are several algorithms for LOS classification and NHP forecasting. The following sub-sections opt for a set of algorithms that seems much more appropriate according to the literature.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.2.\">LOS classification algorithms</head><p>The LOS literature review showed that although there is a long list of research on patients' LOS forecasting, no history exists on the LOS classification <ref type=\"bibr\" target=\"#b34\">[35]</ref><ref type=\"bibr\" target=\"#b35\">[36]</ref><ref type=\"bibr\" target=\"#b36\">[37]</ref><ref type=\"bibr\" target=\"#b37\">[38]</ref>. But Patients' classification based on various features using BN, K-Nearest Neighbor (KNN), SVM, DT, ANN, AdaBoost (AB), LR, Random Forest (RF), Recency-Frequency-Monetary analysis (RFM), Gradient Boosting (GB), and Ensembles algorithms has been taken great attention, as illustrated in Table <ref type=\"table\">2</ref>.</p><p>Mentioning Table <ref type=\"table\">2</ref>, the five most popular ML algorithms, including BN, KNN, SVM, DT, and LR, are considered for LOS classification.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.3.\">NHP forecasting algorithms</head><p>Table <ref type=\"table\" target=\"#tab_1\">3</ref> shows the conventional ML and DL forecasters used in the number of patients forecasting. Considering Table <ref type=\"table\" target=\"#tab_1\">3</ref>, Time series methods are the most convenient forecaster on NHP. In addition, LR and Neural networks were the well-accurate forecasters in most literature. Therefore, SARIMA, SLR, and LSTM neural networks have opted for NHP forecasting.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.\">Case study</head><p>Rouhani Hospital is a public hospital in Babol City of Mazandaran province located in the northern band of Iran. This hospital has 508 beds, nine wards, and 391 specialists. In this hospital, the Heart ward is the busiest ward possessing 30 beds in the main hall of the Heart ward and 15 beds in the Emergency section of Heart diseases.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.1.\">Data set</head><p>The collected data set contains 51231 records between 2011 and 2018. Some features, including age and LOS, are considered to be used in the Heart ward's bed capacity forecasting problem. After removing the outliers and noisy data, 47605 records remained which 70% data are categorized as training data and others as test data.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.2.\">Data analysis</head><p>The NHP in the Heard ward, patients' age distribution, and their LOS play significant roles in the required beds forecasting. In this section, some Data analysis techniques are applied to the NHP, LOS, and Age to provide initial insights on these significant factors affecting the number of required beds equal to 25. </p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Table 2</head><p>The popular ML algorithms for patients classification. </p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Research</head></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.2.1.\">NHP descriptive analysis</head><p>Fig. <ref type=\"figure\" target=\"#fig_3\">2</ref> represents the daily NHP in the Heart ward. In this case study, some Heart patients might be hospitalized temporarily in the Emergency section of the Heart ward or other disease wards, waiting for the Heart ward beds evacuation. The reason is that NHP is over the existing bed capacity of the Heart ward on some days.</p><p>In Fig. <ref type=\"figure\" target=\"#fig_3\">2</ref>, some drastic fallings occur on NHP around the 19 March-4 April each year. Fig. <ref type=\"figure\" target=\"#fig_4\">3</ref> shows these considerable fluctuations in NHP in more detail from 2013 to 2018. All illustrated fluctuations in Fig. <ref type=\"figure\" target=\"#fig_4\">3</ref> occurred during the annual Nowruz holidays, 19 March-4 April, in Iran as the Persian new year ceremony. In this period, there is no accessibility to Heart specialists because all of them are on their private trips. Therefore, there is no new admittance during this period, and this cause to misuse of some beds and risks for patients. On the other hand, a considerable increase occurs in admittance before and after this holiday, especially from 5 April onwards. Three Hypothesis tests are performed on the mean of hospitalized patients during three 20day periods, as presented in Table <ref type=\"table\" target=\"#tab_2\">4</ref>, to investigate the significance of falling in admittance during this period.</p><p>The sample corresponding to each period is formed by pooling the patients' statistics from 2013 to 2018 to carry out the Hypothesis tests. Table <ref type=\"table\" target=\"#tab_3\">5</ref> depicts the outputs of the conducted test using the MINITAB 21.1.0.</p><p>The probability values from Table <ref type=\"table\" target=\"#tab_3\">5</ref> show considerable differences between the mean of patients' admittance during BNH and NH, like     </p><formula xml:id=\"formula_0\">1 𝐻 0 ∶ 𝜇 𝐵𝑁𝐻 = 𝜇 𝑁𝐻 𝐻 1 ∶ 𝜇 𝐵𝑁𝐻 ≠ 𝜇 𝑁𝐻 120 0 2 𝐻 0 ∶ 𝜇 𝑃 𝑁𝐻 = 𝜇 𝑁𝐻 𝐻 1 ∶ 𝜇 𝑃 𝑁𝐻 ≠ 𝜇 𝑁𝐻 120 0 3 𝐻 0 ∶ 𝜇 𝐵𝑁𝐻 = 𝜇 𝑃 𝑁𝐻 𝐻 1 ∶ 𝜇 𝐵𝑁𝐻 ≠ 𝜇 𝑃 𝑁𝐻 120 0.175</formula><p>PNH and NH. Moreover, the p-value=0.175 shows no significant difference between the mean of patients' admittance along BNH and PNH according to corresponding collected data and conventional significance level 0.05. These results verify the conducted data-driven visual inferences from Fig. <ref type=\"figure\" target=\"#fig_3\">2</ref>.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.2.2.\">Age-based NHP descriptive analysis</head><p>Fig. <ref type=\"figure\" target=\"#fig_5\">4</ref> represents that the NHP follows a bimodal pattern according to the patient's age. In addition, the most significant portion of NHP belongs to patients aged between 45 and 85. Using information represented in Fig. <ref type=\"figure\" target=\"#fig_5\">4</ref>, six classes of are considered, including (0,15], <ref type=\"bibr\" target=\"#b14\">(15,</ref><ref type=\"bibr\" target=\"#b29\">30]</ref>, <ref type=\"bibr\" target=\"#b29\">(30,</ref><ref type=\"bibr\" target=\"#b44\">45]</ref>, <ref type=\"bibr\" target=\"#b44\">(45,</ref><ref type=\"bibr\" target=\"#b59\">60]</ref>, <ref type=\"bibr\" target=\"#b59\">(60,</ref><ref type=\"bibr\">85]</ref>, and (85,99], as depicted in Table <ref type=\"table\" target=\"#tab_4\">6</ref>.</p><p>Although Table <ref type=\"table\" target=\"#tab_4\">6</ref> shows that children's class only involves six percent of total NHP, its share is considerable enough to provide specialized proper room in the Heart ward or even a particular children's Heart ward regarding their special emotional considerations. Another interesting note in Fig. <ref type=\"figure\" target=\"#fig_5\">4</ref> is that the mean age of children hospitalized with Heart issues is about 7. By conducting some diagnostic analyses on the modal nature of children's NHP, the roots of this manner would be investigated and might be beneficial in children's Heart disease treatment management and even prevention in the future. Fig. <ref type=\"figure\" target=\"#fig_6\">5</ref> illustrates  the fact that the rate of admittance is increasing only among people aged between 30 and 60. Fig. <ref type=\"figure\" target=\"#fig_6\">5</ref> illustrates that the admittance of people of age class <ref type=\"bibr\" target=\"#b29\">(30,</ref><ref type=\"bibr\" target=\"#b44\">45</ref>] has taken more and more acceleration. In other words, Heart diseases are becoming more common over the past between younger individuals. This fact allocates more credit to promoting preventive actions on Heart disease in the public.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.2.3.\">LOS descriptive analysis</head><p>Fig. <ref type=\"figure\" target=\"#fig_7\">6</ref> represents the patients' LOS distribution. In Fig. <ref type=\"figure\" target=\"#fig_7\">6</ref>, only a few LOSs are too long, and most seem to be less than ten days. This claim is verified in Figs. <ref type=\"figure\">7 and 8</ref>, representing the scatter of NHP in terms of LOS.</p><p>Table <ref type=\"table\" target=\"#tab_5\">7</ref> represents the share of the first twenty values of LOS in terms of NHP to investigate the frequency of LOS values in detail.</p><p>Table <ref type=\"table\" target=\"#tab_5\">7</ref> shows that LOS=1 makes the role of the first to fourth deciles lonely as the first quartile, LOS=2 is the fifth and sixth deciles as the second quartile, LOS=4 is the third quartile, LOS=3 is the seventh decile, LOS=6 is the eighth decile, and LOS=11 is the ninth decile. Also, more than 95.5 percent of patients stay less than 20 days. This information helps to form appropriate classes of LOS.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.3.\">LOS classification</head><p>Several sets of LOS classes are made, and their accuracy is examined using several classification tools coded using the Sklearn library of Python, as presented in Table <ref type=\"table\">8</ref>. In Table <ref type=\"table\">8</ref>, the classification results show that SVM provides the best accuracy and introduces the case of six classes of LOS as the best alternative. Table <ref type=\"table\" target=\"#tab_6\">9</ref> depicts the information on NHP and the time interval of LOS classes. Table <ref type=\"table\" target=\"#tab_6\">9</ref> illustrates only 6% of patients experienced LOS for more than 15 days, and most would stay in the Heart ward for only one day. In addition, Table <ref type=\"table\" target=\"#tab_7\">10</ref> presents detailed information on the NHP distribution in each Age class per LOS class.</p><p>In Table <ref type=\"table\" target=\"#tab_7\">10</ref>, the lowest proportion of NHP from the first class of LOS, LOS=1, comes from the eldest people's class which seems reasonable because of the more Heart risk and need for continual health monitoring in this class. But the following place is allocated to children means the admittance of this type of Heart patient tends to be longer over other Age classes. A more diagnostic analysis could provide helpful information to make better decisions on the specialized Heart beds for children because the children's class possesses the first rank in the proportion of NHP allocated to the long LOS class. This situation assigns crucial importance to establishing specialized children's Heart wards in the future.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.4.\">NHP forecasting</head><p>Table <ref type=\"table\" target=\"#tab_0\">11</ref> summarizes the results of applying three opted forecasters in Section 3.3 using Python libraries.</p><p>As illustrated in Table <ref type=\"table\" target=\"#tab_0\">11</ref>, LR opted for forecasting NHP in the future due to providing the least error index. The mentioned hospital was the main center for COVID-19 patients' treatment in Babol City between 2019 and 2021, and hence, the daily NHP is forecasted for the five years from 2022 to 2026.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.5.\">Heart ward bed capacity forecasting</head><p>According to Fig. <ref type=\"figure\" target=\"#fig_1\">1</ref>, the forecasted NHP and LOS-based distribution of NHP should be applied to forecast the Heart ward bed capacity in the future. The proportion of NHP in LOS classes, from Table <ref type=\"table\" target=\"#tab_6\">9</ref>, is applied to forecast the NHP belonging to each LOS class in the future. It is supposed that the expected nights/beds corresponding to LOS classes are equal to 1, 2, 3, 5, 11, and 22, respectively. Eq. ( <ref type=\"formula\" target=\"#formula_1\">1</ref>) uses the forecasted NHP of LOS classes to predict the required daily beds     between 2022 and 2026 (see Fig. <ref type=\"figure\" target=\"#fig_9\">9</ref>).</p><formula xml:id=\"formula_1\">𝐻𝐵𝐶 𝑗 = ∑ 𝑖 𝑁𝐻𝑃 𝑖𝑗 + ∑ 𝑖≥2 𝑁𝐻𝑃 𝑖,𝑗−1 + ∑ 𝑖≥3 𝑁𝐻𝑃 𝑖,𝑗−2 + ∑ 𝑖≥4 𝑗−3 ∑ 𝑘=𝑗−4 𝑁𝐻𝑃 𝑖𝑘 + ∑ 𝑖≥5 𝑗−5 ∑ 𝑘=𝑗−10 𝑁𝐻𝑃 𝑖𝑘 + 𝑗−11 ∑ 𝑘=𝑗−20 𝑁𝐻𝑃 6,𝑘 𝑖 = 1, 2, … , 6; 𝑗 = 1, 2, … , 1825<label>(1)</label></formula><p>In Eq. ( <ref type=\"formula\" target=\"#formula_1\">1</ref>), i is the index of LOS classes, and j denotes the order of days between 2022 and 2027. Also, 𝑁𝐻𝑃 𝑖𝑗 represents the NHP belonging to the 𝑖th class of LOS that will be admitted in the Heart during day j, and 𝐻𝐵𝐶 𝑗 denotes the needed beds in day j. Fig. <ref type=\"figure\" target=\"#fig_10\">10</ref> illustrates the forecasted HBC in Heart ward from 1 January 2022 to 31 December 2026. Fig. <ref type=\"figure\" target=\"#fig_10\">10</ref> represents drastic increase in the number of required beds because the older hospitalized patients not considered and the calculation only is dependent on the forthcoming NHPs. In this Figure, the average needed bed capacity in the future is forecasted at 120 beds which is much more than the existing 45 beds. Therefore, this hospital's administration should make strategic decisions to increase the bed capacity of the Heart ward from 45 beds to 137 beds by 2026.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.6.\">Managerial insights</head><p>In section 4.3.1, the NHP descriptive analysis showed a type of mismanagement in the use of the existing bed capacity in the Heart ward during about 20 days per year related to the Persian new year holidays. Therefore, some managerial tasks and cultural efforts are needed to provide an equitable shift working for Heart specialists during the new year holidays avoiding empty beds. This could result in sustainable Heart bed capacity in terms of productivity and reliable treatment for high risks Heart patients. In addition, Tables <ref type=\"table\" target=\"#tab_7\">6 and  10</ref> showed that children are a considerable ratio of Heart patients, and a noticeable proportion of them require too long LOS. Therefore, establishing an appropriate specialized Heart room or Heart ward for children must be a significant goal of the hospital's authorities. Also, Fig. <ref type=\"figure\" target=\"#fig_10\">10</ref> represented the need for 117 beds in the Heart ward from 2022 upward. Providing proper facilities to establish per specialized Heart bed requires a considerable budget. Hence, conducting financial analysis to estimate the needed resources such as money is inevitable, particularly in a developing country such as Iran with tremendous limits on monitorial resources.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"5.\">Conclusions, limitations, and recommendations</head><p>This paper considered the hospital bed capacity forecasting problem and proposed a Data-driven methodology to avoid the limits and difficulties of using traditional programming or simulation models. A hybrid approach involving DA, ML, DL, and statistical inference was applied in a Heart ward bed capacity forecasting. Results showed the need for establishing more beds in the Heart ward from 26 to 137 in 2027. In addition, more considerations on the child Heart patients' treatment and the increasing trend of the occurring Heart diseases among younger people are recommended by results.</p><p>This paper only focused on HBC forecasting and paid no attention to other required resources such as Specialists, Nurses, Equipment, and Budget. Forecasting these significant factors could provide beneficial information for decision-makers. In addition, some other factors can affect the NHP of a hospital in the future, such as insurance service level, the accessibility to other hospitals, the service quality level, limits on the number of available corresponding specialists, the number of specialized equipment, the economic conditions, and the people's accessibility to periodic checkup. This needs to use multivariate time series data sets and multivariate ML tools in future works. Also, uncertainty is an inevitable fact in decision-making that could be mentioned in the future use of DA, ML, and DL for HBC forecasting.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Ethical statement</head><p>The Authors declare that no real clinical data is applied in this paper.</p></div><figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_0\"><head></head><label></label><figDesc>et al. (2019), Schiele et al. (2021), and Tello et al. (</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_1\"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The schematic representation of the proposed hybrid data-driven HBC forecasting.</figDesc><graphic coords=\"4,125.73,56.05,351.65,342.01\" type=\"bitmap\" /></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_2\"><head></head><label></label><figDesc>Fathi et al. (2020) [42] ✓ Maniruzzaman et al (2020) [43] ✓ ✓ ✓ Rahman et al. (2020) [38] ✓ Badriyah et al. (2020)<ref type=\"bibr\" target=\"#b43\">[44]</ref> </figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_3\"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The historical daily NHP in the Heart ward.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_4\"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The details of significant decreases in NHP in March per year.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_5\"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The age-based distribution of NHP.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_6\"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The NHP-share trend per Age class.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_7\"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The LOS distribution of Heart patients.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_8\"><head>Fig. 7 . 8 .</head><label>78</label><figDesc>Fig. 7. The NHP with a LOS of less than 31 days.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_9\"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. The forecasted daily NHP between 2022 and 2027.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_10\"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. The forecasted HBC in Heart ward.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_0\"><head>Table 1</head><label>1</label><figDesc>Hospital bed capacity forecasting literature.</figDesc><table><row><cell>Attribute</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Research</cell><cell>Programming</cell><cell>Simulation</cell><cell>Mathematical</cell><cell>Data</cell><cell>Machine</cell><cell>Deep</cell><cell>Statistical</cell><cell>LOS</cell></row><row><cell></cell><cell>model</cell><cell></cell><cell>model</cell><cell>analysis</cell><cell>learning</cell><cell>learning</cell><cell>inference</cell><cell>classification</cell></row><row><cell>Bachouch et al. (2012)</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ben Abdelaziz and</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Masmoudi (2012)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Devapriya et al. (2015)</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Keegan et al. (2018)</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Nas and Koyuncu</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(2019)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Kutafina et al. (2019)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Zhu et al. (2020)</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Deschepper et al.</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(2021)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Haghshenas et al.</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(2021)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Kabir et al. (2021)</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell></cell></row><row><cell>Ordu et al. (2021)</cell><cell>✓</cell><cell>✓</cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Schiele et al. (2021)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Tello et al. (2022)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Latruwe et al. (2023)</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Garcia-Vincuna et al.</cell><cell>✓</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(2023)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Redondo et al. (2023)</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Bekker et al. (2023)</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Widyasari et al. (2023)</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Johnson et al. (2023)</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>This paper</cell><cell></cell><cell></cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_1\"><head>Table 3</head><label>3</label><figDesc>The popular ML/DL algorithms for the number of patients forecasting.</figDesc><table><row><cell>Research</cell><cell>Forecasters</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Time series</cell><cell>Neural networks</cell><cell>DT</cell><cell>Regression</cell><cell>GB</cell><cell>LR</cell><cell>SVM</cell><cell>RF</cell><cell>KNN</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>logistics</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Bergs et al. (2014) [50]</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Mai et al. (2015) [51]</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ekström et al. (2015) [52]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell></cell></row><row><cell>Luo et al. (2017) [53]</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Byron et al. (2018) [54]</cell><cell></cell><cell></cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Khalid et al. (2019) [55]</cell><cell>✓</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sahai et al. (2020) [56]</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Rustam et al. (2020) [57]</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell>✓</cell><cell></cell></row><row><cell>Agrawal et al. (2021) [58]</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Vollmer et al. (2021) [59]</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell>✓</cell><cell></cell><cell>✓</cell><cell>✓</cell></row><row><cell>Sudarshan et al. (2021) [60]</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>✓</cell></row><row><cell>Famiglini et al. (2022) [61]</cell><cell></cell><cell>✓</cell><cell>✓</cell><cell></cell><cell>✓</cell><cell></cell><cell>✓</cell><cell></cell></row><row><cell>Petsis et al. (2022) [62]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Vieira et al. (2023) [63]</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Alvarez-Chaves et al. (2023) [64]</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell></row><row><cell>This paper</cell><cell>✓</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell></cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_2\"><head>Table 4</head><label>4</label><figDesc>The considered periods for testing the significance of NHP fluctuations.</figDesc><table><row><cell>No</cell><cell>Period</cell><cell>Abbreviation</cell><cell>Time duration</cell><cell>Mean of NHP</cell></row><row><cell>1</cell><cell>Before Nowruz holidays</cell><cell>BNH</cell><cell>23 February-14 March</cell><cell>𝜇 𝐵𝑁𝐻</cell></row><row><cell>2</cell><cell>Nowruz holidays</cell><cell>NH</cell><cell>15 March-4 April</cell><cell>𝜇 𝑁𝐻</cell></row><row><cell>3</cell><cell>Post Nowruz holidays</cell><cell>PNH</cell><cell>5 April-23 April</cell><cell>𝜇 𝑃 𝑁𝐻</cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_3\"><head>Table 5</head><label>5</label><figDesc>The results of the hypothesis tests.</figDesc><table><row><cell>No</cell><cell>Hypothesis test</cell><cell>Sample size</cell><cell>P-Value</cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_4\"><head>Table 6</head><label>6</label><figDesc>The proportion of NHP in each age class.</figDesc><table><row><cell>No of Class</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell></row><row><cell>Age Range</cell><cell>0-15</cell><cell>15-30</cell><cell></cell><cell>45-60</cell><cell>60-85</cell><cell>85-99</cell></row><row><cell>NHP</cell><cell>2641</cell><cell>1617</cell><cell>3994</cell><cell>11745</cell><cell>24266</cell><cell>3342</cell></row><row><cell>Proportion</cell><cell>0/06</cell><cell>0/03</cell><cell>0/08</cell><cell>0/25</cell><cell>0/51</cell><cell>0/07</cell></row><row><cell>Cumulative</cell><cell>0/06</cell><cell>0/09</cell><cell>0/17</cell><cell>0/42</cell><cell>0/93</cell><cell>1</cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_5\"><head>Table 7</head><label>7</label><figDesc>The share of each LOS in terms of NHP.</figDesc><table><row><cell></cell><cell>LOS</cell><cell>NHP</cell><cell cols=\"2\">Proportion</cell><cell>Cumulative</cell><cell>LOS</cell><cell>NHP</cell><cell>Proportion</cell><cell>Cumulative</cell></row><row><cell></cell><cell>1</cell><cell>22787</cell><cell>0.478668</cell><cell></cell><cell>0.478668</cell><cell>11</cell><cell>539</cell><cell>0.011322</cell><cell>0.901754</cell></row><row><cell></cell><cell>2</cell><cell>6589</cell><cell>0.13841</cell><cell></cell><cell>0.617078</cell><cell>12</cell><cell>462</cell><cell>0.009705</cell><cell>0.911459</cell></row><row><cell></cell><cell>3</cell><cell>4187</cell><cell>0.087953</cell><cell></cell><cell>0.705031</cell><cell>13</cell><cell>400</cell><cell>0.008402</cell><cell>0.919861</cell></row><row><cell></cell><cell>4</cell><cell>2526</cell><cell>0.053062</cell><cell></cell><cell>0.758093</cell><cell>14</cell><cell>397</cell><cell>0.008339</cell><cell>0.928201</cell></row><row><cell></cell><cell>5</cell><cell>1762</cell><cell>0.037013</cell><cell></cell><cell>0.795106</cell><cell>15</cell><cell>282</cell><cell>0.005924</cell><cell>0.934125</cell></row><row><cell></cell><cell>6</cell><cell>1319</cell><cell>0.027707</cell><cell></cell><cell>0.822813</cell><cell>16</cell><cell>232</cell><cell>0.004873</cell><cell>0.938998</cell></row><row><cell></cell><cell>7</cell><cell>1109</cell><cell>0.023296</cell><cell></cell><cell>0.846109</cell><cell>17</cell><cell>214</cell><cell>0.004495</cell><cell>0.943493</cell></row><row><cell></cell><cell>8</cell><cell>805</cell><cell>0.01691</cell><cell></cell><cell>0.863019</cell><cell>18</cell><cell>219</cell><cell>0.0046</cell><cell>0.948094</cell></row><row><cell></cell><cell>9</cell><cell>707</cell><cell>0.014851</cell><cell></cell><cell>0.87787</cell><cell>19</cell><cell>194</cell><cell>0.004075</cell><cell>0.952169</cell></row><row><cell></cell><cell>10</cell><cell>598</cell><cell>0.012562</cell><cell></cell><cell>0.890432</cell><cell>20</cell><cell>140</cell><cell>0.002941</cell><cell>0.95511</cell></row><row><cell>Table 8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols=\"2\">The accuracy of LOS classifiers.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Classifier</cell><cell cols=\"2\">Number of classes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell></cell><cell></cell></row><row><cell>SVM</cell><cell>63%</cell><cell>55%</cell><cell>71%</cell><cell>48%</cell><cell>51%</cell><cell></cell><cell></cell></row><row><cell>DT</cell><cell>64%</cell><cell>49%</cell><cell>69%</cell><cell>46%</cell><cell>49%</cell><cell></cell><cell></cell></row><row><cell>LR</cell><cell>52%</cell><cell>43%</cell><cell>48%</cell><cell>40%</cell><cell>42%</cell><cell></cell><cell></cell></row><row><cell>KNN</cell><cell>46%</cell><cell>43%</cell><cell>47%</cell><cell>42%</cell><cell>42%</cell><cell></cell><cell></cell></row><row><cell>BN</cell><cell>40%</cell><cell>36%</cell><cell>39%</cell><cell>35%</cell><cell>40%</cell><cell></cell><cell></cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_6\"><head>Table 9</head><label>9</label><figDesc>The proportion of NHP per LOS classes.</figDesc><table><row><cell>No</cell><cell>LOS range</cell><cell>NHP</cell><cell>Proportion</cell><cell>Cumulative</cell></row><row><cell>1</cell><cell>1</cell><cell>22787</cell><cell>0/48</cell><cell>0/48</cell></row><row><cell>2</cell><cell>2</cell><cell>6589</cell><cell>0/14</cell><cell>0/62</cell></row><row><cell>3</cell><cell>3</cell><cell>4187</cell><cell>0/09</cell><cell>0/71</cell></row><row><cell>4</cell><cell>[4,6]</cell><cell>5607</cell><cell>0/12</cell><cell>0/83</cell></row><row><cell>5</cell><cell>[7,15]</cell><cell>5299</cell><cell>0/11</cell><cell>0/94</cell></row><row><cell>6</cell><cell>[16,730]</cell><cell>3136</cell><cell>0/06</cell><cell>1</cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_7\"><head>Table 10</head><label>10</label><figDesc>The NHP partitioning according to Age and LOS classes.</figDesc><table><row><cell>LOS range</cell><cell>Age range</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>(0,15]</cell><cell>(15,30]</cell><cell>(30,45]</cell><cell>(45,60]</cell><cell>(60,85]</cell><cell>(85,99]</cell></row><row><cell>1</cell><cell>891</cell><cell>765</cell><cell>2082</cell><cell>6841</cell><cell>11365</cell><cell>843</cell></row><row><cell>2</cell><cell>498</cell><cell>314</cell><cell>667</cell><cell>1551</cell><cell>3185</cell><cell>374</cell></row><row><cell>3</cell><cell>462</cell><cell>161</cell><cell>288</cell><cell>736</cell><cell>2134</cell><cell>406</cell></row><row><cell>[4,6]</cell><cell>209</cell><cell>133</cell><cell>358</cell><cell>1072</cell><cell>2963</cell><cell>872</cell></row><row><cell>[7,15]</cell><cell>302</cell><cell>122</cell><cell>228</cell><cell>1097</cell><cell>3101</cell><cell>449</cell></row><row><cell>[16,730]</cell><cell>223</cell><cell>38</cell><cell>145</cell><cell>592</cell><cell>1895</cell><cell>243</cell></row><row><cell>Table 11</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols=\"2\">The results of NHP forecasting.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols=\"2\">Forecasting algorithm</cell><cell cols=\"2\">Python library</cell><cell>Fitted model</cell><cell></cell><cell>RMSE</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>specifications</cell><cell></cell><cell></cell></row><row><cell>SARIMA</cell><cell></cell><cell>Statsmodels</cell><cell></cell><cell cols=\"2\">𝑃 = 0, 𝐷 = 1, 𝑄 = 1</cell><cell>9.5</cell></row><row><cell>LR</cell><cell></cell><cell>Sklearn</cell><cell></cell><cell>Slope=-0.0027 ,</cell><cell></cell><cell>8.6</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Intercept=16.71</cell><cell></cell><cell></cell></row><row><cell cols=\"2\">LSTM Neural Network</cell><cell>Keras</cell><cell></cell><cell cols=\"2\">Three hidden layers</cell><cell>9.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols=\"2\">with 300, 150, and</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>100 neurons,</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols=\"2\">respectively, and</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>epoch=1000</cell><cell></cell><cell></cell></row></table></figure>\n",
      "\t\t</body>\n",
      "\t\t<back>\n",
      "\n",
      "\t\t\t<div type=\"availability\">\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Data and code availability statement</head><p>The Authors would submit the related data set and codes whenever a request is received.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Data availability</head><p>Data will be made available on request.</p></div>\n",
      "\t\t\t</div>\n",
      "\n",
      "\n",
      "\t\t\t<div type=\"funding\">\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Funding statement</head><p>This research received no specific grant from any funding agency in the public, commercial, or not-for-profit sectors.</p></div>\n",
      "\t\t\t</div>\n",
      "\n",
      "\t\t\t<div type=\"annex\">\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Declaration of competing interest</head><p>The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p></div>\t\t\t</div>\n",
      "\t\t\t<div type=\"references\">\n",
      "\n",
      "\t\t\t\t<listBibl>\n",
      "\n",
      "<biblStruct xml:id=\"b0\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A model to compare international hospital bed numbers, including a case study on the role of indigenous people on acute occupied bed demand in australian states</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><forename type=\"middle\">P</forename><surname>Jones</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/ijerph191811239</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.3390/ijerph191811239\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Int. J. Environ. Res. Public Health</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">19</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">18</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">11239</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b1\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Models and methods for determining the optimal number of beds in hospitals and regions: a systematic scoping review</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><surname>Ravaghi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Alidoost</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1787/health_glance-2017-en</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1787/health_glance-2017-en\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">BMC Health Serv. Res</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">20</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"13\" />\n",
      "\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b2\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">A model to forecast regional demand for COVID-19 related hospital beds</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">O</forename><surname>Ferstad</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Gu</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1101/2020.03.26.20044842</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1101/2020.03.26.20044842,med-archive\" />\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b3\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">How many medical beds does a country need?</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><forename type=\"middle\">P</forename><surname>Jones</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.12968/bjhc.2020.0028</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.12968/bjhc.2020.0028\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Br. J. Health Care Manag</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">26</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">9</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"248\" to=\"259\" />\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b4\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">How many beds? Capacity implications of hospital care demand projections in the irish hospital system</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">C</forename><surname>Keegan</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Brick</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1002/hpm.2673</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1002/hpm.2673\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Br. J. Health Care Manag</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">34</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">1</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"e569\" to=\"e582\" />\n",
      "\t\t\t<date type=\"published\" when=\"2015\">2015-2030. 2019</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b5\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">Reducing Hospital Beds: What are the Lessons To Be Learned?</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Mckee</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<ptr target=\"https://apps.who.int/iris/handle/10665/107615\" />\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2004\">2004</date>\n",
      "\t\t\t<publisher>W. H. Organization</publisher>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b6\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">How many hospital beds?</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">L</forename><forename type=\"middle\">V</forename><surname>Green</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.5034/inquiryjrnl_39.4.400</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.5034/inquiryjrnl_39.4.400\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Inq. J. Health Care Org. Pro. Fin</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">39</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">4</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"400\" to=\"412\" />\n",
      "\t\t\t<date type=\"published\" when=\"2002\">2002</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b7\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A long-term forecasting and simulation model for strategic planning of hospital bed capacity</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">T</forename><surname>Latruwe</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Van Der Wee</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.orhc.2022.100375</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.orhc.2022.100375\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Oper. Res. Health Care</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">36</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">100375</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2023\">2023</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b8\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A novel healthcare resource allocation decision support tool: A forecasting-simulation-optimization approach</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Ordu</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">E</forename><surname>Demir</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1080/01605682.2019.1700186</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1080/01605682.2019.1700186\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">J. Oper. Res. Soc</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">72</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">3</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"485\" to=\"500\" />\n",
      "\t\t\t<date type=\"published\" when=\"2021\">2021</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b9\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Prediction of hospital bed capacity during the COVID-19 pandemic</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Deschepper</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">K</forename><surname>Eeckloo</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1186/s12913-021-06492-3</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1186/s12913-021-06492-3\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">BMC Health Serv. Res</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">21</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">1</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"10\" />\n",
      "\t\t\t<date type=\"published\" when=\"2021\">2021</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b10\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A multiobjective stochastic program for hospital bed planning</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">F</forename><surname>Ben Abdelaziz</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Masmoudi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1057/jors.2011.39</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1057/jors.2011.39\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">J. Oper. Res. Soc</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">63</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">4</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"530\" to=\"538\" />\n",
      "\t\t\t<date type=\"published\" when=\"2012\">2012</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b11\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Artificial intelligence in business: State of the art and future research agenda</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">M C</forename><surname>Loureiro</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><surname>Guerreiro</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">I</forename><surname>Tussyadiah</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.jbusres.2020.11.001</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.jbusres.2020.11.001\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">J. Bus. Res</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">129</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"911\" to=\"926\" />\n",
      "\t\t\t<date type=\"published\" when=\"2021\">2021</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b12\">\n",
      "\t<analytic>\n",
      "\t\t<title/>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Akerkar</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Artificial Intelligence for Business</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2019\">2019</date>\n",
      "\t\t\t<publisher>Springer</publisher>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b13\">\n",
      "\t<monogr>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">W</forename><forename type=\"middle\">R</forename><surname>Paczkowski</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<title level=\"m\">Business Analytics: Data Science for Business Problems</title>\n",
      "\t\t\t\t<imprint>\n",
      "\t\t\t<publisher>Springer Nature</publisher>\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b14\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Data analytics in pharmaceutical supply chains: state of the art, opportunities, and challenges</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Nguyen</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Lamouri</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1080/00207543.2021.1950937</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1080/00207543.2021.1950937\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Int. J. Prod. Res</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">60</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">22</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"6888\" to=\"6907\" />\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b15\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">The Health Care Data Guide: Learning from Data for Improvement</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">L</forename><forename type=\"middle\">P</forename><surname>Provost</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">K</forename><surname>Murray</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t\t<publisher>John Wiley &amp; Sons</publisher>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b16\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Utilization of artificial intelligence in disease prevention: Diagnosis, treatment, and implications for the healthcare workforce</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">U D</forename><surname>Wani</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">N</forename><forename type=\"middle\">A</forename><surname>Khan</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/healthcare10040608</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.3390/healthcare10040608\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Healthcare</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">10</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">4</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">608</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b17\">\n",
      "\t<monogr>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">K</forename><surname>Santosh</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">L</forename><surname>Gaur</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<title level=\"m\">Artificial Intelligence and Machine Learning in Public Healthcare: Opportunities and Societal Impact</title>\n",
      "\t\t\t\t<imprint>\n",
      "\t\t\t<publisher>Springer Nature</publisher>\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b18\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Machine learning based forecast for the prediction of inpatient bed demand</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Tello</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">E</forename><forename type=\"middle\">S</forename><surname>Reich</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1186/s12911-022-01787-9</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1186/s12911-022-01787-9\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">BMC Medical Inform. Decis. Mak</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">22</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">1</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"13\" />\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b19\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Predicting intensive care unit bed occupancy for integrated operating room scheduling via neural networks</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><surname>Schiele</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">T</forename><surname>Koperna</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">O</forename><surname>Brunner</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Nav. Res. Logist</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">68</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">1</biblScope>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b20\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Insights from a machine learning model for predicting the hospital length of stay (LOS) at the time of admission</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">L</forename><surname>Turgeman</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">H</forename><surname>May</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Sciulli</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.eswa.2017.02.023</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.eswa.2017.02.023\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Expert Syst. Appl</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">78</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"376\" to=\"385\" />\n",
      "\t\t\t<date type=\"published\" when=\"2017\">2017</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b21\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">An integer linear model for hospital bed planning</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><forename type=\"middle\">B</forename><surname>Bachouch</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Guinet</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Hajri-Gabouj</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.ijpe.2012.07.023</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.ijpe.2012.07.023\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Int. J. Prod. Econ</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">140</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">2</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"833\" to=\"843\" />\n",
      "\t\t\t<date type=\"published\" when=\"2012\">2012</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b22\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Stratbam: a discrete-event simulation model to support strategic hospital bed capacity decisions</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">P</forename><surname>Devapriya</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">C</forename><forename type=\"middle\">T B</forename><surname>Strömblad</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1007/s10916-015-0325-0</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1007/s10916-015-0325-0\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">J. Med. Syst</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">39</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">10</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"13\" />\n",
      "\t\t\t<date type=\"published\" when=\"2015\">2015</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b23\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Emergency department capacity planning: a recurrent neural network and simulation approach</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Nas</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Koyuncu</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1155/2019/4359719</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1155/2019/4359719\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Comput. Math. Methods Med</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2019\">2019</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b24\">\n",
      "\t<analytic>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">E</forename><surname>Kutafina</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">I</forename><surname>Bechtold</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1186/s12911-019-0776-1</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1186/s12911-019-0776-1\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\">Recursive neural networks in hospital bed occupancy forecasting</title>\n",
      "\t\t\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2019\">2019</date>\n",
      "\t\t\t<biblScope unit=\"volume\">19</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"10\" />\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b25\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Data-driven models for capacity allocation of inpatient beds in a Chinese public hospital</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">T</forename><surname>Zhu</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">P</forename><surname>Liao</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1155/2020/8740457</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1155/2020/8740457\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Comput. Math. Methods Med</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b26\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A bi-objective model for cancer hospitals&apos; location and cancer patients&apos; allocation in, Iran</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Haghshenas</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Nemati</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">E</forename><surname>Asadi-Gangraj</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Int. J. Hos. Res</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">10</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">4</biblScope>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "\t<note>2021) ijhr.iums.ac.ir.</note>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b27\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Cancer-curing supply chain planning with regard to hospital bed-capacity efficiency: a plan for Iran in 2040</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Haghshenas</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Nemati</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">E</forename><surname>Asadi-Gangraj</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1504/IJSOM.2023.131495</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1504/IJSOM.2023.131495\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Int. J. Serv. Oper. Manag</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">45</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">2</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"170\" to=\"186\" />\n",
      "\t\t\t<date type=\"published\" when=\"2023\">2023</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b28\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">Use of machine learning for long term planning and cost minimization in healthcare management</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">B</forename><surname>Kabir</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">S</forename><surname>Shuvo</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><forename type=\"middle\">U</forename><surname>Ahmed</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1101/2021.10.06.21264654</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1101/2021.10.06.21264654,med-archive\" />\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2021\">2021</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b29\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Estimation of patient flow in hospitals using up-to-date data. Application to bed demand prediction during pandemic waves</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">D</forename><surname>Garcia-Vicuña</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>López-Cheda</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1371/journal.pone.0282331</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1371/journal.pone.0282331\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">PLoS One</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">18</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">2</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">e0282331</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2023\">2023</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b30\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">A simulation model for predicting hospital occupancy for Covid-19 using archetype analysis</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">E</forename><surname>Redondo</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">V</forename><surname>Nicoletta</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.health.2023.100197</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.health.2023.100197\" />\n",
      "\t\t<imprint/>\n",
      "\t</monogr>\n",
      "\t<note>HealthCare Anal. 3 (2023) 100197</note>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b31\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Modeling COVID-19 hospital admissions and occupancy in the netherlands</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Bekker</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Broek</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>Koole</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.ejor.2021.12.044</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.ejor.2021.12.044\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">European J. Oper. Res</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">304</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">1</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"207\" to=\"218\" />\n",
      "\t\t\t<date type=\"published\" when=\"2023\">2023</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b32\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">An optimization model for hospital emergency room based on patient growth and capacity management</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Widyasari</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><surname>Cipta</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Nasution</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.33395/sinkron.v8i1.11890</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.33395/sinkron.v8i1.11890\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Sinkron: J. Dan Penel. Tekn. Inf</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">8</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">1</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"188\" to=\"194\" />\n",
      "\t\t\t<date type=\"published\" when=\"2023\">2023</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b33\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Forecasting ward-level bed requirements to aid pandemic resource planning: Lessons learned and future directions</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">R</forename><surname>Johnson</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><surname>Naik</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1007/s10729-023-09639-2</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1007/s10729-023-09639-2\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Health Care Manag. Sci</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"24\" />\n",
      "\t\t\t<date type=\"published\" when=\"2023\">2023</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b34\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Hospital patients&apos; length of stay prediction: A federated learning approach</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">M</forename><surname>Rahman</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">D</forename><surname>Kundu</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1007/s10729-023-09639-2</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1007/s10729-023-09639-2\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">J. King Saud Univ. Comput. Inf. Sci</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">34</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">10</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"7874\" to=\"7884\" />\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b35\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">State of asthma-related hospital admissions in New Zealand and predicting length of stay using machine learning</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">W</forename><forename type=\"middle\">K D</forename><surname>Jayamini</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">F</forename><surname>Mirza</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/app12199890</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.3390/app12199890\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Appl. Sci</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">12</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">19</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">9890</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b36\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A machine learning algorithm predicts duration of hospitalization in COVID-19 patients</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><surname>Ebinger</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Wells</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.ibmed.2021.100035</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.ibmed.2021.100035\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Intell. Based. Med</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">5</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">100035</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2021\">2021</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b37\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Using data mining to predict emergency department length of stay greater than 4 hours: Derivation and single-site validation of a decision tree algorithm</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">A</forename><surname>Rahman</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">B</forename><surname>Honan</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1111/1742-6723.13421</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1111/1742-6723.13421\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Emerg. Med. Australas</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">32</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">3</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"416\" to=\"421\" />\n",
      "\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b38\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A data mining approach for modeling churn behavior via RFM model in specialized clinics case study: A public sector hospital in tehran</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Mohammadzadeh</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Z</forename><forename type=\"middle\">Z</forename><surname>Hoseini</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><surname>Derafshi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.procs.2017.11.206</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.procs.2017.11.206\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Procedia Comput. Sci</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">120</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"23\" to=\"30\" />\n",
      "\t\t\t<date type=\"published\" when=\"2017\">2017</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b39\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Use of data mining techniques to classify length of stay of emergency department patients</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>Sariyer</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">C</forename><forename type=\"middle\">Ö</forename><surname>Taşar</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><forename type=\"middle\">E</forename><surname>Cepe</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1515/bams-2018-0044</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1515/bams-2018-0044\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Algorithms Med-Syst</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">15</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">1</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2019\">2019. 20180044</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b40\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Classification of patients with breast cancer using neighbourhood component analysis and supervised machine learning techniques</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Laghmati</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">B</forename><surname>Cherradi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1109/CommNet49926.2020.9199633</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1109/CommNet49926.2020.9199633\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Int. Con. Com. Tech. (CommNet)</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"6\" />\n",
      "\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b41\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A machine learning approach based on SVM for classification of liver diseases</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Fathi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Nemati</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.4015/S1016237220500180</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.4015/S1016237220500180\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Biomed. Eng. -Appl</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">32</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">3</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">2050018</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b42\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Classification and prediction of diabetes disease using machine learning paradigm</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Maniruzzaman</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Rahman</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1007/s13755-019-0095-z</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1007/s13755-019-0095-z\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Health Inf. Sci. Syst</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">8</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">1</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"14\" />\n",
      "\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b43\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Machine learning algorithm for stroke disease classification</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">T</forename><surname>Badriyah</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">N</forename><surname>Sakinah</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1109/ICECCE49384.2020.9179307</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1109/ICECCE49384.2020.9179307\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Int. Con. Elec. Comn. Com. Eng. (ICECCE)</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"5\" />\n",
      "\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b44\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Breast cancer type classification using machine learning</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><surname>Wu</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">C</forename><surname>Hicks</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/s22134968</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.3390/s22134968\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">J. Pers. Med</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">11</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">2</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">61</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2021\">2021</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b45\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Predicting patient length of stay in Australian emergency departments using data mining</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">G</forename><surname>Gurazada</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Gao</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Sensors</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">22</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">13</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">4968</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b46\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Machine learning model for predicting the length of stay in the intensive care unit for Covid-19 patients in the eastern province of Saudi Arabia</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">D</forename><forename type=\"middle\">A</forename><surname>Alabbad</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><forename type=\"middle\">M</forename><surname>Almuhaideb</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.imu.2022.100937</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.imu.2022.100937\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Inform. Med. Unlocked</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">30</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">100937</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b47\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">A systematic review on surface electromyography-based classification system for identifying hand and finger movements, Healthcare Anal</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Sultana</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">F</forename><surname>Ahmed</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">S</forename><surname>Alam</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.health.2022.100126</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.health.2022.100126\" />\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t\t<biblScope unit=\"page\">100126</biblScope>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b48\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Prediction of chronic liver disease patients using integrated projection based statistical feature extraction with machine learning algorithms</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Amin</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Yasmin</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.imu.2022.101155</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.imu.2022.101155\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Inform. Med. Unlocked</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">36</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">101155</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2023\">2023</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b49\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Knowing.what.to. expect, Forecasting monthly emergency department visits: A time-series analysis</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><surname>Bergs</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">P</forename><surname>Heerinckx</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Verelst</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.ienj.2013.08.001</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.ienj.2013.08.001\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Int. Emerg. Nurs</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">22</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">2</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"112\" to=\"115\" />\n",
      "\t\t\t<date type=\"published\" when=\"2014\">2014</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b50\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Predicting the number of emergency department presentations in western Australia: A population-based time series analysis</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Q</forename><surname>Mai</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">P</forename><surname>Aboagye-Sarfo</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1111/1742-6723.12344</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1111/1742-6723.12344\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Emerg. Med. Australas</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">27</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">1</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"16\" to=\"21\" />\n",
      "\t\t\t<date type=\"published\" when=\"2015\">2015</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b51\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Forecasting emergency department visits using internet data</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Ekström</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">L</forename><surname>Kurland</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.annemergmed.2014.10.008</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.annemergmed.2014.10.008\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Ann. Emerg. Med</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">65</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">4</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"436\" to=\"442\" />\n",
      "\t\t\t<date type=\"published\" when=\"2015\">2015</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b52\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Hospital daily outpatient visits forecasting using a combinatorial model based on ARIMA and SES models</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">L</forename><surname>Luo</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">L</forename><surname>Luo</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1186/s12913-017-2407-9</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1186/s12913-017-2407-9\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">BMC Health. Serv. Res</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">17</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">1</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"13\" />\n",
      "\t\t\t<date type=\"published\" when=\"2017\">2017</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b53\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Using data mining to predict hospital admissions from the emergency department</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">B</forename><surname>Graham</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Bond</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1109/ACCESS.2018.2808843</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1109/ACCESS.2018.2808843\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">IEEE Access</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">6</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"10458\" to=\"10469\" />\n",
      "\t\t\t<date type=\"published\" when=\"2018\">2018</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b54\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Forecasting of weekly patient visits to emergency department: real case study</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Khaldi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><forename type=\"middle\">El</forename><surname>Afia</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Chiheb</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.procs.2019.01.026</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.procs.2019.01.026\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Proc. comput. sci</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">148</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"532\" to=\"541\" />\n",
      "\t\t\t<date type=\"published\" when=\"2019\">2019</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b55\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">ARIMA modelling and forecasting of COVID-19 in top five affected countries</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><forename type=\"middle\">K</forename><surname>Sahai</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">N</forename><surname>Rath</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.dsx.2020.07.042</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.dsx.2020.07.042\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Diabetes Metab. Syndr</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">14</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">5</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1419\" to=\"1427\" />\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b56\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">COVID-19 future forecasting using supervised machine learning models</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">F</forename><surname>Rustam</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><forename type=\"middle\">A</forename><surname>Reshi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1109/ACCESS.2020.2997311</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1109/ACCESS.2020.2997311\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">IEEE Access</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">8</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"101489\" to=\"101499\" />\n",
      "\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b57\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">FOCOMO: Forecasting and monitoring the worldwide spread of COVID-19 using machine learning methods</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">P</forename><surname>Agrawal</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">V</forename><surname>Madaan</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1080/09720502.2021.1885812</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1080/09720502.2021.1885812\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">J. Interdiscip. Math</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">24</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">2</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"443\" to=\"466\" />\n",
      "\t\t\t<date type=\"published\" when=\"2021\">2021</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b58\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A unified machine learning approach to time series forecasting applied to demand at emergency departments</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">A C</forename><surname>Vollmer</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">B</forename><surname>Glampson</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1186/s12873-020-00395-y</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1186/s12873-020-00395-y\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">BMC Emerg. Med</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">21</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">1</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"14\" />\n",
      "\t\t\t<date type=\"published\" when=\"2021\">2021</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b59\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Performance evaluation of emergency department patient arrivals forecasting models by including meteorological and calendar information: A comparative study</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">V</forename><forename type=\"middle\">K</forename><surname>Sudarshan</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Brabrand</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.compbiomed.2021.104541</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.compbiomed.2021.104541\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Comput. Biol. Med</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">135</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">104541</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2021\">2021</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b60\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A robust and parsimonious machine learning method to predict ICU admission of COVID-19 patients</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">L</forename><surname>Famiglini</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Campagner</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.compbiomed.2021.104541</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1016/j.compbiomed.2021.104541\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Med. Biol. Eng. Comput</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"13\" />\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b61\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Forecasting and explaining emergency department visits in a public hospital</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Petsis</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Karamanou</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1007/s10844-022-00716-6</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1007/s10844-022-00716-6\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">J. Intell. Inf. Syst</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"22\" />\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b62\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Forecasting daily admissions to an emergency department considering single and multiple seasonal patterns</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Vieira</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">I</forename><surname>Sousa</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Dória-Nóbrega</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1007/s10844-022-00716-6</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1007/s10844-022-00716-6\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Healthcare Anal</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">3</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">100146</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2023\">2023</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b63\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Machine learning methods for predicting the admissions and hospitalisations in the emergency department of a civil and military hospital</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><surname>Álvarez-Chaves</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">P</forename><surname>Muñoz</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1007/s10844-023-00790-4</idno>\n",
      "\t\t<ptr target=\"http://dx.doi.org/10.1007/s10844-023-00790-4\" />\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">J. Intell. Inf. Syst</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">1</biblScope>\n",
      "\t\t\t<biblScope unit=\"issue\">20</biblScope>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "\t\t\t\t</listBibl>\n",
      "\t\t\t</div>\n",
      "\t\t</back>\n",
      "\t</text>\n",
      "</TEI>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "pdf_path = \"papers/hospital_bed_capacity_planning.pdf\"\n",
    "url = \"http://localhost:8070/api/processFulltextDocument\"\n",
    "\n",
    "with open(pdf_path, 'rb') as pdf_file:\n",
    "    response = requests.post(url, files={'input': pdf_file})\n",
    "    \n",
    "xml_output = response.text\n",
    "print(xml_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "363ab00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heading: Introduction\n",
      "Heading: Literature review\n",
      "Heading: A hybrid data-driven approach to HBC forecasting\n",
      "Heading: New framework for HBC forecasting\n",
      "Heading: LOS classification algorithms\n",
      "Heading: NHP forecasting algorithms\n",
      "Heading: Case study\n",
      "Heading: Data set\n",
      "Heading: Data analysis\n",
      "Heading: Table 2\n",
      "Heading: Research\n",
      "Heading: NHP descriptive analysis\n",
      "Heading: Age-based NHP descriptive analysis\n",
      "Heading: LOS descriptive analysis\n",
      "Heading: LOS classification\n",
      "Heading: NHP forecasting\n",
      "Heading: Heart ward bed capacity forecasting\n",
      "Heading: Managerial insights\n",
      "Heading: Conclusions, limitations, and recommendations\n",
      "Heading: Ethical statement\n",
      "\n",
      "## Introduction\n",
      "The Hospital Bed Capacity (HBC) forecasting problem has taken significant attention because of its effects on the sustainability of hospitals, particularly in terms of hospital economic efficiency, and patient satisfaction  [1] [2] [3] [4] [5] [6] [7] . The traditional approach to this problem is using simulation or programming models involving several issues, such as the need for some assumptions on attributes of some quantities, for example, the probability distribution of some factors  [8] [9...\n",
      "\n",
      "## Literature review\n",
      "The literature on healthcare centers' bed capacity forecasting is reviewed to clear the paper's contributions and novelty aspects.  Bachouch et al. (2012)  considered some limitations, such as budget, shared resources, and beds needed by acute and emergency patients, in the problem of hospital bed planning. Using constraints such as incompatibility between pathologies and continuity of care, an integer linear programming model was proposed, and the results were compared using several solvers suc...\n",
      "\n",
      "## A hybrid data-driven approach to HBC forecasting\n",
      "In this section, the framework of the proposed hybrid data-driven approach to HBC forecasting is provided, and some classification and forecasting algorithms are opted according to the corresponding literature....\n",
      "\n",
      "## New framework for HBC forecasting\n",
      "As mentioned in the previous sections, factors of LOS and NHP play the most significant role in the bed capacity forecasting problem. Therefore, conducting descriptive analyses on these factors and other affecting features, for example, patient's age and bed occupancy, provides great initial insights into the problem. Consequently, the LOS classification, NHP distribution across LOS classes, and NHP forecasting are the heart of the proposed bed capacity forecasting framework. The results of thes...\n",
      "\n",
      "## LOS classification algorithms\n",
      "The LOS literature review showed that although there is a long list of research on patients' LOS forecasting, no history exists on the LOS classification  [35] [36] [37] [38] . But Patients' classification based on various features using BN, K-Nearest Neighbor (KNN), SVM, DT, ANN, AdaBoost (AB), LR, Random Forest (RF), Recency-Frequency-Monetary analysis (RFM), Gradient Boosting (GB), and Ensembles algorithms has been taken great attention, as illustrated in Table  2 . Mentioning Table  2 , the ...\n",
      "\n",
      "## NHP forecasting algorithms\n",
      "Table  3  shows the conventional ML and DL forecasters used in the number of patients forecasting. Considering Table  3 , Time series methods are the most convenient forecaster on NHP. In addition, LR and Neural networks were the well-accurate forecasters in most literature. Therefore, SARIMA, SLR, and LSTM neural networks have opted for NHP forecasting....\n",
      "\n",
      "## Case study\n",
      "Rouhani Hospital is a public hospital in Babol City of Mazandaran province located in the northern band of Iran. This hospital has 508 beds, nine wards, and 391 specialists. In this hospital, the Heart ward is the busiest ward possessing 30 beds in the main hall of the Heart ward and 15 beds in the Emergency section of Heart diseases....\n",
      "\n",
      "## Data set\n",
      "The collected data set contains 51231 records between 2011 and 2018. Some features, including age and LOS, are considered to be used in the Heart ward's bed capacity forecasting problem. After removing the outliers and noisy data, 47605 records remained which 70% data are categorized as training data and others as test data....\n",
      "\n",
      "## Data analysis\n",
      "The NHP in the Heard ward, patients' age distribution, and their LOS play significant roles in the required beds forecasting. In this section, some Data analysis techniques are applied to the NHP, LOS, and Age to provide initial insights on these significant factors affecting the number of required beds equal to 25. ...\n",
      "\n",
      "## Table 2\n",
      "The popular ML algorithms for patients classification. ...\n",
      "\n",
      "## NHP descriptive analysis\n",
      "Fig.  2  represents the daily NHP in the Heart ward. In this case study, some Heart patients might be hospitalized temporarily in the Emergency section of the Heart ward or other disease wards, waiting for the Heart ward beds evacuation. The reason is that NHP is over the existing bed capacity of the Heart ward on some days. In Fig.  2 , some drastic fallings occur on NHP around the 19 March-4 April each year. Fig.  3  shows these considerable fluctuations in NHP in more detail from 2013 to 2018...\n",
      "\n",
      "## Age-based NHP descriptive analysis\n",
      "Fig.  4  represents that the NHP follows a bimodal pattern according to the patient's age. In addition, the most significant portion of NHP belongs to patients aged between 45 and 85. Using information represented in Fig.  4 , six classes of are considered, including (0,15],  (15, 30] ,  (30, 45] ,  (45, 60] ,  (60, 85] , and (85,99], as depicted in Table  6 . Although Table  6  shows that children's class only involves six percent of total NHP, its share is considerable enough to provide specia...\n",
      "\n",
      "## LOS descriptive analysis\n",
      "Fig.  6  represents the patients' LOS distribution. In Fig.  6 , only a few LOSs are too long, and most seem to be less than ten days. This claim is verified in Figs.  7 and 8 , representing the scatter of NHP in terms of LOS. Table  7  represents the share of the first twenty values of LOS in terms of NHP to investigate the frequency of LOS values in detail. Table  7  shows that LOS=1 makes the role of the first to fourth deciles lonely as the first quartile, LOS=2 is the fifth and sixth decile...\n",
      "\n",
      "## LOS classification\n",
      "Several sets of LOS classes are made, and their accuracy is examined using several classification tools coded using the Sklearn library of Python, as presented in Table  8 . In Table  8 , the classification results show that SVM provides the best accuracy and introduces the case of six classes of LOS as the best alternative. Table  9  depicts the information on NHP and the time interval of LOS classes. Table  9  illustrates only 6% of patients experienced LOS for more than 15 days, and most woul...\n",
      "\n",
      "## NHP forecasting\n",
      "Table  11  summarizes the results of applying three opted forecasters in Section 3.3 using Python libraries. As illustrated in Table  11 , LR opted for forecasting NHP in the future due to providing the least error index. The mentioned hospital was the main center for COVID-19 patients' treatment in Babol City between 2019 and 2021, and hence, the daily NHP is forecasted for the five years from 2022 to 2026....\n",
      "\n",
      "## Heart ward bed capacity forecasting\n",
      "According to Fig.  1 , the forecasted NHP and LOS-based distribution of NHP should be applied to forecast the Heart ward bed capacity in the future. The proportion of NHP in LOS classes, from Table  9 , is applied to forecast the NHP belonging to each LOS class in the future. It is supposed that the expected nights/beds corresponding to LOS classes are equal to 1, 2, 3, 5, 11, and 22, respectively. Eq. (  1 ) uses the forecasted NHP of LOS classes to predict the required daily beds     between 2...\n",
      "\n",
      "## Managerial insights\n",
      "In section 4.3.1, the NHP descriptive analysis showed a type of mismanagement in the use of the existing bed capacity in the Heart ward during about 20 days per year related to the Persian new year holidays. Therefore, some managerial tasks and cultural efforts are needed to provide an equitable shift working for Heart specialists during the new year holidays avoiding empty beds. This could result in sustainable Heart bed capacity in terms of productivity and reliable treatment for high risks He...\n",
      "\n",
      "## Conclusions, limitations, and recommendations\n",
      "This paper considered the hospital bed capacity forecasting problem and proposed a Data-driven methodology to avoid the limits and difficulties of using traditional programming or simulation models. A hybrid approach involving DA, ML, DL, and statistical inference was applied in a Heart ward bed capacity forecasting. Results showed the need for establishing more beds in the Heart ward from 26 to 137 in 2027. In addition, more considerations on the child Heart patients' treatment and the increasi...\n",
      "\n",
      "## Ethical statement\n",
      "The Authors declare that no real clinical data is applied in this paper....\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "root = etree.fromstring(xml_output.encode('utf-8'))\n",
    "sections = []\n",
    "\n",
    "for div in root.findall('.//{*}body/{*}div'):\n",
    "    heading = div.findtext('{*}head')\n",
    "    print(f\"Heading: {heading}\")\n",
    "    text_parts = [t for t in div.itertext() if t.strip() != heading]\n",
    "    text = \" \".join(text_parts)\n",
    "    if heading and text: \n",
    "        sections.append({\n",
    "            \"heading\": heading,\n",
    "            \"content\": text\n",
    "        })\n",
    "\n",
    "for s in sections:\n",
    "    print(f\"\\n## {s['heading']}\\n{s['content'][:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e34c00",
   "metadata": {},
   "source": [
    "# GROBID hierarchical section extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a5c8d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"heading\": \"Introduction\",\n",
      "    \"content\": \"The Hospital Bed Capacity (HBC) forecasting problem has taken significant attention because of its effects on the sustainability of hospitals, particularly in terms of hospital economic efficiency, and patient satisfaction  [1] [2] [3] [4] [5] [6] [7] . The traditional approach to this problem is using simulation or programming models involving several issues, such as the need for some assumptions on attributes of some quantities, for example, the probability distribution of some factors  [8] [9] [10] [11] . In addition, reaching optimum or reasonable solutions is a big challenge of the bed capacity programming models, particularly in the case of large-scale, multi-objective, and integer models. Consequently, using model-free methods for HBC forecasting seems to be a facilitator. Nowadays, business analytics, including Data Analysis (DA), Machine Learning (ML), and Deep Learning (DL) techniques, are widely used as model-free methods in different businesses of services and manufacturing to reach insights on market trends, such as customers' behavior, costs, and technology by no reliance on the simulation or mathematical models  [12] [13] [14] . Also, a reasonable number of their successful applications in the healthcare sector, such as Length of Stay (LOS) forecasting, patient classification, healthcare resources forecasting, and disease diagnosis have been illustrated  [15] [16] [17] [18] . In recent years, a few researchers applied some forecaster tools of ML to predict the required The rest of the paper is as follows. Section 2 reviews the corresponding literature, and Section 3 introduces the proposed data-driven methodology. Section 4 contains the computational results of applying the proposed hybrid data-driven approach in the case study, and finally, Section 5 involves the conclusions, limitations, and recommendations for future works.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"Literature review\",\n",
      "    \"content\": \"The literature on healthcare centers' bed capacity forecasting is reviewed to clear the paper's contributions and novelty aspects.  Bachouch et al. (2012)  considered some limitations, such as budget, shared resources, and beds needed by acute and emergency patients, in the problem of hospital bed planning. Using constraints such as incompatibility between pathologies and continuity of care, an integer linear programming model was proposed, and the results were compared using several solvers such as the CPLEX  [22] . Ben Abdelaziz and Masmoudi (2012) studied the bed capacity of 157 public hospitals in Tunisia when the demand for beds is random using a multi-objective stochastic programming model to allocate the beds to the hospital's departments. In this problem, the three objectives are the total cost of creating new beds, the number of nurses and doctors, and the optimal number of beds  [11] . The healthcare capacities assessment is a matter of great importance in the same vein.  Devapriya et al. (2015)  proposed a discrete-event simulation model to determine the required bed capacity using forecasted patients' volume and LOS  [23] . Also,  Keegan et al. (2018)  used an expanded HIPPOCRATES macrosimulation method to predict the number of beds needed for public and private hospitals in Ireland by 2030. Baseline year and projected demand and capacity profiles in this analysis are generated through the HIPPOCRATES macro-simulation model of demand and cost of health care developed by the ESRI. The emergency department plays a vital role in the hospital because it is the first deal for patients. Therefore, the effective management of the emergency department is significant in improving the quality of service and treatment. Nas and Koyuncu (2019) used ten ML tools to predict the patients' arrival rates. They applied a simulation model to determine the required number of beds in the emergency department by minimizing the LOS in a case study in Turkey  [24] .  Kutafina et al. (2019)  predicted hospital bed occupancy using recurrent neural networks based on 353520-time series records and four features from a hospital in Germany. The results show that the proposed ML model is a powerful tool for automatic planning and decision-making on existing bed capacity planning  [25] .  Zhu et al. (2020)  developed three mathematical models considering the uncertainty of demand for inpatient beds and the number of periods  [26] . They solved and analyzed these models in a public hospital in China. Predicting the required capacity of hospital wards during pandemics, such as Covid-19s, is essential for the hospital.  Deschepper et al. (2021)  used an incremental Poisson model on the previous patients' statistics to establish a Mont-Carlo simulation model for a 10day prediction of needed beds in various wards of A hospital in Ghent.  Haghshenas et al. (2021)  proposed a bi-objective mixed-integer optimization model for Cancer hospitals' location-allocation problem under bed capacity and efficiency considerations  [27] . They forecasted the cancer incidences in the provinces of Iran in 2040 using LR models to provide a plan for cancer hospitals established in each province in some predefined efficient bed capacities. Also, they applied this forecasting method to determine the demand parameter values in a single objective mathematical model for Cancer-curing supply chain planning  [28] . The healthcare system of a country is very complex and vital, that is why  Kabir et al. (2021)  used Recurrent Neural Network (RNN) to predict population growth and applied the Markov decision process to simulate the number of required beds by the next 30 years in a case study of Bangladesh  [29] .  Ordu et al. (2021)  proposed a linear programming model for bed capacity and staff requirement planning in a case study in England. They also forecasted the demand for specialists with ML tools and simulated the patients' treatment pathway using a discrete-event simulation model. It is crucial to determine the operating room bed capacity according to the critical condition of the patients.  Schiele et al. (2021)  predicted the bed occupancy in the Intensive Care Unit (ICU) using an Artificial Neural Network (ANN) algorithm as an ML forecaster and 6000 patients' data from 2010 to 2016 in an ICU scheduling problem in Germany. High traffic of patients in hospitals' wards, in particular the emergency department, affects the capability to provide the optimal level of care.  Tello et al. (2022)  predicted weekly hospital bed capacity using LR as a forecaster per cluster of beds/day. They applied the Kmeans clustering method in SVM as the classifier of beds/day factor in a case study in the USA  [19] .  Latruwe et al. (2023)  proposed a simulation model called the ProMoBed, for inpatient hospitals' bed capacity forecasting. They used LOS, seasonality, and admission data to simulate a stochastic pattern of demand for beds in a case study in Belgium  [8] . Garcia-Vincuna et al. (2023) initially predicted the LOS using linear and non-linear programming and then simulated the bed prediction for the ICU department  [30] . The Covid epidemic sent about 19 million people to hospitals worldwide and showed the importance of forecasting during epidemics.  Redondo et al. (2023)  used a discrete simulation model to predict hospital discharges for Covid patients  [31] .  Bekker et al. (2023)  proposed a linear programming model for predicting hospital beds in the short term. The model predicts admissions and uses a queue-based model to occupy beds, providing accurate results for three days  [32] .  Widyasari et al. (2023)  predicted the bed capacity of Malahayati Hospital in Indonesia using SVM and linear programming  [33] . Covid has put a lot of pressure on healthcare resources worldwide, often challenging hospital capacity and stressing hospital staff,  Johnson et al. (2023)  predicted hospital resources using time series. Results showed that statistical forecasting and ML methods can provide valuable predictions to help make resource planning decisions during epidemics  [34] . The above-reviewed literature, summarized in Table  1 , shows that the commonly used techniques in HBC forecasting have been simulation and programming models. To our best knowledge, only three researchers, including  Kutafina     2022 ), applied ML tools in the healthcare centers' bed capacity planning. These papers used time series data on occupied beds and forecast the required beds in the short-run future, and ignore the direct effects of LOS and NHP. As illustrated in Table  1 , this paper uses a wide variety of techniques from DA, ML, DL, and Statistics to investigate the nature of significant factors, such as patients' LOS, Patients' Age, and NHP, to discover their historical manner and provide valuable information to forecast HBC. In addition, conducting LOS classification to use in HBC forecasting is a unique attribute of this paper.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"A hybrid data-driven approach to HBC forecasting\",\n",
      "    \"content\": \"In this section, the framework of the proposed hybrid data-driven approach to HBC forecasting is provided, and some classification and forecasting algorithms are opted according to the corresponding literature.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"New framework for HBC forecasting\",\n",
      "    \"content\": \"As mentioned in the previous sections, factors of LOS and NHP play the most significant role in the bed capacity forecasting problem. Therefore, conducting descriptive analyses on these factors and other affecting features, for example, patient's age and bed occupancy, provides great initial insights into the problem. Consequently, the LOS classification, NHP distribution across LOS classes, and NHP forecasting are the heart of the proposed bed capacity forecasting framework. The results of these analyses are applied in a simple assumption-free mathematical model to forecast the required beds in the future. In addition, patients' age analysis could provide beneficial insight into the scatter of NHP according to Age, particularly in hospitals without specialized wards for children. Fig.  1  represents the structure and steps of the proposed framework. According to Fig.  1 , like all data-oriented analyses, data collection and pre-processing activities, such as data set cleaning and feature transformations, are the initial conventional steps. The application of DA techniques to the three major features, including patients' Age, NHP, and patients' LOS, can provide massive great information to use in managerial prescriptive notes providing, LOS classification, and NHP forecasting. Through data analysis, some statistical inferences, such as the Hypothesis tests, might be used to verify some descriptive findings. The results of NHP forecasting and LOS-based NHP data analysis are applied in a mathematical model to forecast the hospital bed capacity. There are several algorithms for LOS classification and NHP forecasting. The following sub-sections opt for a set of algorithms that seems much more appropriate according to the literature.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"LOS classification algorithms\",\n",
      "    \"content\": \"The LOS literature review showed that although there is a long list of research on patients' LOS forecasting, no history exists on the LOS classification  [35] [36] [37] [38] . But Patients' classification based on various features using BN, K-Nearest Neighbor (KNN), SVM, DT, ANN, AdaBoost (AB), LR, Random Forest (RF), Recency-Frequency-Monetary analysis (RFM), Gradient Boosting (GB), and Ensembles algorithms has been taken great attention, as illustrated in Table  2 . Mentioning Table  2 , the five most popular ML algorithms, including BN, KNN, SVM, DT, and LR, are considered for LOS classification.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"NHP forecasting algorithms\",\n",
      "    \"content\": \"Table  3  shows the conventional ML and DL forecasters used in the number of patients forecasting. Considering Table  3 , Time series methods are the most convenient forecaster on NHP. In addition, LR and Neural networks were the well-accurate forecasters in most literature. Therefore, SARIMA, SLR, and LSTM neural networks have opted for NHP forecasting.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"Case study\",\n",
      "    \"content\": \"Rouhani Hospital is a public hospital in Babol City of Mazandaran province located in the northern band of Iran. This hospital has 508 beds, nine wards, and 391 specialists. In this hospital, the Heart ward is the busiest ward possessing 30 beds in the main hall of the Heart ward and 15 beds in the Emergency section of Heart diseases.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"Data set\",\n",
      "    \"content\": \"The collected data set contains 51231 records between 2011 and 2018. Some features, including age and LOS, are considered to be used in the Heart ward's bed capacity forecasting problem. After removing the outliers and noisy data, 47605 records remained which 70% data are categorized as training data and others as test data.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"Data analysis\",\n",
      "    \"content\": \"The NHP in the Heard ward, patients' age distribution, and their LOS play significant roles in the required beds forecasting. In this section, some Data analysis techniques are applied to the NHP, LOS, and Age to provide initial insights on these significant factors affecting the number of required beds equal to 25.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"Table 2\",\n",
      "    \"content\": \"The popular ML algorithms for patients classification.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"Research\",\n",
      "    \"content\": \"\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"NHP descriptive analysis\",\n",
      "    \"content\": \"Fig.  2  represents the daily NHP in the Heart ward. In this case study, some Heart patients might be hospitalized temporarily in the Emergency section of the Heart ward or other disease wards, waiting for the Heart ward beds evacuation. The reason is that NHP is over the existing bed capacity of the Heart ward on some days. In Fig.  2 , some drastic fallings occur on NHP around the 19 March-4 April each year. Fig.  3  shows these considerable fluctuations in NHP in more detail from 2013 to 2018. All illustrated fluctuations in Fig.  3  occurred during the annual Nowruz holidays, 19 March-4 April, in Iran as the Persian new year ceremony. In this period, there is no accessibility to Heart specialists because all of them are on their private trips. Therefore, there is no new admittance during this period, and this cause to misuse of some beds and risks for patients. On the other hand, a considerable increase occurs in admittance before and after this holiday, especially from 5 April onwards. Three Hypothesis tests are performed on the mean of hospitalized patients during three 20day periods, as presented in Table  4 , to investigate the significance of falling in admittance during this period. The sample corresponding to each period is formed by pooling the patients' statistics from 2013 to 2018 to carry out the Hypothesis tests. Table  5  depicts the outputs of the conducted test using the MINITAB 21.1.0. The probability values from Table  5  show considerable differences between the mean of patients' admittance during BNH and NH, like      1 𝐻 0 ∶ 𝜇 𝐵𝑁𝐻 = 𝜇 𝑁𝐻 𝐻 1 ∶ 𝜇 𝐵𝑁𝐻 ≠ 𝜇 𝑁𝐻 120 0 2 𝐻 0 ∶ 𝜇 𝑃 𝑁𝐻 = 𝜇 𝑁𝐻 𝐻 1 ∶ 𝜇 𝑃 𝑁𝐻 ≠ 𝜇 𝑁𝐻 120 0 3 𝐻 0 ∶ 𝜇 𝐵𝑁𝐻 = 𝜇 𝑃 𝑁𝐻 𝐻 1 ∶ 𝜇 𝐵𝑁𝐻 ≠ 𝜇 𝑃 𝑁𝐻 120 0.175 PNH and NH. Moreover, the p-value=0.175 shows no significant difference between the mean of patients' admittance along BNH and PNH according to corresponding collected data and conventional significance level 0.05. These results verify the conducted data-driven visual inferences from Fig.  2 .\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"Age-based NHP descriptive analysis\",\n",
      "    \"content\": \"Fig.  4  represents that the NHP follows a bimodal pattern according to the patient's age. In addition, the most significant portion of NHP belongs to patients aged between 45 and 85. Using information represented in Fig.  4 , six classes of are considered, including (0,15],  (15, 30] ,  (30, 45] ,  (45, 60] ,  (60, 85] , and (85,99], as depicted in Table  6 . Although Table  6  shows that children's class only involves six percent of total NHP, its share is considerable enough to provide specialized proper room in the Heart ward or even a particular children's Heart ward regarding their special emotional considerations. Another interesting note in Fig.  4  is that the mean age of children hospitalized with Heart issues is about 7. By conducting some diagnostic analyses on the modal nature of children's NHP, the roots of this manner would be investigated and might be beneficial in children's Heart disease treatment management and even prevention in the future. Fig.  5  illustrates  the fact that the rate of admittance is increasing only among people aged between 30 and 60. Fig.  5  illustrates that the admittance of people of age class  (30, 45 ] has taken more and more acceleration. In other words, Heart diseases are becoming more common over the past between younger individuals. This fact allocates more credit to promoting preventive actions on Heart disease in the public.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"LOS descriptive analysis\",\n",
      "    \"content\": \"Fig.  6  represents the patients' LOS distribution. In Fig.  6 , only a few LOSs are too long, and most seem to be less than ten days. This claim is verified in Figs.  7 and 8 , representing the scatter of NHP in terms of LOS. Table  7  represents the share of the first twenty values of LOS in terms of NHP to investigate the frequency of LOS values in detail. Table  7  shows that LOS=1 makes the role of the first to fourth deciles lonely as the first quartile, LOS=2 is the fifth and sixth deciles as the second quartile, LOS=4 is the third quartile, LOS=3 is the seventh decile, LOS=6 is the eighth decile, and LOS=11 is the ninth decile. Also, more than 95.5 percent of patients stay less than 20 days. This information helps to form appropriate classes of LOS.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"LOS classification\",\n",
      "    \"content\": \"Several sets of LOS classes are made, and their accuracy is examined using several classification tools coded using the Sklearn library of Python, as presented in Table  8 . In Table  8 , the classification results show that SVM provides the best accuracy and introduces the case of six classes of LOS as the best alternative. Table  9  depicts the information on NHP and the time interval of LOS classes. Table  9  illustrates only 6% of patients experienced LOS for more than 15 days, and most would stay in the Heart ward for only one day. In addition, Table  10  presents detailed information on the NHP distribution in each Age class per LOS class. In Table  10 , the lowest proportion of NHP from the first class of LOS, LOS=1, comes from the eldest people's class which seems reasonable because of the more Heart risk and need for continual health monitoring in this class. But the following place is allocated to children means the admittance of this type of Heart patient tends to be longer over other Age classes. A more diagnostic analysis could provide helpful information to make better decisions on the specialized Heart beds for children because the children's class possesses the first rank in the proportion of NHP allocated to the long LOS class. This situation assigns crucial importance to establishing specialized children's Heart wards in the future.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"NHP forecasting\",\n",
      "    \"content\": \"Table  11  summarizes the results of applying three opted forecasters in Section 3.3 using Python libraries. As illustrated in Table  11 , LR opted for forecasting NHP in the future due to providing the least error index. The mentioned hospital was the main center for COVID-19 patients' treatment in Babol City between 2019 and 2021, and hence, the daily NHP is forecasted for the five years from 2022 to 2026.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"Heart ward bed capacity forecasting\",\n",
      "    \"content\": \"According to Fig.  1 , the forecasted NHP and LOS-based distribution of NHP should be applied to forecast the Heart ward bed capacity in the future. The proportion of NHP in LOS classes, from Table  9 , is applied to forecast the NHP belonging to each LOS class in the future. It is supposed that the expected nights/beds corresponding to LOS classes are equal to 1, 2, 3, 5, 11, and 22, respectively. Eq. (  1 ) uses the forecasted NHP of LOS classes to predict the required daily beds     between 2022 and 2026 (see Fig.  9 ). 𝐻𝐵𝐶 𝑗 = ∑ 𝑖 𝑁𝐻𝑃 𝑖𝑗 + ∑ 𝑖≥2 𝑁𝐻𝑃 𝑖,𝑗−1 + ∑ 𝑖≥3 𝑁𝐻𝑃 𝑖,𝑗−2 + ∑ 𝑖≥4 𝑗−3 ∑ 𝑘=𝑗−4 𝑁𝐻𝑃 𝑖𝑘 + ∑ 𝑖≥5 𝑗−5 ∑ 𝑘=𝑗−10 𝑁𝐻𝑃 𝑖𝑘 + 𝑗−11 ∑ 𝑘=𝑗−20 𝑁𝐻𝑃 6,𝑘 𝑖 = 1, 2, … , 6; 𝑗 = 1, 2, … , 1825 (1) In Eq. (  1 ), i is the index of LOS classes, and j denotes the order of days between 2022 and 2027. Also, 𝑁𝐻𝑃 𝑖𝑗 represents the NHP belonging to the 𝑖th class of LOS that will be admitted in the Heart during day j, and 𝐻𝐵𝐶 𝑗 denotes the needed beds in day j. Fig.  10  illustrates the forecasted HBC in Heart ward from 1 January 2022 to 31 December 2026. Fig.  10  represents drastic increase in the number of required beds because the older hospitalized patients not considered and the calculation only is dependent on the forthcoming NHPs. In this Figure, the average needed bed capacity in the future is forecasted at 120 beds which is much more than the existing 45 beds. Therefore, this hospital's administration should make strategic decisions to increase the bed capacity of the Heart ward from 45 beds to 137 beds by 2026.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"Managerial insights\",\n",
      "    \"content\": \"In section 4.3.1, the NHP descriptive analysis showed a type of mismanagement in the use of the existing bed capacity in the Heart ward during about 20 days per year related to the Persian new year holidays. Therefore, some managerial tasks and cultural efforts are needed to provide an equitable shift working for Heart specialists during the new year holidays avoiding empty beds. This could result in sustainable Heart bed capacity in terms of productivity and reliable treatment for high risks Heart patients. In addition, Tables  6 and  10  showed that children are a considerable ratio of Heart patients, and a noticeable proportion of them require too long LOS. Therefore, establishing an appropriate specialized Heart room or Heart ward for children must be a significant goal of the hospital's authorities. Also, Fig.  10  represented the need for 117 beds in the Heart ward from 2022 upward. Providing proper facilities to establish per specialized Heart bed requires a considerable budget. Hence, conducting financial analysis to estimate the needed resources such as money is inevitable, particularly in a developing country such as Iran with tremendous limits on monitorial resources.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"Conclusions, limitations, and recommendations\",\n",
      "    \"content\": \"This paper considered the hospital bed capacity forecasting problem and proposed a Data-driven methodology to avoid the limits and difficulties of using traditional programming or simulation models. A hybrid approach involving DA, ML, DL, and statistical inference was applied in a Heart ward bed capacity forecasting. Results showed the need for establishing more beds in the Heart ward from 26 to 137 in 2027. In addition, more considerations on the child Heart patients' treatment and the increasing trend of the occurring Heart diseases among younger people are recommended by results. This paper only focused on HBC forecasting and paid no attention to other required resources such as Specialists, Nurses, Equipment, and Budget. Forecasting these significant factors could provide beneficial information for decision-makers. In addition, some other factors can affect the NHP of a hospital in the future, such as insurance service level, the accessibility to other hospitals, the service quality level, limits on the number of available corresponding specialists, the number of specialized equipment, the economic conditions, and the people's accessibility to periodic checkup. This needs to use multivariate time series data sets and multivariate ML tools in future works. Also, uncertainty is an inevitable fact in decision-making that could be mentioned in the future use of DA, ML, and DL for HBC forecasting.\",\n",
      "    \"subsections\": []\n",
      "  },\n",
      "  {\n",
      "    \"heading\": \"Ethical statement\",\n",
      "    \"content\": \"The Authors declare that no real clinical data is applied in this paper.\",\n",
      "    \"subsections\": []\n",
      "  }\n",
      "]\n",
      "\n",
      "# Introduction\n",
      "The Hospital Bed Capacity (HBC) forecasting problem has taken significant attention because of its effects on the sustainability of hospitals, particularly in terms of hospital economic efficiency, and patient satisfaction  [1] [2] [3] [4] [5] [6] [7] . The traditional approach to this problem is us ...\n",
      "\n",
      "# Literature review\n",
      "The literature on healthcare centers' bed capacity forecasting is reviewed to clear the paper's contributions and novelty aspects.  Bachouch et al. (2012)  considered some limitations, such as budget, shared resources, and beds needed by acute and emergency patients, in the problem of hospital bed p ...\n",
      "\n",
      "# A hybrid data-driven approach to HBC forecasting\n",
      "In this section, the framework of the proposed hybrid data-driven approach to HBC forecasting is provided, and some classification and forecasting algorithms are opted according to the corresponding literature. ...\n",
      "\n",
      "# New framework for HBC forecasting\n",
      "As mentioned in the previous sections, factors of LOS and NHP play the most significant role in the bed capacity forecasting problem. Therefore, conducting descriptive analyses on these factors and other affecting features, for example, patient's age and bed occupancy, provides great initial insight ...\n",
      "\n",
      "# LOS classification algorithms\n",
      "The LOS literature review showed that although there is a long list of research on patients' LOS forecasting, no history exists on the LOS classification  [35] [36] [37] [38] . But Patients' classification based on various features using BN, K-Nearest Neighbor (KNN), SVM, DT, ANN, AdaBoost (AB), LR, ...\n",
      "\n",
      "# NHP forecasting algorithms\n",
      "Table  3  shows the conventional ML and DL forecasters used in the number of patients forecasting. Considering Table  3 , Time series methods are the most convenient forecaster on NHP. In addition, LR and Neural networks were the well-accurate forecasters in most literature. Therefore, SARIMA, SLR,  ...\n",
      "\n",
      "# Case study\n",
      "Rouhani Hospital is a public hospital in Babol City of Mazandaran province located in the northern band of Iran. This hospital has 508 beds, nine wards, and 391 specialists. In this hospital, the Heart ward is the busiest ward possessing 30 beds in the main hall of the Heart ward and 15 beds in the  ...\n",
      "\n",
      "# Data set\n",
      "The collected data set contains 51231 records between 2011 and 2018. Some features, including age and LOS, are considered to be used in the Heart ward's bed capacity forecasting problem. After removing the outliers and noisy data, 47605 records remained which 70% data are categorized as training dat ...\n",
      "\n",
      "# Data analysis\n",
      "The NHP in the Heard ward, patients' age distribution, and their LOS play significant roles in the required beds forecasting. In this section, some Data analysis techniques are applied to the NHP, LOS, and Age to provide initial insights on these significant factors affecting the number of required  ...\n",
      "\n",
      "# Table 2\n",
      "The popular ML algorithms for patients classification. ...\n",
      "\n",
      "# Research\n",
      " ...\n",
      "\n",
      "# NHP descriptive analysis\n",
      "Fig.  2  represents the daily NHP in the Heart ward. In this case study, some Heart patients might be hospitalized temporarily in the Emergency section of the Heart ward or other disease wards, waiting for the Heart ward beds evacuation. The reason is that NHP is over the existing bed capacity of th ...\n",
      "\n",
      "# Age-based NHP descriptive analysis\n",
      "Fig.  4  represents that the NHP follows a bimodal pattern according to the patient's age. In addition, the most significant portion of NHP belongs to patients aged between 45 and 85. Using information represented in Fig.  4 , six classes of are considered, including (0,15],  (15, 30] ,  (30, 45] ,  ...\n",
      "\n",
      "# LOS descriptive analysis\n",
      "Fig.  6  represents the patients' LOS distribution. In Fig.  6 , only a few LOSs are too long, and most seem to be less than ten days. This claim is verified in Figs.  7 and 8 , representing the scatter of NHP in terms of LOS. Table  7  represents the share of the first twenty values of LOS in terms ...\n",
      "\n",
      "# LOS classification\n",
      "Several sets of LOS classes are made, and their accuracy is examined using several classification tools coded using the Sklearn library of Python, as presented in Table  8 . In Table  8 , the classification results show that SVM provides the best accuracy and introduces the case of six classes of LO ...\n",
      "\n",
      "# NHP forecasting\n",
      "Table  11  summarizes the results of applying three opted forecasters in Section 3.3 using Python libraries. As illustrated in Table  11 , LR opted for forecasting NHP in the future due to providing the least error index. The mentioned hospital was the main center for COVID-19 patients' treatment in ...\n",
      "\n",
      "# Heart ward bed capacity forecasting\n",
      "According to Fig.  1 , the forecasted NHP and LOS-based distribution of NHP should be applied to forecast the Heart ward bed capacity in the future. The proportion of NHP in LOS classes, from Table  9 , is applied to forecast the NHP belonging to each LOS class in the future. It is supposed that the ...\n",
      "\n",
      "# Managerial insights\n",
      "In section 4.3.1, the NHP descriptive analysis showed a type of mismanagement in the use of the existing bed capacity in the Heart ward during about 20 days per year related to the Persian new year holidays. Therefore, some managerial tasks and cultural efforts are needed to provide an equitable shi ...\n",
      "\n",
      "# Conclusions, limitations, and recommendations\n",
      "This paper considered the hospital bed capacity forecasting problem and proposed a Data-driven methodology to avoid the limits and difficulties of using traditional programming or simulation models. A hybrid approach involving DA, ML, DL, and statistical inference was applied in a Heart ward bed cap ...\n",
      "\n",
      "# Ethical statement\n",
      "The Authors declare that no real clinical data is applied in this paper. ...\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import json\n",
    "\n",
    "def parse_div(div):\n",
    "    \"\"\"\n",
    "    Recursively parse a <div> element and extract:\n",
    "    - heading text\n",
    "    - content text\n",
    "    - subsections\n",
    "    \"\"\"\n",
    "    heading = div.findtext('{*}head')\n",
    "    \n",
    "    # Remove heading text from main content\n",
    "    all_text_parts = list(div.itertext())\n",
    "    if heading:\n",
    "        all_text_parts = [t for t in all_text_parts if t.strip() != heading.strip()]\n",
    "    content = \" \".join(all_text_parts).strip()\n",
    "\n",
    "    # Parse subsections (nested divs)\n",
    "    subsections = []\n",
    "    for sub_div in div.findall('{*}div'):\n",
    "        subsections.append(parse_div(sub_div))\n",
    "\n",
    "    return {\n",
    "        \"heading\": heading.strip() if heading else None,\n",
    "        \"content\": content,\n",
    "        \"subsections\": subsections\n",
    "    }\n",
    "\n",
    "def extract_sections_from_grobid(xml_text):\n",
    "    \"\"\"\n",
    "    Parse GROBID TEI XML and extract hierarchical sections.\n",
    "    \"\"\"\n",
    "    root = etree.fromstring(xml_text.encode('utf-8'))\n",
    "\n",
    "    # Find the <body> element\n",
    "    body = root.find('.//{*}body')\n",
    "    if body is None:\n",
    "        raise ValueError(\"No <body> element found in TEI XML\")\n",
    "\n",
    "    sections = []\n",
    "    for div in body.findall('{*}div'):\n",
    "        sections.append(parse_div(div))\n",
    "\n",
    "    return sections\n",
    "\n",
    "\n",
    "\n",
    "sections = extract_sections_from_grobid(xml_output)\n",
    "\n",
    "# Pretty print JSON\n",
    "print(json.dumps(sections, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Optional: print readable summary\n",
    "def print_sections(sections, level=1):\n",
    "    for s in sections:\n",
    "        indent = \"#\" * level\n",
    "        print(f\"\\n{indent} {s['heading']}\")\n",
    "        print(s['content'][:300], \"...\")\n",
    "        if s[\"subsections\"]:\n",
    "            print_sections(s[\"subsections\"], level + 1)\n",
    "\n",
    "print_sections(sections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "107fa4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\Yue Ning\\AppData\\Local\\Temp\\ipykernel_44216\\386252838.py:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  pdf_path = \"papers\\ml_model_cardio_disease_detection.pdf\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<TEI xml:space=\"preserve\" xmlns=\"http://www.tei-c.org/ns/1.0\" \n",
      "xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n",
      "xsi:schemaLocation=\"http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd\"\n",
      " xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
      "\t<teiHeader xml:lang=\"en\">\n",
      "\t\t<fileDesc>\n",
      "\t\t\t<titleStmt>\n",
      "\t\t\t\t<title level=\"a\" type=\"main\">Machine Learning-Based Predictive Models for Detection of Cardiovascular Diseases</title>\n",
      "\t\t\t</titleStmt>\n",
      "\t\t\t<publicationStmt>\n",
      "\t\t\t\t<publisher/>\n",
      "\t\t\t\t<availability status=\"unknown\"><licence/></availability>\n",
      "\t\t\t\t<date type=\"published\" when=\"2024-01-08\">8 January 2024</date>\n",
      "\t\t\t</publicationStmt>\n",
      "\t\t\t<sourceDesc>\n",
      "\t\t\t\t<biblStruct>\n",
      "\t\t\t\t\t<analytic>\n",
      "\t\t\t\t\t\t<author>\n",
      "\t\t\t\t\t\t\t<persName><forename type=\"first\">Adedayo</forename><surname>Ogunpola</surname></persName>\n",
      "\t\t\t\t\t\t\t<email>adedayo.ogunpola@mail.bcu.ac.uk</email>\n",
      "\t\t\t\t\t\t\t<affiliation key=\"aff0\">\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"department\">College of Computing and Digital Technology</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"laboratory\">DAAI Research Group</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"institution\">Birmingham City University</orgName>\n",
      "\t\t\t\t\t\t\t\t<address>\n",
      "\t\t\t\t\t\t\t\t\t<postCode>B4 7XG</postCode>\n",
      "\t\t\t\t\t\t\t\t\t<settlement>Birmingham</settlement>\n",
      "\t\t\t\t\t\t\t\t\t<country key=\"GB\">UK</country>\n",
      "\t\t\t\t\t\t\t\t</address>\n",
      "\t\t\t\t\t\t\t</affiliation>\n",
      "\t\t\t\t\t\t</author>\n",
      "\t\t\t\t\t\t<author>\n",
      "\t\t\t\t\t\t\t<persName><forename type=\"first\">Faisal</forename><surname>Saeed</surname></persName>\n",
      "\t\t\t\t\t\t\t<email>faisal.saeed@bcu.ac.uk</email>\n",
      "\t\t\t\t\t\t\t<idno type=\"ORCID\">0000-0002-2822-1708</idno>\n",
      "\t\t\t\t\t\t\t<affiliation key=\"aff0\">\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"department\">College of Computing and Digital Technology</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"laboratory\">DAAI Research Group</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"institution\">Birmingham City University</orgName>\n",
      "\t\t\t\t\t\t\t\t<address>\n",
      "\t\t\t\t\t\t\t\t\t<postCode>B4 7XG</postCode>\n",
      "\t\t\t\t\t\t\t\t\t<settlement>Birmingham</settlement>\n",
      "\t\t\t\t\t\t\t\t\t<country key=\"GB\">UK</country>\n",
      "\t\t\t\t\t\t\t\t</address>\n",
      "\t\t\t\t\t\t\t</affiliation>\n",
      "\t\t\t\t\t\t</author>\n",
      "\t\t\t\t\t\t<author>\n",
      "\t\t\t\t\t\t\t<persName><forename type=\"first\">Shadi</forename><surname>Basurra</surname></persName>\n",
      "\t\t\t\t\t\t\t<email>shadi.basurra@bcu.ac.uk</email>\n",
      "\t\t\t\t\t\t\t<idno type=\"ORCID\">0000-0002-2822-1708</idno>\n",
      "\t\t\t\t\t\t\t<affiliation key=\"aff0\">\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"department\">College of Computing and Digital Technology</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"laboratory\">DAAI Research Group</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"institution\">Birmingham City University</orgName>\n",
      "\t\t\t\t\t\t\t\t<address>\n",
      "\t\t\t\t\t\t\t\t\t<postCode>B4 7XG</postCode>\n",
      "\t\t\t\t\t\t\t\t\t<settlement>Birmingham</settlement>\n",
      "\t\t\t\t\t\t\t\t\t<country key=\"GB\">UK</country>\n",
      "\t\t\t\t\t\t\t\t</address>\n",
      "\t\t\t\t\t\t\t</affiliation>\n",
      "\t\t\t\t\t\t</author>\n",
      "\t\t\t\t\t\t<author>\n",
      "\t\t\t\t\t\t\t<persName><forename type=\"first\">Abdullah</forename><forename type=\"middle\">M</forename><surname>Albarrak</surname></persName>\n",
      "\t\t\t\t\t\t\t<email>amsbarrak@imamu.edu.sa</email>\n",
      "\t\t\t\t\t\t\t<idno type=\"ORCID\">0000-0002-9140-4339</idno>\n",
      "\t\t\t\t\t\t\t<affiliation key=\"aff1\">\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"department\" key=\"dep1\">Computer Science Department</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"department\" key=\"dep2\">College of Computer and Information Sciences</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"institution\">Imam Mohammad Ibn Saud Islamic University (IMSIU)</orgName>\n",
      "\t\t\t\t\t\t\t\t<address>\n",
      "\t\t\t\t\t\t\t\t\t<postCode>11432</postCode>\n",
      "\t\t\t\t\t\t\t\t\t<settlement>Riyadh</settlement>\n",
      "\t\t\t\t\t\t\t\t\t<country key=\"SA\">Saudi Arabia</country>\n",
      "\t\t\t\t\t\t\t\t</address>\n",
      "\t\t\t\t\t\t\t</affiliation>\n",
      "\t\t\t\t\t\t</author>\n",
      "\t\t\t\t\t\t<author>\n",
      "\t\t\t\t\t\t\t<persName><forename type=\"first\">Sultan</forename><forename type=\"middle\">Noman</forename><surname>Qasem</surname></persName>\n",
      "\t\t\t\t\t\t\t<idno type=\"ORCID\">0000-0002-6575-161X</idno>\n",
      "\t\t\t\t\t\t\t<affiliation key=\"aff1\">\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"department\" key=\"dep1\">Computer Science Department</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"department\" key=\"dep2\">College of Computer and Information Sciences</orgName>\n",
      "\t\t\t\t\t\t\t\t<orgName type=\"institution\">Imam Mohammad Ibn Saud Islamic University (IMSIU)</orgName>\n",
      "\t\t\t\t\t\t\t\t<address>\n",
      "\t\t\t\t\t\t\t\t\t<postCode>11432</postCode>\n",
      "\t\t\t\t\t\t\t\t\t<settlement>Riyadh</settlement>\n",
      "\t\t\t\t\t\t\t\t\t<country key=\"SA\">Saudi Arabia</country>\n",
      "\t\t\t\t\t\t\t\t</address>\n",
      "\t\t\t\t\t\t\t</affiliation>\n",
      "\t\t\t\t\t\t</author>\n",
      "\t\t\t\t\t\t<title level=\"a\" type=\"main\">Machine Learning-Based Predictive Models for Detection of Cardiovascular Diseases</title>\n",
      "\t\t\t\t\t</analytic>\n",
      "\t\t\t\t\t<monogr>\n",
      "\t\t\t\t\t\t<imprint>\n",
      "\t\t\t\t\t\t\t<date type=\"published\" when=\"2024-01-08\">8 January 2024</date>\n",
      "\t\t\t\t\t\t</imprint>\n",
      "\t\t\t\t\t</monogr>\n",
      "\t\t\t\t\t<idno type=\"MD5\">AC89AAD4D2FEEDF4DFCB0B1EC73D2950</idno>\n",
      "\t\t\t\t\t<idno type=\"DOI\">10.3390/diagnostics14020144</idno>\n",
      "\t\t\t\t\t<note type=\"submission\">Received: 27 November 2023 Revised: 21 December 2023 Accepted: 25 December 2023</note>\n",
      "\t\t\t\t</biblStruct>\n",
      "\t\t\t</sourceDesc>\n",
      "\t\t</fileDesc>\n",
      "\t\t<encodingDesc>\n",
      "\t\t\t<appInfo>\n",
      "\t\t\t\t<application version=\"0.7.2\" ident=\"GROBID\" when=\"2025-10-29T08:07+0000\">\n",
      "\t\t\t\t\t<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>\n",
      "\t\t\t\t\t<ref target=\"https://github.com/kermitt2/grobid\"/>\n",
      "\t\t\t\t</application>\n",
      "\t\t\t</appInfo>\n",
      "\t\t</encodingDesc>\n",
      "\t\t<profileDesc>\n",
      "\t\t\t<textClass>\n",
      "\t\t\t\t<keywords>\n",
      "\t\t\t\t\t<term>Ogunpola, A.</term>\n",
      "\t\t\t\t\t<term>Saeed, F.</term>\n",
      "\t\t\t\t\t<term>Basurra, S.</term>\n",
      "\t\t\t\t\t<term>Albarrak, A.M.</term>\n",
      "\t\t\t\t\t<term>Qasem, S.N. Machine Learning-Based Predictive Models for Detection of cardiovascular diseases</term>\n",
      "\t\t\t\t\t<term>deep learning</term>\n",
      "\t\t\t\t\t<term>disease detection</term>\n",
      "\t\t\t\t\t<term>heart diseases</term>\n",
      "\t\t\t\t\t<term>machine learning</term>\n",
      "\t\t\t\t\t<term>ensemble learning</term>\n",
      "\t\t\t\t\t<term>XGBoost Neural Network Precision rate: 91% Recall rate: 89% Kavitha et al. [24] Hybrid Model (Random Forest (RF) and Decision Tree (DT)) Accuracy: 88% Amiri and Armano [25] Classification-CART Accuracy: 99.14% Sensitivity: 100% Specificity: 98.28% Liu and Kim [26] Classifier-Long Short Term Memory (LSTM) Accuracy: 98.4% 2.3. Datasets Collection and Preprocessing</term>\n",
      "\t\t\t\t</keywords>\n",
      "\t\t\t</textClass>\n",
      "\t\t\t<abstract>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><p>Cardiovascular diseases present a significant global health challenge that emphasizes the critical need for developing accurate and more effective detection methods. Several studies have contributed valuable insights in this field, but it is still necessary to advance the predictive models and address the gaps in the existing detection approaches. For instance, some of the previous studies have not considered the challenge of imbalanced datasets, which can lead to biased predictions, especially when the datasets include minority classes. This study's primary focus is the early detection of heart diseases, particularly myocardial infarction, using machine learning techniques. It tackles the challenge of imbalanced datasets by conducting a comprehensive literature review to identify effective strategies. Seven machine learning and deep learning classifiers, including K-Nearest Neighbors, Support Vector Machine, Logistic Regression, Convolutional Neural Network, Gradient Boost, XGBoost, and Random Forest, were deployed to enhance the accuracy of heart disease predictions. The research explores different classifiers and their performance, providing valuable insights for developing robust prediction models for myocardial infarction. The study's outcomes emphasize the effectiveness of meticulously fine-tuning an XGBoost model for cardiovascular diseases. This optimization yields remarkable results: 98.50% accuracy, 99.14% precision, 98.29% recall, and a 98.71% F1 score. Such optimization significantly enhances the model's diagnostic accuracy for heart disease.</p></div>\n",
      "\t\t\t</abstract>\n",
      "\t\t</profileDesc>\n",
      "\t</teiHeader>\n",
      "\t<text xml:lang=\"en\">\n",
      "\t\t<body>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1.\">Introduction</head><p>The heart plays a crucial role in sustaining life by effectively pumping oxygenated blood and regulating important hormones to maintain optimal blood pressure levels. Any deviation from its functioning can lead to the development of heart conditions, collectively known as cardiovascular diseases (CVD). CVD includes a range of disorders that affect both the heart and blood vessels, such as cerebrovascular problems, congenital anomalies, pulmonary embolisms, irregular heart rhythms (arrhythmias), peripheral arterial issues, coronary artery disease (CAD), rheumatic heart ailments, coronary heart disease (CHD), and cardiomyopathies that affect the heart muscle.</p><p>Notably, CHD is the subtype among cardiovascular diseases, accounting for a significant 64% of all cases. While it primarily affects men, women are also susceptible to its impact. Within the realm of CVDs, CAD is particularly concerning due to its association with global mortality rates. According to the World Health Organization (WHO) <ref type=\"bibr\" target=\"#b0\">[1]</ref>, the consequences of CVDs are profound, with staggering statistics indicating an estimated 17.9 million deaths annually are attributed to these diseases worldwide. These alarming numbers highlight the significance of research efforts and medical advancements dedicated to combatting and lessening the impact of cardiovascular diseases worldwide. There are risk factors that contribute to the development of CVDs, including blood pressure, excess body weight and obesity, abnormal lipid profiles, glucose irregularities or diabetes conditions, tobacco usage or smoking habits, physical inactivity or sedentary lifestyle, alcohol consumption, and cholesterol levels. The WHO predicts that CVD will remain a cause of mortality, silently posing a substantial threat to human life for the foreseeable future, possibly even beyond 2030.</p><p>Machine learning, as highlighted by Ramesh et al. <ref type=\"bibr\" target=\"#b1\">[2]</ref>, enjoys major transformative capability within the healthcare industry. Its outstanding advancements can be ascribed to its exceptional data processing abilities, which are far superior to those of humans. Consequently, the field of healthcare has observed the development of several AI applications that leverage machine learning's speed and accuracy, paving the way for revolutionary solutions to diverse healthcare challenges. Several machine learning methods have been applied for the purpose of detecting cardiovascular diseases. However, there is still a need to enhance the predictive models and address the research gaps in the existing detection approaches, such as the challenge of imbalanced datasets, which can lead to biased predictions.</p><p>By investigating the effectiveness of hybrid models combining different techniques, various researchers have explored diverse methodologies, including neural networks and various machine learning methods, to enhance prediction accuracy <ref type=\"bibr\" target=\"#b2\">[3]</ref><ref type=\"bibr\" target=\"#b3\">[4]</ref><ref type=\"bibr\" target=\"#b4\">[5]</ref><ref type=\"bibr\" target=\"#b5\">[6]</ref><ref type=\"bibr\" target=\"#b6\">[7]</ref><ref type=\"bibr\">[8]</ref><ref type=\"bibr\" target=\"#b8\">[9]</ref><ref type=\"bibr\" target=\"#b9\">[10]</ref><ref type=\"bibr\" target=\"#b10\">[11]</ref><ref type=\"bibr\" target=\"#b11\">[12]</ref>. While these studies provide valuable insights, the variability in datasets, models, and outcomes underscores the complexity of the predictive task. Despite the advancements, there remains a pressing need for further investigations to refine existing models and improve the overall performance of cardiovascular disease prediction. The diverse landscape of machine learning applications in this domain emphasizes the importance of continued research to enhance the accuracy, reliability, and generalizability of predictive models, ultimately contributing to more effective clinical interventions and patient care.</p><p>In this paper, we have explored the strengths and limitations of the existing machine learning (ML) techniques in the context of heart disease analysis. Then, we investigated and applied seven machine learning-driven predictive models that can enhance the detection of cardiovascular and cerebrovascular diseases; these models include K-Nearest Neighbors, Support Vector Machine, Logistic Regression, Convolutional Neural Network, Gradient Boost, XGBoost, and Random Forest. Two datasets were used in this study, which were pre-processed using different techniques such as oversampling, feature scaling, normalization, and dimensionality reduction to optimize data for effective machine learning analysis. Finally, we evaluated and compared the efficacy of different machine learning (ML) techniques for analyzing heart diseases within the healthcare sector.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"2.\">Related Works</head><p>In this paper, we present a concise technical background and review pertinent literature related to research studies conducted on the early forecast of heart disease utilizing machine learning and deep learning techniques. We highlight the different methods that have been employed in these studies to foretell heart disease at an initial stage.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"2.1.\">Machine Learning Approach</head><p>Machine learning remains a rapidly advancing discipline of computational algorithms that try to imitate human intelligence by learning through data and the surrounding environment. These algorithms play a crucial role in processing and analyzing large-scale data, often referred to as \"big data\". Machine learning techniques have demonstrated their effectiveness in various domains, including pattern recognition, computer vision, spacecraft engineering, as well as biomedical and medical applications. Their versatility and success have made them indispensable tools in addressing complex challenges and extracting valuable insights from diverse datasets <ref type=\"bibr\" target=\"#b12\">[13]</ref>.</p><p>Machine learning is a specialized approach that automates the process of model building. Using algorithms, machines can discover hidden patterns and insights within datasets. Importantly, in machine learning, we do not particularly instruct machines on where to explore for insights; instead, the algorithms enable the machines to learn and adapt their techniques and outputs as they uncover new-found data and scenarios. This iterative nature of machine learning allows for continuous improvement and adaptation, making it a powerful tool for processing and analyzing complex datasets <ref type=\"bibr\" target=\"#b13\">[14]</ref>.</p><p>There exist two main approaches in machine learning: supervised learning and unsupervised learning. In one approach, supervised learning, algorithms are trained using specific examples. The machine is provided with input data along with their corresponding correct outputs. Learning takes place by comparing the machine's experimental outcomes with the accurate outputs to discover blunders. This sort of learning is suitable after previous data has been utilized to foretell future occurrences <ref type=\"bibr\" target=\"#b14\">[15]</ref>.</p><p>The other approach, unsupervised learning, involves the machine exploring the records and attempting to discover patterns or structures on its own. It needs to create models commencing from scratch and is not provided with any precise outputs to guide its learning process. Unsupervised learning is commonly employed to detect and distinguish outliers in the data. This approach is particularly useful when there is limited or no labeled data available for training <ref type=\"bibr\" target=\"#b13\">[14]</ref>. Researchers worldwide have made significant efforts to combat cardiovascular disease (CVD) and improve patient outcomes <ref type=\"bibr\" target=\"#b15\">[16]</ref>. These efforts include enhancing clinical decision support systems to achieve precise early detection and enable effective treatment. Machine learning (ML) and artificial intelligence (AI) techniques have played a pivotal role in the early detection and diagnosis of CVD.</p><p>CVD detection encompasses different distinct approaches. The first approach involves utilizing AI models that analyze various test reports to distinguish between CVD patients and healthy citizens. The second approach utilizes signals such as electrocardiogram (ECG) and heart sound signals as vital information for ML models to classify individuals as either healthy or having CVD <ref type=\"bibr\" target=\"#b15\">[16]</ref>.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"2.2.\">Deep Learning Approach</head><p>In recent years, there has been remarkable progress in the field of deep learning, with a primary focus on developing intelligent automated systems that aid doctors in predicting and diagnosing diseases through the utilization of the Internet of Things (IoT). While conventional machine learning techniques were often restricted by their dependency on single datasets, the advent of deep learning has brought significant enhancements to the accuracy of existing algorithms. Deep learning leverages artificial neural networks, which consist of multiple hidden layers organized in a cascading pattern. This architecture enables the processing of non-linear datasets, allowing for more complex patterns and relationships to be captured and learned by the model. As a result, deep learning has emerged as a powerful tool in medical applications, providing improved predictive capabilities and enhancing disease diagnosis through the integration of IoT devices and data sources. This approach has shown promising results, outperforming older machine learning algorithms in terms of accuracy. As accurate medical support systems for detecting hidden patterns and predicting diseases are still lacking, deep learning offers the potential to accurately predict heart diseases at an early stage, allowing for timely intervention and treatment <ref type=\"bibr\" target=\"#b16\">[17]</ref>. <ref type=\"bibr\">Sudha and Kumar [18]</ref> observed that the Convolutional Neural Network (CNN) is a suitable method for diagnosing heart disease. CNN's ability to learn and represent features in a concise and conceptual manner is advantageous, especially as the network's depth increases. Additionally, they proposed a hybrid model that combines Convolutional Neural Networks (CNN) with Long Short-Term Memory (LSTM) units, which are a type of recurrent neural network (RNN). LSTM units are known for their ability to store and transmit relevant information over long sequences, making them particularly useful for time-series data such as heart disease data. By integrating CNN and LSTM, the hybrid model aimed to enhance the accuracy of heart disease classification. The CNN component is adept at capturing spatial patterns in the data, while the LSTM component excels at recognizing temporal dependencies and patterns. This combination allows the model to effectively learn complex features from the data, leading to improved classification accuracy. Experimental results from the study revealed promising outcomes, with the hybrid model achieving an accuracy of 89%, sensitivity of 81%, and specificity of 93%. These results outperformed conventional machine learning classifiers, indicating the potential of the proposed hybrid approach in advancing the accuracy of heart disease classification <ref type=\"bibr\">[18]</ref>.</p><p>The healthcare sector has emerged as a prime beneficiary of the growing volume and accessibility of data <ref type=\"bibr\" target=\"#b18\">[19]</ref>. Various entities, such as healthcare providers, pharmacological firms, research institutions, and government parastatals, are now accumulating vast volumes of data from diverse sources, including research, clinical trials, public health programs, and insurance data. The merging of such data holds immense potential for advancing healthcare practices and decision-making <ref type=\"bibr\" target=\"#b19\">[20]</ref>. Traditionally, doctors used to diagnose and treat patients based on their symptoms alone. However, evidence-based medicine has become the prevailing approach, where physicians review extensive datasets obtained from medical trials and treatment paths on a huge scale to make decisions built on the most comprehensive and up-to-date information available. This shift towards datadriven decision-making is transforming healthcare practices, improving patient outcomes, and driving further advancements in the medical field <ref type=\"bibr\" target=\"#b13\">[14]</ref>.</p><p>Numerous industry and research initiatives are actively working on implementing machine learning expertise in the healthcare sector to enhance patient care and well-being globally. One such initiative is the Shah Lab, based at Stanford University <ref type=\"bibr\" target=\"#b13\">[14]</ref>. The Shah Lab focuses on leveraging machine learning and data science to address critical healthcare challenges and develop innovative solutions for various medical applications. Through these initiatives, researchers and experts aim to harness the power of machine learning to analyze large-scale healthcare data, including electronic health records, medical imaging, genomics, and patient outcomes. By extracting valuable insights and patterns from this data, they aim to improve disease diagnosis, treatment prediction, personalized medicine, and overall patient management. The goal is to provide healthcare professionals with advanced tools and technologies that can assist them in making more accurate and timely clinical decisions, leading to better patient outcomes and an overall improvement in healthcare services worldwide. Table <ref type=\"table\" target=\"#tab_0\">1</ref> below presents a summary of the performance metrics related to the existing methods under evaluation, with each entry corresponding to specific evaluation criteria. istics, including uneven vessel thickness, complex vascular structures in the background, and the presence of noise. The dataset consisted of 130 X-ray coronary angiograms, each having a size of 300 × 300 pixels. The data was collected from the cardiology department of the Mexican Social Security Institute, and ethical approval was obtained (reference number R-2019-1001-078) for the use of this medical database in heart disease diagnosis. To train and evaluate their proposed model, called ASCARIS, the dataset was randomly divided into two parts: a training set containing 100 images and a test set comprising 30 images.</p><p>The ASCARIS model was developed based on color, diameter, and shape features extracted from the angiography images. Al Mehedi et al. <ref type=\"bibr\" target=\"#b27\">[28]</ref> utilized a dataset of 299 heart failure patients obtained from the Faisalabad Institute of Cardiology and the Allied Hospital in Faisalabad. The dataset consisted of 13 attributes, including features such as Age, Anemia, High Blood Pressure, Creatinine Phosphokinase (CPK), Diabetes, Ejection Fraction, Sex, Serum Creatinine, Serum Sodium, Smoking, Time, and a target column labeled as \"Death Event\", which was used for binary classification. The dataset underwent preprocessing to ensure its quality and consistency. After preprocessing, the dataset was divided into separate train and test sets for model training and evaluation. Two feature selection methods were applied to the train set to identify the most relevant features for the heart failure prediction task.</p><p>Deepika and Seema <ref type=\"bibr\" target=\"#b28\">[29]</ref> conducted a study on heart disease with datasets available online from the UCI Machine Learning Repository at the University of California, Irvine. They comprise 76 attributes, including the target property, but only 14 of these attributes were considered essential for analysis. The researchers used two specific datasets for their study: the Cleveland Clinic Foundation dataset, with records from 303 patients, and the Hungarian Institute of Cardiology dataset, with records from 294 patients. Various machine learning algorithms, including Naïve Bayes (NB), Support Vector Machine (SVM), Decision Tree (DT), and Artificial Neural Networks, were employed in the analysis to predict heart disease. Within the broader context, Table <ref type=\"table\" target=\"#tab_1\">2</ref> clarifies the preprocessing approaches and predictive methodologies utilized in previous studies. </p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Study Dataset Preprocessing and Modeling Results</head><p>Algarni et al. <ref type=\"bibr\" target=\"#b26\">[27]</ref> Coronary artery X-ray angiography images obtained from a clinical database.</p><p>Training: 100 images Test: 30 images ASCARIS model (based on color, diameter, and shape features).</p><p>Accuracy: 97%</p><p>Uyar and ˙Ilhan <ref type=\"bibr\" target=\"#b29\">[30]</ref> Cleveland dataset for heart disease.</p><p>Removal of 6 instances with missing entries from the dataset and categorization of the diagnosis attribute (num) into two classes: absence (num = 0) and presence (num = 1, 2, 3, or 4) of heart disease. </p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"2.4.\">Discussions on the Research Limitations</head><p>The literature review involved an in-depth exploration of the existing research and knowledge pertaining to heart disease prediction using diverse machine learning and deep learning techniques. Several studies reviewed the recent advancements and limitations of applying machine learning for cardiovascular disease detection <ref type=\"bibr\" target=\"#b9\">[10,</ref><ref type=\"bibr\" target=\"#b32\">[33]</ref><ref type=\"bibr\" target=\"#b33\">[34]</ref><ref type=\"bibr\" target=\"#b34\">[35]</ref><ref type=\"bibr\" target=\"#b35\">[36]</ref>. For instance, the studies [8, <ref type=\"bibr\" target=\"#b36\">[37]</ref><ref type=\"bibr\" target=\"#b37\">[38]</ref><ref type=\"bibr\" target=\"#b38\">[39]</ref><ref type=\"bibr\" target=\"#b39\">[40]</ref> proposed different data mining and machine learning methods based on heartbeat segmentation and selection process, ECG images, images of carotid arteries, and others.</p><p>Numerous studies have concentrated on applying machine learning algorithms such as Decision Tree, Naïve Bayes, Random Forest, Support Vector Machine, and Logistic Regression on the Heart Disease Dataset, yielding promising accuracy rates for classification. Moreover, deep learning methods, particularly Convolutional Neural Networks (CNN), have gained significant traction for effectively handling complex tasks and unstructured data. The review also examined discussions regarding the implementation of data preprocessing techniques, feature selection methods, and performance evaluation metrics to optimize the efficiency of predictive models. Some studies underscored the importance of data quality and the relevance of specific features in enhancing the accuracy of the models.</p><p>Machine learning algorithms play a crucial role in precisely foretelling heart disease by discovering suppressed patterns in data, making predictions, and improving performance based on historical data. These programs make it possible for us to anticipate and diagnose heart disease more accurately, while deep learning, fueled by artificial neural networks, is a critical factor in handling complex computations on large volumes of data. These algorithms play an essential role in identifying key attributes and patterns in both structured and unstructured data, enhancing more efficient data analysis and processing.</p><p>Employing machine learning and deep learning approaches offers considerable potential in the field of heart disease diagnosis and treatment. These sophisticated techniques enable the integration of various data sources, such as medical records, imaging data, genetics, and lifestyle factors, to create a universal and individualized approach to healthcare. The iterative nature of machine learning acknowledges continuous learning and adaptation, resulting in progressed diagnostic and predictive models over time. This promises to enhance the accuracy and effectiveness of heart disease management, ultimately leading to better patient outcomes.</p><p>After reviewing the available literature, it is evident that there is a lack of extensive experimentation on the use of Gradient Boosting models in the detection of heart disease. However, considering the unique capabilities of Gradient Boosting models in analyzing data and capturing temporal dependencies, their potential in this domain is worth exploring.</p><p>The potential of Gradient Boosting models to progressively enhance predictive accuracy by refining weaker learners within the model positions them as promising contenders for improving the precision of heart disease detection. Consequently, there is a need for further exploration and experimentation dedicated to harnessing the capabilities of Gradient Boosting models in this context.</p><p>By embracing the use of Gradient Boosting models in heart disease detection and conducting more targeted experiments, we can unlock new possibilities for advancing healthcare interventions and ultimately enhancing patient outcomes and well-being.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.\">Materials and Methods</head><p>The following methods are adapted to achieve the goals of this research. They are applied to explore and comprehend various dimensions of heart-related conditions, ultimately contributing to the creation of precise models for the diagnosis and prediction of these conditions. The general research method framework of this study is shown in Figure <ref type=\"figure\" target=\"#fig_0\">1</ref>.</p><p>The following methods are adapted to achieve the goals of this research. They are applied to explore and comprehend various dimensions of heart-related conditions, ultimately contributing to the creation of precise models for the diagnosis and prediction of these conditions. The general research method framework of this study is shown in Figure <ref type=\"figure\" target=\"#fig_0\">1</ref>. </p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.1.\">Datasets</head><p>To carry out this research study, two datasets were examined, namely the Cardiovascular Heart Disease Dataset, which was retrieved from the Mendeley database, and the Heart Disease Cleveland Dataset, which was retrieved from the Kaggle database. The \"Cardio\" and \"Target\" columns on both datasets refer to the column we are trying to predict with numeric values 0 (no disease) and 1 (disease). It is important to note that neither dataset has any missing values. The detailed descriptions of all these attributes are listed below: </p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.1.\">Datasets</head><p>To carry out this research study, two datasets were examined, namely the Cardiovascular Heart Disease Dataset, which was retrieved from the Mendeley database, and the Heart Disease Cleveland Dataset, which was retrieved from the Kaggle database. The \"Cardio\" and \"Target\" columns on both datasets refer to the column we are trying to predict with numeric values 0 (no disease) and 1 (disease). It is important to note that neither dataset has any missing values. The detailed descriptions of all these attributes are listed below:</p><p>The Cardiovascular Heart Disease Dataset (Table <ref type=\"table\" target=\"#tab_3\">3</ref>) holds significant importance within the healthcare and machine learning domains. It serves as an asset for tasks associated with the prediction and classification of cardiovascular diseases while holding data of 1000 data samples in 13 attributes, each representing a potential risk factor. Shifting our focus to the Heart Disease Cleveland Dataset (Table <ref type=\"table\" target=\"#tab_4\">4</ref>), a widely recognized dataset frequently employed in the fields of machine learning and healthcare, which has been extensively used in tasks related to predicting and classifying heart disease. This dataset holds prominence for its pivotal role in assessing the effectiveness of diverse machine learning algorithms in diagnosing heart disease with 303 patients' information in 14 attributes. Its primary objective revolves around predicting whether heart disease is present or absent. </p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.\">cp</head><p>Categorical attribute indicating the various types of chest pain felt by the patient. 0 for typical angina, 1 for atypical angina, 2 for non-anginal pain, and 3 for asymptomatic.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.\">trestbps</head><p>Numerical measurement of the patient's blood pressure at rest, recorded in mm/HG.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"5.\">chol</head><p>Numeric value indicating the serum cholesterol intensity of the patient, calculated in mg/dL.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"6.\">fbs</head><p>Categorical representation of fasting blood sugar levels, with 1 signifying levels above 120 mg/dL and 0 indicating levels below.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"7.\">restecg</head><p>Categorical feature describing the result of the electrocardiogram conducted at rest. 0 for normal, 1 for ST-T wave abnormalities, and 2 for indications of probable or definite left ventricular hypertrophy according to Estes' criteria.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"8.\">thalach</head><p>Numeric representation of the heart rate realized by the patient.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"9.\">exang</head><p>Categorical feature denoting whether exercise-induced angina is present. 0 signifies no, while 1 signifies yes.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"10.\">oldpeak</head><p>Numeric value indicating exercise-induced ST-depression relative to the rest state.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"11.\">slope</head><p>Categorical attribute representing the slope of the ST segment during peak exercise. It can take three values: 0 for up-sloping, 1 for flat, and 2 for down-sloping.</p><p>12. ca Categorical feature indicating the number of major blood vessels, ranging from 0 to 3.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"13\">thal</head><p>Categorical representation of a blood disorder called thalassemia. 0 for NULL, 1 for normal blood flow, 2 for fixed defects (indicating no blood flow in a portion of the heart), and 3 for reversible defects (indicating abnormal but observable blood flow).</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"14.\">target</head><p>The target variable to predict heart disease, encoded as 1 for patients with heart disease and 0 for patients without heart disease.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.2.\">Data Pre-Processing</head><p>Data preprocessing is an essential step within machine learning that aims to improve dataset quality and reliability before analysis and modeling. This phase tackles challenges such as missing data, inconsistencies, outliers, and skewed class distributions. Addressing missing values is crucial to ensure accurate insights by utilizing techniques such as imputation. Detecting and managing outliers is also vital, as these data points can skew results. A key concern is class distribution balance, where methods like oversampling mitigate imbalanced datasets. Considering these considerations, employing techniques such as feature scaling, normalization, and dimensionality reduction can optimize data for effective machine learning analysis.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.3.\">Model Development</head><p>The conclusion of the thorough literature work brings us to the pivotal stage of model development. This section encompasses seven notable machine learning techniques: Logistic Regression, Convolutional Neural Network, Support Vector Machine (SVM), Gradient Boosting, K-Nearest Neighbors (KNN), XGBoost, and Random Forest. Each algorithm contributes distinct characteristics to unveil predictive revelations in the analysis of cardiovascular and cerebrovascular diseases, utilizing resources such as Scikit-Learn and Keras libraries.</p><p>Each of these models possesses unique traits, spanning from linear approaches to ensemble techniques and deep learning architectures. Through thorough empirical investigations, we assessed the effectiveness of every model in terms of recall, precision, accuracy, and F1-score metrics.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.4.\">Model Evaluation</head><p>Model Evaluation stands as a pivotal phase in the realm of machine learning, dedicated to thoroughly gauging how well-trained models predict outcomes. This essential step ensures that models can generalize to new data effectively, informing decisions about deployment and refinement. The following key techniques and metrics will contribute to a comprehensive evaluation of this study:</p><p>Confusion Matrix: Offering insight into true positives, true negatives, false positives, and false negatives, this matrix forms the basis for calculating vital metrics.</p><p>Accuracy: Providing an overall view of model performance by measuring correctly predicted instances against the total dataset.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Accuracy = (TP + TN)/(TP + FP + TN + FN)</head><p>(</p><p>Precision and Recall: Precision assesses positive prediction accuracy, while recall gauges the model's ability to capture positive instances.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Precision = TP/(TP + FP)</head><p>(</p><p>Recall = TP/(TP + FN)</p><p>F1-Score: Striking a balance between precision and recall, this score is essential for harmonizing performance aspects. F1 = (2 × precision × recall)/(precision + recall)</p><p>Cross-Validation: This technique partitions data for training and testing, guarding against overfitting.</p><p>Hyperparameter Tuning: Optimizing model parameters through techniques like GridSearch enhances performance.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.\">Results</head><p>This section explores the detailed analysis of machine learning models for heart disease prediction, leveraging two distinct datasets: the Cardiovascular Heart Disease Dataset and the Heart Disease Cleveland Dataset using the Python programming language.</p><p>Our primary objective is to identify the most effective predictive models, considering both traditional tabular datasets while keeping in mind the aims of the study.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.1.\">Pre-Processing Results</head><p>To harness the potential of the Cardiovascular Heart Disease Dataset and the Heart Disease Cleveland Dataset for machine learning applications, it becomes imperative to execute preliminary data preprocessing procedures. These procedures encompass a range of actions, including managing missing data, encoding categorical variables, standardizing or normalizing feature values, and partitioning the dataset into distinct training and testing subsets. Additionally, the utilization of exploratory data analysis (EDA) techniques and data visualization tools proves instrumental in gaining insights into data distributions and inter-variable relationships.</p><p>Firstly, a correlation matrix heatmap is created, as shown in Figure <ref type=\"figure\" target=\"#fig_3\">2</ref>. This heatmap computes the correlation coefficients among diverse attributes in the datasets and represents them graphically. Its purpose is to facilitate the visual examination of associations between various features. Positive correlations are depicted using green hues, whereas negative correlations are represented in red. This heatmap serves the purpose of identifying the features that exhibit the most substantial correlations with the target variable, thereby revealing their impact on the presence or absence of cardiovascular disease. On the left side is the Cardiovascular Heart Disease Dataset, while on the right is the Heart Disease Cleveland Dataset.  The histograms corresponding to individual dataset attributes provide valuable insights by allowing exploration of each feature's distribution, as shown in Figure <ref type=\"figure\" target=\"#fig_6\">3</ref>. They are instrumental in the detection of potential outliers and provide a rapid overview of the characteristics and spans of these features. This visualization is a helpful tool for compre- The histograms corresponding to individual dataset attributes provide valuable insights by allowing exploration of each feature's distribution, as shown in Figure <ref type=\"figure\" target=\"#fig_6\">3</ref>. They are instrumental in the detection of potential outliers and provide a rapid overview of the characteristics and spans of these features. This visualization is a helpful tool for comprehending the overall shape and distribution of the data. The pictorial evidence of both datasets can be seen below, where the Cardiovascular Heart Disease Dataset is on the left, and the Heart Disease Cleveland Dataset can be seen on the right. As shown in Figure <ref type=\"figure\" target=\"#fig_8\">4</ref>, the pie chart is utilized to depict the distribution of the target variable, which signifies the existence or non-existence of cardiovascular disease. The figure shows the distribution of features in the target variable, where 1 represents features As shown in Figure <ref type=\"figure\" target=\"#fig_8\">4</ref>, the pie chart is utilized to depict the distribution of the target variable, which signifies the existence or non-existence of cardiovascular disease. The figure shows the distribution of features in the target variable, where 1 represents features with heart disease, and 0 represents features without heart disease. It enumerates the instances of each class and exhibits the proportions as percentages in the pie chart, illustrating the presence and absence of cardiovascular disease. In Figure <ref type=\"figure\" target=\"#fig_8\">4</ref>  After successfully preprocessing and visualizing the features of the dataset, we conducted an in-depth exploration of various machine learning models to discern their predictive efficacy.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.2.\">K-Nearest Neighbors (KNN) Results</head><p>We commenced the analysis by employing the K-Nearest Neighbors (KNN) algorithm with varying 'k' values, representing the number of nearest neighbors considered during the predictions. Employing cross-validation, we computed scores for each 'k' value, ultimately discerning that 'k = 7′ yielded the most favorable mean cross-validation score. This outcome underscores that configuring KNN with 'k = 7′ exhibits significant promise.</p><p>As shown in Tables <ref type=\"table\" target=\"#tab_9\">5-8</ref>, the implementation of this model yielded an impressive accuracy rate of 96.50% and 91.80% on the datasets, respectively, serving as an overarching measure of the model's correctness in its predictions. Furthermore, meticulous hyperparameter tuning was carried out to guarantee optimal performance. The precision score, gauging the proportion of true positive predictions among all positive predictions, achieved a notable level, approximately 96.61% and 96.55%. Additionally, the recall, representing the proportion of true positive predictions among all actual positives, exhibited a strong value, approximately 97.44%, and 87.50%. Similarly, the F1 Score attained an impressive value, hovering around 97.02% and 91.80%. These metrics collectively affirm the exceptional performance of the KNN model within the dataset.  After successfully preprocessing and visualizing the features of the dataset, we conducted an in-depth exploration of various machine learning models to discern their predictive efficacy.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.2.\">K-Nearest Neighbors (KNN) Results</head><p>We commenced the analysis by employing the K-Nearest Neighbors (KNN) algorithm with varying 'k' values, representing the number of nearest neighbors considered during the predictions. Employing cross-validation, we computed scores for each 'k' value, ultimately discerning that 'k = 7' yielded the most favorable mean cross-validation score. This outcome underscores that configuring KNN with 'k = 7' exhibits significant promise.</p><p>As shown in Tables <ref type=\"table\" target=\"#tab_9\">5-8</ref>, the implementation of this model yielded an impressive accuracy rate of 96.50% and 91.80% on the datasets, respectively, serving as an overarching measure of the model's correctness in its predictions. Furthermore, meticulous hyperparameter tuning was carried out to guarantee optimal performance. The precision score, gauging the proportion of true positive predictions among all positive predictions, achieved a notable level, approximately 96.61% and 96.55%. Additionally, the recall, representing the proportion of true positive predictions among all actual positives, exhibited a strong value, approximately 97.44%, and 87.50%. Similarly, the F1 Score attained an impressive value, hovering around 97.02% and 91.80%. These metrics collectively affirm the exceptional performance of the KNN model within the dataset. </p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.3.\">Random Forest Results</head><p>By conducting an extensive hyperparameter tuning process, we modified the number of trees (n_estimators) to 200 within the Random Forest ensemble model. As shown in Tables 5-8, the tuned model achieved an outstanding accuracy level, hovering at around 98.60% and 91.09%. The assessment of precision showed a significant enhancement, which obtained 98.63% and 94.44%.</p><p>Similarly, the F1 Score, which amalgamates precision and recall, demonstrated the model's robustness, registering a value of 98.80% and 89.81, respectively. Furthermore, the recall score, measuring the model's aptitude for recognizing genuine positive cases, reached a remarkable value of 98.97% and 85.61.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.4.\">Logistic Regression (LR) Results</head><p>By implementing a custom threshold of 0.6, the model was configured to adopt a cautious approach when classifying instances as positive. To be specific, if the predicted probability of an instance belonging to the positive class (class 1) equaled or exceeded 0.6, it was categorized as positive; otherwise, it was designated as negative. This threshold selection significantly influenced how the model struck a balance between precision and recall. As shown in Tables <ref type=\"table\" target=\"#tab_9\">5-8</ref>, the model's precision score was 96.55% and 93.10%, signifying its proficiency in minimizing false positive predictions.</p><p>The recall scores stood at 95.73% and 84.38%, emphasizing the model's importance in correctly identifying all positive cases, particularly in scenarios where missing potential cases of heart disease is a critical concern. The F1 Score captured genuine positive cases at 96.14% and 88.52%. Regarding overall accuracy, the model achieved an accuracy score of 95.50% and 88.52%.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.5.\">Gradient Boosting (GB) Results</head><p>Through the GridSearchCV process, we effectively fine-tuned the model's hyperparameters. The optimal hyperparameters selected encompassed a learning rate of 0.2, a maximum depth of 3 for individual trees, and 100 boosting stages (n_estimators). These hyperparameters were chosen based on their exceptional performance on the validation datasets. When tested on independent data, the refined Gradient Boosting model consistently delivered exceptional results. As shown in Tables <ref type=\"table\" target=\"#tab_9\">5-8</ref>, it attained an impressive precision score of 99.13% and 90.90%, indicative of its ability to minimize false positive predictions effectively.</p><p>Furthermore, the model exhibited a recall score of 97.44% and 84.38%, which holds paramount importance in medical applications where identifying potential cases of heart disease is critical. The F1 Score, which harmonizes precision and recall, reached an impressive value of 98.28% and 87.10.</p><p>The model's accuracy on the test dataset was consistently high, measuring 98.00%, although it achieved 86.89% on the Heart Disease Cleveland Dataset. These findings collectively underscore the Gradient Boosting model's exceptional suitability for the task of heart disease classification, highlighting its potential to accurately detect individuals with heart disease while maintaining a low rate of false positives. Such performance makes it an asset for healthcare professionals and researchers in the cardiology field.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.6.\">Support Vector Machine (SVM) Results</head><p>The process of tuning hyperparameters, carried out through GridSearchCV, effectively determined the most suitable hyperparameter configuration for the SVM model. This configuration included a regularization parameter (C) set to 10, a polynomial kernel with a degree of 2, and the utilization of a linear kernel.</p><p>As shown in Tables <ref type=\"table\" target=\"#tab_9\">5-8</ref>, for post-tuning, the model achieved a precision score of 95.00% and 80.65%, a recall score of 97.44% and 78.12%, and an F1 Score of 96.20% and 79.37%.</p><p>On the test dataset, the model exhibited an accuracy of approximately 95.50% and 78.69%, affirming its consistent and accurate predictive capabilities.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.7.\">Convolutional Neural Network (CNN) Results</head><p>The model architecture consists of three layers: an initial layer with 128 units employing the ReLU activation function, followed by a hidden layer featuring 64 units with ReLU activation, and ultimately, an output layer utilizing the sigmoid activation function. During model compilation, the Adam optimizer was employed alongside binary cross-entropy loss, with accuracy serving as the evaluation metric.</p><p>To mitigate the risk of overfitting, a precautionary measure known as early stopping was integrated into the training process. This involved monitoring the validation loss for a maximum of 10 epochs and restoring the model's weights to their best configuration. The training was conducted using scaled training data over a maximum of 100 epochs, employing a batch size of 64.</p><p>As shown in Tables <ref type=\"table\" target=\"#tab_9\">5-8</ref>, the model's performance on the test dataset is particularly noteworthy. Precision achieved an impressive score of 97.46% and 87.50%.</p><p>This suggests that when the model predicts an individual as having heart disease, it is highly likely to be accurate. Furthermore, the recall scores were 98.29% and 87.50%. The F1 Score demonstrates resilience at 97.87% and 87.50%. Overall accuracy, which reflects the ratio of correctly predicted cases to the total cases, stands at 97.50% and 86.89%, respectively.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.8.\">XGBoost Results</head><p>Through the utilization of GridSearchCV, a highly effective process of hyperparameter tuning was carried out. This process led to the discovery of optimal hyperparameters for the XGBoost model, which included a learning rate of 0.2, a maximum tree depth of 3, 100 boosting rounds (n_estimators), and a subsample fraction of 1.0. The recall of these chosen hyperparameters was substantiated by a remarkable validation score of approximately 98.00% on the Cardiovascular Heart Disease Dataset and 84% on the Heart Disease Cleveland Dataset, respectively.</p><p>On the test dataset, the fine-tuned XGBoost model upheld its exceptional performance by achieving a precision score of 99.14% and 90.00%, signifying its adeptness in accurately categorizing positive cases. Moreover, the recall score, at 98.29% and 84.38%, holds particular significance. The F1 Score exhibits resilience at 98.71% and 87.10%. The model's overall accuracy on the test data hovers at 98.50% and 86.89%. These remarkable outcomes underscore the XGBoost model's aptness for heart disease classification.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"5.\">Discussion</head><p>The experimental results are shown in Tables 5-8 and Figure <ref type=\"figure\" target=\"#fig_11\">5</ref>. The thorough assessment of machine learning models, specifically the XGBoost and K-Nearest Neighbors models, in the context of heart disease prediction, provides valuable insights. These insights align with the research conducted by Zhang et al. <ref type=\"bibr\" target=\"#b40\">[41]</ref>, which underscores the effectiveness of the XGBoost algorithm in this specific domain.  </p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"6.\">Conclusions and Future Scope</head><p>As we discussed the broader scope of model selection and its implications for heart disease prediction, the conducted analysis has unearthed invaluable insights. Among the array of models under scrutiny, K-Nearest Neighbors and XGBoost have consistently risen to prominence as top-performing candidates across both datasets, as shown below. These models have exhibited remarkable accuracy and recall scores, rendering them robust contenders for the precise classification of heart disease. It is noteworthy, however, that other models, including Logistic Regression, Convolutional Neural Network, Gradient Boost, Random Forest (RF), and Support Vector Machines (SVM), have showcased Across both datasets, these models consistently demonstrate exceptional performance, emphasizing their efficacy in heart disease prediction. Notably, the XGBoost model stands out with an impressive accuracy rate of 98.50% in the Cardiovascular Heart Disease Dataset, while the K-Nearest Neighbors (KNN) model achieves a commendable accuracy of 91.80% in the Heart Disease Cleveland Dataset. These high levels of accuracy emphasize the models' reliability, positioning them as valuable tools for diagnosing heart disease.</p><p>Precision, a critical metric in healthcare, reflects the models' ability to identify heart disease cases precisely. Both models achieve outstanding precision, with the XGBoost model leading at 99.14%, closely followed by the KNN model at 96.55%. These elevated precision levels significantly reduce the occurrence of false positive diagnoses, alleviating unnecessary concerns for patients.</p><p>Furthermore, the F1 Score, which balances precision and recall, highlights the XGBoost model's effectiveness in recognizing heart disease cases while minimizing the risk of overlooking positive instances. The model achieves F1 Scores of 98.71% and 91.80% in both datasets, showcasing its ability to strike this delicate balance effectively.</p></div>\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"6.\">Conclusions and Future Scope</head><p>As we discussed the broader scope of model selection and its implications for heart disease prediction, the conducted analysis has unearthed invaluable insights. Among the array of models under scrutiny, K-Nearest Neighbors and XGBoost have consistently risen to prominence as top-performing candidates across both datasets, as shown below. These models have exhibited remarkable accuracy and recall scores, rendering them robust contenders for the precise classification of heart disease. It is noteworthy, however, that other models, including Logistic Regression, Convolutional Neural Network, Gradient Boost, Random Forest (RF), and Support Vector Machines (SVM), have showcased significant predictive capabilities once their hyperparameters were meticulously tuned. In this diverse ensemble, XGBoost emerges as a standout performer, marked by its exceptional accuracy and recall scores, coupled with a harmoniously balanced F1 Score and precision on the Cardiovascular Heart Disease Dataset. This points out XGBoost's transformative potential in the realm of heart disease prediction and diagnosis, positioning it as an invaluable tool for healthcare professionals. The model instills a high level of confidence in identifying potential cases of heart disease, firmly establishing itself as an exemplary choice within this dataset. The exceptional precision and accuracy exhibited by these models bear profound implications for the diagnosis and care of individuals with heart disease. Such precision not only enhances diagnostic accuracy but also opens new avenues for interventions and treatments that can be initiated with heightened confidence. In the quest for the most suitable model, it is imperative to align the selection with the specific requirements and constraints of the application at hand. Practical considerations such as interpretability, computational complexity, and data availability should guide the decision-making process, ensuring that the chosen model is tailored to meet the unique needs of the task. These findings culminate in a valuable resource that can empower informed decision-making within the realm of heart disease prediction, particularly in clinical settings. The potential to revolutionize heart disease diagnosis and patient care is emphasized, further cementing the significance of machine learning in the field of healthcare. In practical terms, this implies that when the model indicates an individual as having heart disease, the likelihood of accuracy is notably high, signifying a significant advancement in the landscape of medical diagnostics. Future directions for this study could involve expanding the scope by incorporating more extensive medical imaging datasets. Leveraging such data could enhance image-based heart disease prediction, potentially leading to even more accurate and robust diagnostic tools in the field of cardiovascular health. Furthermore, exploring ensemble models that merge the strengths of multiple algorithms may offer promising avenues for further improving predictive accuracy in the field of heart disease prediction. These considerations shed light on the multifaceted nature of heart disease prediction research, emphasizing the need for ongoing refinement and innovation in this critical domain. Future research directions should also prioritize the refinement of models and expansion of datasets. In contrast to <ref type=\"bibr\" target=\"#b41\">[42,</ref><ref type=\"bibr\" target=\"#b42\">43]</ref>, our study employs a distinct dataset, leveraging its unique characteristics to enhance the robustness and generalizability of the models. Furthermore, the selection of machine learning models in our work deviates from those used in the cited studies, contributing to the innovative aspect of our approach. Importantly, the outcomes of our models exhibit a noteworthy improvement in predictive accuracy, establishing a superior performance benchmark.</p><p>This nuanced combination of dataset, model selection, and elevated accuracy underscores the distinctive contribution of our work to the field of heart disease prediction. It positions our study as an advancement beyond existing research, offering a more refined and accurate predictive framework.</p></div><figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_0\"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Research method workflow.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_1\"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Research method workflow.</figDesc><graphic coords=\"7,125.90,87.05,381.60,237.71\" type=\"bitmap\" /></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_2\"><head>Diagnostics 2024 ,</head><label>2024</label><figDesc>14,  x FOR PEER REVIEW 11 of 20 thereby revealing their impact on the presence or absence of cardiovascular disease. On the left side is the Cardiovascular Heart Disease Dataset, while on the right is the Heart Disease Cleveland Dataset.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_3\"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Heatmap distribution of the dataset features.</figDesc><graphic coords=\"10,164.90,481.65,378.00,272.48\" type=\"bitmap\" /></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_4\"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Heatmap distribution of the dataset features.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_5\"><head>Diagnostics 2024 , 20 Figure 3 .</head><label>2024203</label><figDesc>Figure 3. Histogram distribution of the dataset features.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_6\"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Histogram distribution of the dataset features.</figDesc><graphic coords=\"11,165.37,478.23,285.35,276.17\" type=\"bitmap\" /></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_7\"><head></head><label></label><figDesc>, the pie chart on the right represents features of the target column distribution of the Cardiovascular Heart Disease Dataset, while the left represents the feature of the target column distribution of the Heart Disease Cleveland Dataset. Diagnostics 2024, 14, x FOR PEER REVIEW 13 of 20 Disease Dataset, while the left represents the feature of the target column distribution of the Heart Disease Cleveland Dataset.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_8\"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The distribution of features in the target variable.</figDesc><graphic coords=\"12,355.46,206.18,201.59,219.04\" type=\"bitmap\" /></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_9\"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The distribution of features in the target variable.</figDesc><graphic coords=\"12,160.83,206.18,183.13,219.06\" type=\"bitmap\" /></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_10\"><head>Diagnostics 2024 ,</head><label>2024</label><figDesc>14, x FOR PEER REVIEW 17 of 20</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_11\"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Accuracy of machine learning models on both datasets.</figDesc></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_12\"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Accuracy of machine learning models on both datasets.</figDesc><graphic coords=\"15,169.67,515.58,360.00,173.25\" type=\"bitmap\" /></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_0\"><head>Table 1 .</head><label>1</label><figDesc>Summary of the performance of the existing methods.</figDesc><table><row><cell>Study</cell><cell>Method</cell><cell>Results</cell></row><row><cell>Mohan et al. [21]</cell><cell>Hybrid Random Forest with Linear Model (HRFLM)</cell><cell>Accuracy: 88% Sensitivity: 92.8% Specificity: 82.6%</cell></row><row><cell></cell><cell>SVM</cell><cell>83% Accuracy SVM</cell></row><row><cell>Singh et al. [22]</cell><cell>K-Nearest Neighbors Decision Tree</cell><cell>79% (DT) 78% (LR)</cell></row><row><cell></cell><cell>Linear Regression</cell><cell>87% (KNN)</cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_1\"><head>Table 2 .</head><label>2</label><figDesc>Preprocessing and predictive methods.</figDesc><table /></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_3\"><head>Table 3 .</head><label>3</label><figDesc>Cardiovascular Heart Disease Dataset.</figDesc><table><row><cell>Features</cell><cell>Details</cell></row><row><cell>1. Patient Id</cell><cell>Individual unique identifier.</cell></row><row><cell>2. Age</cell><cell>Numeric representation of patients' age in years.</cell></row><row><cell>3. Gender</cell><cell>Binary (1, 0 (0 = female, 1 = male))</cell></row><row><cell>4. Chestpain</cell><cell>Nominal (0, 1, 2, 3 (Value 0: typical angina Value 1: atypical angina Value 2: non-anginal pain Value 3: asymptomatic))</cell></row><row><cell>5. restingBP</cell><cell>Numeric (94-200 (in mm HG))</cell></row><row><cell>6. serumcholestrol</cell><cell>Numeric (126-564 (in mg/dL))</cell></row><row><cell>7. fastingbloodsugar</cell><cell>Binary (0, 1 &gt; 120 mg/dL (0 = false, 1 = true))</cell></row><row><cell></cell><cell>Nominal (0, 1, 2 (Value 0: normal, Value 1: having ST-T wave</cell></row><row><cell>8. restingrelectro</cell><cell>abnormality (T wave inversions and/or ST elevation or depression of &gt;0.05 mV), Value 2: showing probable or definite</cell></row><row><cell></cell><cell>left ventricular hypertrophy by Estes' criteria))</cell></row><row><cell>9. maxheartrate</cell><cell>Numeric (71-202)</cell></row><row><cell>10. exerciseangia</cell><cell>Binary (0, 1 (0 = no, 1 = yes))</cell></row><row><cell>11. oldpeak</cell><cell>Numeric (0-6.2)</cell></row><row><cell>12. slope</cell><cell>Nominal (1, 2, 3 (1-upsloping, 2-flat, 3-downsloping))</cell></row><row><cell>13. noofmajorvessels</cell><cell>Numeric (0, 1, 2, 3)</cell></row><row><cell>14. target</cell><cell>Binary (0, 1 (0 = Absence of Heart Disease, 1= Presence of Heart Disease))</cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_4\"><head>Table 4 .</head><label>4</label><figDesc>Heart Disease Cleveland Dataset.</figDesc><table><row><cell>Features</cell><cell>Details</cell></row><row><cell>1. Age</cell><cell>Numeric representation of patients' age in years.</cell></row><row><cell>2. Sex</cell><cell>Categorical feature representing gender, where Male is encoded as 1 and Female as 0.</cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_5\"><head>Table 5 .</head><label>5</label><figDesc>Results on Precision measure.</figDesc><table><row><cell>Classification Model</cell><cell>Precision (in %)</cell><cell></cell></row><row><cell></cell><cell>Dataset 1</cell><cell>Dataset 2</cell></row><row><cell>KNN</cell><cell>96.50%</cell><cell>96.55%</cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_6\"><head>Table 5 .</head><label>5</label><figDesc>Results on Precision measure.</figDesc><table><row><cell>Classification Model</cell><cell>Precision (in %)</cell><cell></cell></row><row><cell></cell><cell>Dataset 1</cell><cell>Dataset 2</cell></row><row><cell>KNN</cell><cell>96.50%</cell><cell>96.55%</cell></row><row><cell>RF</cell><cell>98.63%</cell><cell>94.44%</cell></row><row><cell>LR</cell><cell>96.55%</cell><cell>93.10%</cell></row><row><cell>GB</cell><cell>99.13%</cell><cell>90.00%</cell></row><row><cell>SVM</cell><cell>95.00%</cell><cell>80.65%</cell></row><row><cell>CNN</cell><cell>99.14%</cell><cell>87.50%</cell></row><row><cell>XGBoost</cell><cell>99.14%</cell><cell>90.00%</cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_7\"><head>Table 6 .</head><label>6</label><figDesc>Results on Recall measure.</figDesc><table><row><cell>Classification Model</cell><cell>Recall (in %)</cell><cell></cell></row><row><cell></cell><cell>Dataset 1</cell><cell>Dataset 2</cell></row><row><cell>KNN</cell><cell>97.44%</cell><cell>87.50%</cell></row><row><cell>RF</cell><cell>98.97%</cell><cell>85.61%</cell></row><row><cell>LR</cell><cell>95.73%</cell><cell>84.38%</cell></row><row><cell>GB</cell><cell>97.44%</cell><cell>84.38%</cell></row><row><cell>SVM</cell><cell>97.44%</cell><cell>78.12%</cell></row><row><cell>CNN</cell><cell>98.29%</cell><cell>89.77%</cell></row><row><cell>XGBoost</cell><cell>98.29%</cell><cell>84.38%</cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_8\"><head>Table 7 .</head><label>7</label><figDesc>Results on F1-Score measure.</figDesc><table><row><cell>Classification Model</cell><cell>F1-Score (in %)</cell><cell></cell></row><row><cell></cell><cell>Dataset 1</cell><cell>Dataset 2</cell></row><row><cell>KNN</cell><cell>97.02%</cell><cell>91.80%</cell></row><row><cell>RF</cell><cell>98.80%</cell><cell>89.81%</cell></row><row><cell>LR</cell><cell>96.14%</cell><cell>88.52%</cell></row><row><cell>GB</cell><cell>98.28%</cell><cell>87.10%</cell></row><row><cell>SVM</cell><cell>96.20%</cell><cell>79.37%</cell></row><row><cell>CNN</cell><cell>97.80%</cell><cell>87.50%</cell></row><row><cell>XGBoost</cell><cell>98.71%</cell><cell>87.10%</cell></row></table></figure>\n",
      "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_9\"><head>Table 8 .</head><label>8</label><figDesc>Results on Accuracy measure.</figDesc><table><row><cell>Classification Model</cell><cell>Accuracy (in %)</cell><cell></cell></row><row><cell></cell><cell>Dataset 1</cell><cell>Dataset 2</cell></row><row><cell>KNN</cell><cell>96.50%</cell><cell>91.80%</cell></row><row><cell>RF</cell><cell>98.60%</cell><cell>91.09%</cell></row><row><cell>LR</cell><cell>95.50%</cell><cell>88.52%</cell></row><row><cell>GB</cell><cell>98.00%</cell><cell>86.89%</cell></row><row><cell>SVM</cell><cell>95.50%</cell><cell>78.69%</cell></row><row><cell>CNN</cell><cell>97.50%</cell><cell>86.89%</cell></row><row><cell>XGBoost</cell><cell>98.50%</cell><cell>86.89%</cell></row></table></figure>\n",
      "\t\t</body>\n",
      "\t\t<back>\n",
      "\n",
      "\t\t\t<div type=\"acknowledgement\">\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Acknowledgments:</head><p>The authors extend their appreciation to the Deanship of Scientific Research at Imam Mohammad Ibn Saud Islamic University for funding this work through Grant Number IMSIU-RG23077.</p></div>\n",
      "\t\t\t</div>\n",
      "\n",
      "\n",
      "\t\t\t<div type=\"funding\">\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><p>Funding: This work was supported and funded by the Deanship of Scientific Research at Imam Mohammad Ibn Saud Islamic University (IMSIU) (grant number IMSIU-RG23077).</p></div>\n",
      "\t\t\t</div>\n",
      "\n",
      "\t\t\t<div type=\"annex\">\n",
      "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Conflicts of Interest:</head><p>The authors declare no conflicts of interest.</p></div>\t\t\t</div>\n",
      "\t\t\t<div type=\"references\">\n",
      "\n",
      "\t\t\t\t<listBibl>\n",
      "\n",
      "<biblStruct xml:id=\"b0\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">World Health Organization. WHO Cardiovascular Diseases</title>\n",
      "\t\t<ptr target=\"https://www.who.int/health-topics/cardiovascular-diseases#tab=tab_1\" />\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2022-01-19\">19 January 2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b1\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Artificial intelligence in medicine</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><forename type=\"middle\">N</forename><surname>Ramesh</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">C</forename><surname>Kambhampati</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">R</forename><surname>Monson</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">P</forename><forename type=\"middle\">J</forename><surname>Drew</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1308/147870804290</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Ann. R. Coll. Surg. Engl</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">86</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2004\">2004</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b2\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Computational detection and interpretation of heart disease based on conditional variational auto-encoder and stacked ensemblelearning framework</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Abdellatif</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><surname>Mubarak</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><surname>Abdellatef</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><surname>Kanesan</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Y</forename><surname>Abdelltif</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">C.-O</forename><surname>Chow</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">H</forename><surname>Chuah</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><forename type=\"middle\">M</forename><surname>Gheni</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>Kendall</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.bspc.2023.105644</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Biomed. Signal Process. Control</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">88</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2024\">2024. 105644</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b3\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">An intelligent Medical Cyber-Physical System to support heart valve disease screening and diagnosis</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>Tartarisco</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>Cicceri</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Bruschetta</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Tonacci</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Campisi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Vitabile</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Cerasa</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Distefano</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Pellegrino</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">P</forename><forename type=\"middle\">A</forename><surname>Modesti</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.eswa.2023.121772</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Expert Syst. Appl</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">238</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2024\">2024. 121772</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b4\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A Systematic Review of Machine Learning and IoT Applied to the Prediction and Monitoring of Cardiovascular Diseases</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Cuevas-Chávez</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Y</forename><surname>Hernández</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><surname>Ortiz-Hernandez</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">E</forename><surname>Sánchez-Jiménez</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>Ochoa-Ruiz</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><surname>Pérez</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>González-Serna</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/healthcare11162240</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Healthcare</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">2023</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2240\">2240</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b5\">\n",
      "\t<analytic>\n",
      "\t\t<title/>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">D</forename><forename type=\"middle\">K</forename><surname>Plati</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">E</forename><forename type=\"middle\">E</forename><surname>Tripoliti</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Bechlioulis</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Rammos</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">I</forename><surname>Dimou</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">L</forename><surname>Lakkas</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">C</forename><surname>Watson</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">K</forename><surname>Mcdonald</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Ledwidge</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Pharithi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/diagnostics11101863</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Machine Learning Approach for Chronic Heart Failure Diagnosis. Diagnostics</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">11</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"1863\">2021. 1863</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b6\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">Machine Learning-Based Cardiovascular Disease Prediction Model: A Cohort Study on the Korean National Health Insurance Service Health Screening Database</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">O</forename><surname>Kim</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Y.-S</forename><surname>Jeong</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">H</forename><surname>Kim</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J.-W</forename><surname>Lee</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">D</forename><surname>Park</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H.-S</forename><surname>Kim</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2021\">2021</date>\n",
      "\t\t\t<biblScope unit=\"page\">943</biblScope>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b7\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Ben Dhaou, I. Artificial Intelligence for Cardiac Diseases Diagnosis and Prediction Using ECG Images on Embedded Systems</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">L</forename><surname>Mhamdi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">O</forename><surname>Dammak</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">F</forename><surname>Cottin</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/biomedicines10082013</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Biomedicines</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">10</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2013\">2022. 2013</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b8\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">Prediction of Coronary Artery Disease Using Machine Learning Techniques with Iris Analysis. Diagnostics</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">F</forename><surname>Özbilgin</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Ç</forename><surname>Kurnaz</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">E</forename><surname>Aydın</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/diagnostics13061081</idno>\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"1081\">2023. 1081</date>\n",
      "\t\t\t<biblScope unit=\"volume\">13</biblScope>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b9\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">Machine Learning and IoT Applied to Cardiovascular Diseases Identification through Heart Sounds: A Literature Review</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">I</forename><forename type=\"middle\">S G</forename><surname>Brites</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">L</forename><forename type=\"middle\">M</forename><surname>Da Silva</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">L V</forename><surname>Barbosa</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">J</forename><surname>Rigo</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">D</forename><surname>Correia</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">V</forename><forename type=\"middle\">R Q</forename><surname>Leithardt</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">https://www.preprints.org/manuscript/202110.0161/v1</idno>\n",
      "\t\t<ptr target=\"https://www.preprints.org/manuscript/202110.0161/v1\" />\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2021-06\">2021. June 2023</date>\n",
      "\t\t</imprint>\n",
      "\t\t<respStmt>\n",
      "\t\t\t<orgName>Repositório Comum (Repositório Científico de Acesso Aberto de Portugal</orgName>\n",
      "\t\t</respStmt>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b10\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Deep Learning-Based Automated Diagnosis for Coronary Artery Disease Using SPECT-MPI Images</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">N</forename><forename type=\"middle\">I</forename><surname>Papandrianos</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Feleki</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">E</forename><forename type=\"middle\">I</forename><surname>Papageorgiou</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">C</forename><surname>Martini</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/jcm11133918</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">J. Clin. Med</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">2022</biblScope>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b11\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Cardiovascular Disease Diagnosis from DXA Scan and Retinal Images Using Deep Learning</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><forename type=\"middle\">R H</forename><surname>Al-Absi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">T</forename><surname>Islam</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">A</forename><surname>Refaee</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">E H</forename><surname>Chowdhury</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">T</forename><surname>Alam</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/s22124310</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Sensors</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">22</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">4310</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b12\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">What Is Machine Learning?</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">I</forename><surname>El Naqa</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">J</forename><surname>Murphy</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2015\">2015</date>\n",
      "\t\t\t<publisher>Springer International Publishing: Berlin/Heidelberg</publisher>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"3\" to=\"11\" />\n",
      "\t\t\t<pubPlace>Germany</pubPlace>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b13\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A study of machine learning in healthcare</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Bhardwaj</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><forename type=\"middle\">R</forename><surname>Nambiar</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">D</forename><surname>Dutta</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\">Proceedings of the 2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC)</title>\n",
      "\t\t\t\t<meeting>the 2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC)<address><addrLine>Torino, Italy; New York, NY, USA</addrLine></address></meeting>\n",
      "\t\t<imprint>\n",
      "\t\t\t<publisher>IEEE</publisher>\n",
      "\t\t\t<date type=\"published\" when=\"2017-07-08\">4-8 July 2017. 2017</date>\n",
      "\t\t\t<biblScope unit=\"volume\">2</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"236\" to=\"241\" />\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b14\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">What is Machine Learning: A Tour of Authoritative Definitions and a Handy One-Liner You Can Use</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><surname>Brownlee</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<ptr target=\"www.machinelearningmastery.com\" />\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2023-11-25\">25 November 2023</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b15\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A wearable smartphone-based platform for real-time cardiovascular disease detection via electrocardiogram processing</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">J</forename><surname>Oresko</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Z</forename><surname>Jin</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><surname>Cheng</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Huang</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Y</forename><surname>Sun</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><surname>Duschl</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><forename type=\"middle\">C</forename><surname>Cheng</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1109/TITB.2010.2047865</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">IEEE Trans. Inf. Technol. Biomed</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">14</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"734\" to=\"740\" />\n",
      "\t\t\t<date type=\"published\" when=\"2010\">2010</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b16\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Deep learning models on Heart Disease Estimation-A review</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">T</forename><forename type=\"middle\">M A M</forename><surname>Sharean</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>Johncy</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">J. Artif. Intell</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">2022</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"122\" to=\"130\" />\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b17\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Hybrid CNN and LSTM network For heart disease prediction</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">V</forename><forename type=\"middle\">K</forename><surname>Sudha</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">D</forename><surname>Kumar</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1007/s42979-022-01598-9</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">SN Comput. Sci</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">2023</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">172</biblScope>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b18\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Big data in genomics: An overview</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Bhardwaj</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Sethi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Nambiar</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\">Proceedings of the 2014 IEEE International Conference on Big Data (Big Data)</title>\n",
      "\t\t\t\t<meeting>the 2014 IEEE International Conference on Big Data (Big Data)<address><addrLine>Beijing, China; New York, NY, USA</addrLine></address></meeting>\n",
      "\t\t<imprint>\n",
      "\t\t\t<publisher>IEEE</publisher>\n",
      "\t\t\t<date type=\"published\" when=\"2014-08\">August 2014. 2014</date>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"45\" to=\"49\" />\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b19\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">The Big-Data Revolution in US Health Care: Accelerating Value and Innovation</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">B</forename><surname>Kayyali</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">D</forename><surname>Knott</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Van Kuiken</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2013\">2013</date>\n",
      "\t\t\t<publisher>Mc Kinsey &amp; Company</publisher>\n",
      "\t\t\t<biblScope unit=\"volume\">2</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"13\" />\n",
      "\t\t\t<pubPlace>Chicago, IL, USA</pubPlace>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b20\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Effective heart disease prediction using hybrid machine learning techniques</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Mohan</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">C</forename><surname>Thirumalai</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>Srivastava</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1109/ACCESS.2019.2923707</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">IEEE Access</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">7</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"81542\" to=\"81554\" />\n",
      "\t\t\t<date type=\"published\" when=\"2019\">2019</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b21\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Heart disease prediction using machine learning algorithms</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Singh</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Kumar</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><surname>February</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\">Proceedings of the 2020 International Conference on Electrical and Electronics Engineering (ICE3)</title>\n",
      "\t\t\t\t<meeting>the 2020 International Conference on Electrical and Electronics Engineering (ICE3)<address><addrLine>Gorakhpur, India; New York, NY, USA</addrLine></address></meeting>\n",
      "\t\t<imprint>\n",
      "\t\t\t<publisher>IEEE</publisher>\n",
      "\t\t\t<date type=\"published\" when=\"2020-02-15\">14-15 February 2020. 2020</date>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"452\" to=\"457\" />\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b22\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Prediction of heart disease using machine learning</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Gavhane</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>Kokkula</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">I</forename><surname>Pandya</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">K</forename><surname>Devadkar</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><surname>March</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\">Proceedings of the 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA)</title>\n",
      "\t\t\t\t<meeting>the 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA)<address><addrLine>Coimbatore, India; New York, NY, USA</addrLine></address></meeting>\n",
      "\t\t<imprint>\n",
      "\t\t\t<publisher>IEEE</publisher>\n",
      "\t\t\t<date type=\"published\" when=\"2018-03\">March 2018. 2018</date>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1275\" to=\"1278\" />\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b23\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Heart disease prediction using hybrid machine learning model</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Kavitha</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>Gnaneswar</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Dinesh</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Y</forename><forename type=\"middle\">R</forename><surname>Sai</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><forename type=\"middle\">S</forename><surname>Suraj</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\">Proceedings of the 2021 6th International Conference on Inventive Computation Technologies (ICICT)</title>\n",
      "\t\t\t\t<meeting>the 2021 6th International Conference on Inventive Computation Technologies (ICICT)<address><addrLine>Coimbatore, India; New York, NY, USA</addrLine></address></meeting>\n",
      "\t\t<imprint>\n",
      "\t\t\t<publisher>IEEE</publisher>\n",
      "\t\t\t<date type=\"published\" when=\"2021-01\">January 2021. 2021</date>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1329\" to=\"1333\" />\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b24\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Heart sound analysis for diagnosis of heart diseases in newborns</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><forename type=\"middle\">M</forename><surname>Amiri</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>Armano</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">APCBEE Procedia</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">7</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"109\" to=\"116\" />\n",
      "\t\t\t<date type=\"published\" when=\"2013\">2013</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b25\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Classification of heart diseases based on ECG signals using long short-term memory</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Liu</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Y</forename><surname>Kim</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\">Proceedings of the 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</title>\n",
      "\t\t\t\t<meeting>the 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)<address><addrLine>Honolulu, HI, USA; New York, NY, USA</addrLine></address></meeting>\n",
      "\t\t<imprint>\n",
      "\t\t\t<publisher>IEEE</publisher>\n",
      "\t\t\t<date type=\"published\" when=\"2018-07-21\">18-21 July 2018. 2018</date>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"2707\" to=\"2710\" />\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b26\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Multi-constraints based deep learning model for automated segmentation and diagnosis of coronary artery disease in X-ray angiographic images</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Algarni</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Al-Rezqi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">F</forename><surname>Saeed</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Alsaeedi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">F</forename><surname>Ghabban</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.7717/peerj-cs.993</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">PeerJ Comput. Sci</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">8</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">e993</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b27\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Identifying prognostic features for predicting heart failure by using machine learning algorithm</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><forename type=\"middle\">M</forename><surname>Hasan</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><surname>Shin</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">U</forename><surname>Das</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><forename type=\"middle\">Y</forename><surname>Srizon</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\">Proceedings of the ICBET&apos;21: 2021 11th International Conference on Biomedical Engineering and Technology</title>\n",
      "\t\t\t\t<meeting>the ICBET&apos;21: 2021 11th International Conference on Biomedical Engineering and Technology<address><addrLine>Tokyo, Japan</addrLine></address></meeting>\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2021-03\">March 2021</date>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"40\" to=\"46\" />\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b28\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Predictive analytics to prevent and control chronic diseases</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">K</forename><surname>Deepika</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Seema</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\">Proceedings of the 2016 2nd International Conference on Applied and Theoretical Computing and Communication Technology (iCATccT)</title>\n",
      "\t\t\t\t<meeting>the 2016 2nd International Conference on Applied and Theoretical Computing and Communication Technology (iCATccT)<address><addrLine>Bangalore, India; New York, NY, USA</addrLine></address></meeting>\n",
      "\t\t<imprint>\n",
      "\t\t\t<publisher>IEEE</publisher>\n",
      "\t\t\t<date type=\"published\" when=\"2016-07-23\">21-23 July 2016. 2016</date>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"381\" to=\"386\" />\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b29\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Diagnosis of heart disease using genetic algorithm based trained recurrent fuzzy neural networks</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">K</forename><surname>Uyar</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Ilhan</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.procs.2017.11.283</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Procedia Comput. Sci</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">120</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"588\" to=\"593\" />\n",
      "\t\t\t<date type=\"published\" when=\"2017\">2017</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b30\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Extracting cardiac dynamics within ECG signal for human identification and cardiovascular diseases classification</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Deng</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">C</forename><surname>Wang</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Tang</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">T</forename><surname>Zheng</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.neunet.2018.01.009</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Neural Netw</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">100</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"70\" to=\"83\" />\n",
      "\t\t\t<date type=\"published\" when=\"2018\">2018</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b31\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Effective diagnosis of heart disease through neural networks ensembles</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Das</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">I</forename><surname>Turkoglu</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Sengur</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.eswa.2008.09.013</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Expert Syst. Appl</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">36</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"7675\" to=\"7680\" />\n",
      "\t\t\t<date type=\"published\" when=\"2009\">2009</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b32\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Applying artificial intelligence to wearable sensor data to diagnose and predict cardiovascular disease: A review</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J.-D</forename><surname>Huang</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><surname>Wang</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">E</forename><surname>Ramsey</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>Leavey</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">T</forename><forename type=\"middle\">J A</forename><surname>Chico</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">J</forename><surname>Condell</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/s22208002</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Sensors</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">22</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b33\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Smart Wearables for the Detection of Cardiovascular Diseases: A Systematic Literature Review</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Moshawrab</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Adda</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Bouzouane</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><surname>Ibrahim</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Raad</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/s23020828</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Sensors</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">23</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2023\">2023</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b34\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A Systematic Literature Review of Deep and Machine Learning Algorithms in Cardiovascular Diseases Diagnosis</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Z</forename><forename type=\"middle\">K</forename><surname>Alkayyali</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">A B</forename><surname>Idris</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">S</forename><surname>Abu-Naser</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">J. Theor. Appl. Inf. Technol</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">101</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1353\" to=\"1365\" />\n",
      "\t\t\t<date type=\"published\" when=\"2023\">2023</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b35\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Automated diagnosis of cardiovascular diseases from cardiac magnetic resonance imaging using deep learning models: A review</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Jafari</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Shoeibi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Khodatars</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">N</forename><surname>Ghassemi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">P</forename><surname>Moridian</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Alizadehsani</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Khosravi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">H</forename><surname>Ling</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">N</forename><surname>Delfan</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Y.-D</forename><surname>Zhang</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.compbiomed.2023.106998</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Comput. Biol. Med</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">160</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2023\">2023. 106998</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b36\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">A data mining approach for cardiovascular disease diagnosis using heart rate variability and images of carotid arteries</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><surname>Kim</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">I M</forename><surname>Ishag</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Piao</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">T</forename><surname>Kwon</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">K</forename><forename type=\"middle\">H</forename><surname>Ryu</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/sym8060047</idno>\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2016\">2016</date>\n",
      "\t\t\t<biblScope unit=\"volume\">8</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">47</biblScope>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b37\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Cardiovascular disease recognition based on heartbeat segmentation and selection process</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><surname>Boulares</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Alotaibi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Almansour</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Barnawi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/ijerph182010952</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Int. J. Environ. Res. Public Health</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">18</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2021\">2021. 10952</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b38\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Recent developments in modeling, imaging, and monitoring of cardiovascular diseases using machine learning</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">H</forename><surname>Moradi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">A</forename><surname>Al-Hourani</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">G</forename><surname>Concilia</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">F</forename><surname>Khoshmanesh</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">F</forename><forename type=\"middle\">R</forename><surname>Nezami</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Needham</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Baratchi</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">K</forename><surname>Khoshmanesh</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1007/s12551-022-01040-7</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Biophys. Rev</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">15</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"19\" to=\"33\" />\n",
      "\t\t\t<date type=\"published\" when=\"2023\">2023</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b39\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Effective heart disease prediction using machine learning techniques</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">C</forename><forename type=\"middle\">M</forename><surname>Bhatt</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">P</forename><surname>Patel</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">T</forename><surname>Ghetia</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">P</forename><forename type=\"middle\">L</forename><surname>Mazzeo</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/a16020088</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Algorithms</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">16</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2023\">2023</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b40\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">Improvement of the performance of models for predicting coronary artery disease based on XGBoost algorithm and feature processing technology</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Zhang</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Y</forename><surname>Yuan</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Z</forename><surname>Yao</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">X</forename><surname>Wang</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">Z</forename><surname>Lei</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.3390/electronics11030315</idno>\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2022\">2022</date>\n",
      "\t\t\t<biblScope unit=\"volume\">11</biblScope>\n",
      "\t\t\t<biblScope unit=\"page\">315</biblScope>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b41\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">Comparison of machine learning methods for the classification of cardiovascular disease</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">R</forename><surname>Hagan</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">C</forename><forename type=\"middle\">J</forename><surname>Gillan</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">F</forename><surname>Mallett</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<idno type=\"DOI\">10.1016/j.imu.2021.100606</idno>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"j\">Inform. Med. Unlocked</title>\n",
      "\t\t<imprint>\n",
      "\t\t\t<biblScope unit=\"volume\">24</biblScope>\n",
      "\t\t\t<date type=\"published\" when=\"2021\">2021. 100606</date>\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b42\">\n",
      "\t<analytic>\n",
      "\t\t<title level=\"a\" type=\"main\">A Comparison of Neural Networks and Machine Learning Methods for Prediction of Heart Disease</title>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">O</forename><forename type=\"middle\">S</forename><surname>Ghongade</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">K S</forename><surname>Reddy</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Tokala</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">K</forename><surname>Hajarathaiah</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">K</forename><surname>Enduri</surname></persName>\n",
      "\t\t</author>\n",
      "\t\t<author>\n",
      "\t\t\t<persName><forename type=\"first\">S</forename><surname>Anamalamudi</surname></persName>\n",
      "\t\t</author>\n",
      "\t</analytic>\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\">Proceedings of the 2023 3rd International Conference on Intelligent Communication and Computational Techniques (ICCT)</title>\n",
      "\t\t\t\t<meeting>the 2023 3rd International Conference on Intelligent Communication and Computational Techniques (ICCT)<address><addrLine>Jaipur, India</addrLine></address></meeting>\n",
      "\t\t<imprint>\n",
      "\t\t\t<date type=\"published\" when=\"2023-01-20\">19-20 January 2023</date>\n",
      "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"7\" />\n",
      "\t\t</imprint>\n",
      "\t</monogr>\n",
      "</biblStruct>\n",
      "\n",
      "<biblStruct xml:id=\"b43\">\n",
      "\t<monogr>\n",
      "\t\t<title level=\"m\" type=\"main\">Disclaimer/Publisher&apos;s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods</title>\n",
      "\t\t<imprint/>\n",
      "\t</monogr>\n",
      "\t<note>instructions or products referred to in the content</note>\n",
      "</biblStruct>\n",
      "\n",
      "\t\t\t\t</listBibl>\n",
      "\t\t\t</div>\n",
      "\t\t</back>\n",
      "\t</text>\n",
      "</TEI>\n",
      "\n",
      "Heading: Introduction\n",
      "Heading: Related Works\n",
      "Heading: Machine Learning Approach\n",
      "Heading: Deep Learning Approach\n",
      "Heading: Study Dataset Preprocessing and Modeling Results\n",
      "Heading: Discussions on the Research Limitations\n",
      "Heading: Materials and Methods\n",
      "Heading: Datasets\n",
      "Heading: Datasets\n",
      "Heading: cp\n",
      "Heading: trestbps\n",
      "Heading: chol\n",
      "Heading: fbs\n",
      "Heading: restecg\n",
      "Heading: thalach\n",
      "Heading: exang\n",
      "Heading: oldpeak\n",
      "Heading: slope\n",
      "Heading: thal\n",
      "Heading: target\n",
      "Heading: Data Pre-Processing\n",
      "Heading: Model Development\n",
      "Heading: Model Evaluation\n",
      "Heading: Accuracy = (TP + TN)/(TP + FP + TN + FN)\n",
      "Heading: Precision = TP/(TP + FP)\n",
      "Heading: Results\n",
      "Heading: Pre-Processing Results\n",
      "Heading: K-Nearest Neighbors (KNN) Results\n",
      "Heading: K-Nearest Neighbors (KNN) Results\n",
      "Heading: Random Forest Results\n",
      "Heading: Logistic Regression (LR) Results\n",
      "Heading: Gradient Boosting (GB) Results\n",
      "Heading: Support Vector Machine (SVM) Results\n",
      "Heading: Convolutional Neural Network (CNN) Results\n",
      "Heading: XGBoost Results\n",
      "Heading: Discussion\n",
      "Heading: Conclusions and Future Scope\n",
      "Heading: Conclusions and Future Scope\n",
      "\n",
      "## Introduction\n",
      "The heart plays a crucial role in sustaining life by effectively pumping oxygenated blood and regulating important hormones to maintain optimal blood pressure levels. Any deviation from its functioning can lead to the development of heart conditions, collectively known as cardiovascular diseases (CVD). CVD includes a range of disorders that affect both the heart and blood vessels, such as cerebrovascular problems, congenital anomalies, pulmonary embolisms, irregular heart rhythms (arrhythmias), ...\n",
      "\n",
      "## Related Works\n",
      "In this paper, we present a concise technical background and review pertinent literature related to research studies conducted on the early forecast of heart disease utilizing machine learning and deep learning techniques. We highlight the different methods that have been employed in these studies to foretell heart disease at an initial stage....\n",
      "\n",
      "## Machine Learning Approach\n",
      "Machine learning remains a rapidly advancing discipline of computational algorithms that try to imitate human intelligence by learning through data and the surrounding environment. These algorithms play a crucial role in processing and analyzing large-scale data, often referred to as \"big data\". Machine learning techniques have demonstrated their effectiveness in various domains, including pattern recognition, computer vision, spacecraft engineering, as well as biomedical and medical application...\n",
      "\n",
      "## Deep Learning Approach\n",
      "In recent years, there has been remarkable progress in the field of deep learning, with a primary focus on developing intelligent automated systems that aid doctors in predicting and diagnosing diseases through the utilization of the Internet of Things (IoT). While conventional machine learning techniques were often restricted by their dependency on single datasets, the advent of deep learning has brought significant enhancements to the accuracy of existing algorithms. Deep learning leverages ar...\n",
      "\n",
      "## Study Dataset Preprocessing and Modeling Results\n",
      "Algarni et al.  [27]  Coronary artery X-ray angiography images obtained from a clinical database. Training: 100 images Test: 30 images ASCARIS model (based on color, diameter, and shape features). Accuracy: 97% Uyar and ˙Ilhan  [30]  Cleveland dataset for heart disease. Removal of 6 instances with missing entries from the dataset and categorization of the diagnosis attribute (num) into two classes: absence (num = 0) and presence (num = 1, 2, 3, or 4) of heart disease. ...\n",
      "\n",
      "## Discussions on the Research Limitations\n",
      "The literature review involved an in-depth exploration of the existing research and knowledge pertaining to heart disease prediction using diverse machine learning and deep learning techniques. Several studies reviewed the recent advancements and limitations of applying machine learning for cardiovascular disease detection  [10, [33] [34] [35] [36] . For instance, the studies [8,  [37] [38] [39] [40]  proposed different data mining and machine learning methods based on heartbeat segmentation and...\n",
      "\n",
      "## Materials and Methods\n",
      "The following methods are adapted to achieve the goals of this research. They are applied to explore and comprehend various dimensions of heart-related conditions, ultimately contributing to the creation of precise models for the diagnosis and prediction of these conditions. The general research method framework of this study is shown in Figure  1 . The following methods are adapted to achieve the goals of this research. They are applied to explore and comprehend various dimensions of heart-rela...\n",
      "\n",
      "## Datasets\n",
      "To carry out this research study, two datasets were examined, namely the Cardiovascular Heart Disease Dataset, which was retrieved from the Mendeley database, and the Heart Disease Cleveland Dataset, which was retrieved from the Kaggle database. The \"Cardio\" and \"Target\" columns on both datasets refer to the column we are trying to predict with numeric values 0 (no disease) and 1 (disease). It is important to note that neither dataset has any missing values. The detailed descriptions of all thes...\n",
      "\n",
      "## Datasets\n",
      "To carry out this research study, two datasets were examined, namely the Cardiovascular Heart Disease Dataset, which was retrieved from the Mendeley database, and the Heart Disease Cleveland Dataset, which was retrieved from the Kaggle database. The \"Cardio\" and \"Target\" columns on both datasets refer to the column we are trying to predict with numeric values 0 (no disease) and 1 (disease). It is important to note that neither dataset has any missing values. The detailed descriptions of all thes...\n",
      "\n",
      "## cp\n",
      "Categorical attribute indicating the various types of chest pain felt by the patient. 0 for typical angina, 1 for atypical angina, 2 for non-anginal pain, and 3 for asymptomatic....\n",
      "\n",
      "## trestbps\n",
      "Numerical measurement of the patient's blood pressure at rest, recorded in mm/HG....\n",
      "\n",
      "## chol\n",
      "Numeric value indicating the serum cholesterol intensity of the patient, calculated in mg/dL....\n",
      "\n",
      "## fbs\n",
      "Categorical representation of fasting blood sugar levels, with 1 signifying levels above 120 mg/dL and 0 indicating levels below....\n",
      "\n",
      "## restecg\n",
      "Categorical feature describing the result of the electrocardiogram conducted at rest. 0 for normal, 1 for ST-T wave abnormalities, and 2 for indications of probable or definite left ventricular hypertrophy according to Estes' criteria....\n",
      "\n",
      "## thalach\n",
      "Numeric representation of the heart rate realized by the patient....\n",
      "\n",
      "## exang\n",
      "Categorical feature denoting whether exercise-induced angina is present. 0 signifies no, while 1 signifies yes....\n",
      "\n",
      "## oldpeak\n",
      "Numeric value indicating exercise-induced ST-depression relative to the rest state....\n",
      "\n",
      "## slope\n",
      "Categorical attribute representing the slope of the ST segment during peak exercise. It can take three values: 0 for up-sloping, 1 for flat, and 2 for down-sloping. 12. ca Categorical feature indicating the number of major blood vessels, ranging from 0 to 3....\n",
      "\n",
      "## thal\n",
      "Categorical representation of a blood disorder called thalassemia. 0 for NULL, 1 for normal blood flow, 2 for fixed defects (indicating no blood flow in a portion of the heart), and 3 for reversible defects (indicating abnormal but observable blood flow)....\n",
      "\n",
      "## target\n",
      "The target variable to predict heart disease, encoded as 1 for patients with heart disease and 0 for patients without heart disease....\n",
      "\n",
      "## Data Pre-Processing\n",
      "Data preprocessing is an essential step within machine learning that aims to improve dataset quality and reliability before analysis and modeling. This phase tackles challenges such as missing data, inconsistencies, outliers, and skewed class distributions. Addressing missing values is crucial to ensure accurate insights by utilizing techniques such as imputation. Detecting and managing outliers is also vital, as these data points can skew results. A key concern is class distribution balance, wh...\n",
      "\n",
      "## Model Development\n",
      "The conclusion of the thorough literature work brings us to the pivotal stage of model development. This section encompasses seven notable machine learning techniques: Logistic Regression, Convolutional Neural Network, Support Vector Machine (SVM), Gradient Boosting, K-Nearest Neighbors (KNN), XGBoost, and Random Forest. Each algorithm contributes distinct characteristics to unveil predictive revelations in the analysis of cardiovascular and cerebrovascular diseases, utilizing resources such as ...\n",
      "\n",
      "## Model Evaluation\n",
      "Model Evaluation stands as a pivotal phase in the realm of machine learning, dedicated to thoroughly gauging how well-trained models predict outcomes. This essential step ensures that models can generalize to new data effectively, informing decisions about deployment and refinement. The following key techniques and metrics will contribute to a comprehensive evaluation of this study: Confusion Matrix: Offering insight into true positives, true negatives, false positives, and false negatives, this...\n",
      "\n",
      "## Accuracy = (TP + TN)/(TP + FP + TN + FN)\n",
      "( Precision and Recall: Precision assesses positive prediction accuracy, while recall gauges the model's ability to capture positive instances....\n",
      "\n",
      "## Precision = TP/(TP + FP)\n",
      "( Recall = TP/(TP + FN) F1-Score: Striking a balance between precision and recall, this score is essential for harmonizing performance aspects. F1 = (2 × precision × recall)/(precision + recall) Cross-Validation: This technique partitions data for training and testing, guarding against overfitting. Hyperparameter Tuning: Optimizing model parameters through techniques like GridSearch enhances performance....\n",
      "\n",
      "## Results\n",
      "This section explores the detailed analysis of machine learning models for heart disease prediction, leveraging two distinct datasets: the Cardiovascular Heart Disease Dataset and the Heart Disease Cleveland Dataset using the Python programming language. Our primary objective is to identify the most effective predictive models, considering both traditional tabular datasets while keeping in mind the aims of the study....\n",
      "\n",
      "## Pre-Processing Results\n",
      "To harness the potential of the Cardiovascular Heart Disease Dataset and the Heart Disease Cleveland Dataset for machine learning applications, it becomes imperative to execute preliminary data preprocessing procedures. These procedures encompass a range of actions, including managing missing data, encoding categorical variables, standardizing or normalizing feature values, and partitioning the dataset into distinct training and testing subsets. Additionally, the utilization of exploratory data ...\n",
      "\n",
      "## K-Nearest Neighbors (KNN) Results\n",
      "We commenced the analysis by employing the K-Nearest Neighbors (KNN) algorithm with varying 'k' values, representing the number of nearest neighbors considered during the predictions. Employing cross-validation, we computed scores for each 'k' value, ultimately discerning that 'k = 7′ yielded the most favorable mean cross-validation score. This outcome underscores that configuring KNN with 'k = 7′ exhibits significant promise. As shown in Tables  5-8 , the implementation of this model yielded an...\n",
      "\n",
      "## K-Nearest Neighbors (KNN) Results\n",
      "We commenced the analysis by employing the K-Nearest Neighbors (KNN) algorithm with varying 'k' values, representing the number of nearest neighbors considered during the predictions. Employing cross-validation, we computed scores for each 'k' value, ultimately discerning that 'k = 7' yielded the most favorable mean cross-validation score. This outcome underscores that configuring KNN with 'k = 7' exhibits significant promise. As shown in Tables  5-8 , the implementation of this model yielded an...\n",
      "\n",
      "## Random Forest Results\n",
      "By conducting an extensive hyperparameter tuning process, we modified the number of trees (n_estimators) to 200 within the Random Forest ensemble model. As shown in Tables 5-8, the tuned model achieved an outstanding accuracy level, hovering at around 98.60% and 91.09%. The assessment of precision showed a significant enhancement, which obtained 98.63% and 94.44%. Similarly, the F1 Score, which amalgamates precision and recall, demonstrated the model's robustness, registering a value of 98.80% a...\n",
      "\n",
      "## Logistic Regression (LR) Results\n",
      "By implementing a custom threshold of 0.6, the model was configured to adopt a cautious approach when classifying instances as positive. To be specific, if the predicted probability of an instance belonging to the positive class (class 1) equaled or exceeded 0.6, it was categorized as positive; otherwise, it was designated as negative. This threshold selection significantly influenced how the model struck a balance between precision and recall. As shown in Tables  5-8 , the model's precision sco...\n",
      "\n",
      "## Gradient Boosting (GB) Results\n",
      "Through the GridSearchCV process, we effectively fine-tuned the model's hyperparameters. The optimal hyperparameters selected encompassed a learning rate of 0.2, a maximum depth of 3 for individual trees, and 100 boosting stages (n_estimators). These hyperparameters were chosen based on their exceptional performance on the validation datasets. When tested on independent data, the refined Gradient Boosting model consistently delivered exceptional results. As shown in Tables  5-8 , it attained an ...\n",
      "\n",
      "## Support Vector Machine (SVM) Results\n",
      "The process of tuning hyperparameters, carried out through GridSearchCV, effectively determined the most suitable hyperparameter configuration for the SVM model. This configuration included a regularization parameter (C) set to 10, a polynomial kernel with a degree of 2, and the utilization of a linear kernel. As shown in Tables  5-8 , for post-tuning, the model achieved a precision score of 95.00% and 80.65%, a recall score of 97.44% and 78.12%, and an F1 Score of 96.20% and 79.37%. On the test...\n",
      "\n",
      "## Convolutional Neural Network (CNN) Results\n",
      "The model architecture consists of three layers: an initial layer with 128 units employing the ReLU activation function, followed by a hidden layer featuring 64 units with ReLU activation, and ultimately, an output layer utilizing the sigmoid activation function. During model compilation, the Adam optimizer was employed alongside binary cross-entropy loss, with accuracy serving as the evaluation metric. To mitigate the risk of overfitting, a precautionary measure known as early stopping was inte...\n",
      "\n",
      "## XGBoost Results\n",
      "Through the utilization of GridSearchCV, a highly effective process of hyperparameter tuning was carried out. This process led to the discovery of optimal hyperparameters for the XGBoost model, which included a learning rate of 0.2, a maximum tree depth of 3, 100 boosting rounds (n_estimators), and a subsample fraction of 1.0. The recall of these chosen hyperparameters was substantiated by a remarkable validation score of approximately 98.00% on the Cardiovascular Heart Disease Dataset and 84% o...\n",
      "\n",
      "## Discussion\n",
      "The experimental results are shown in Tables 5-8 and Figure  5 . The thorough assessment of machine learning models, specifically the XGBoost and K-Nearest Neighbors models, in the context of heart disease prediction, provides valuable insights. These insights align with the research conducted by Zhang et al.  [41] , which underscores the effectiveness of the XGBoost algorithm in this specific domain.  ...\n",
      "\n",
      "## Conclusions and Future Scope\n",
      "As we discussed the broader scope of model selection and its implications for heart disease prediction, the conducted analysis has unearthed invaluable insights. Among the array of models under scrutiny, K-Nearest Neighbors and XGBoost have consistently risen to prominence as top-performing candidates across both datasets, as shown below. These models have exhibited remarkable accuracy and recall scores, rendering them robust contenders for the precise classification of heart disease. It is note...\n",
      "\n",
      "## Conclusions and Future Scope\n",
      "As we discussed the broader scope of model selection and its implications for heart disease prediction, the conducted analysis has unearthed invaluable insights. Among the array of models under scrutiny, K-Nearest Neighbors and XGBoost have consistently risen to prominence as top-performing candidates across both datasets, as shown below. These models have exhibited remarkable accuracy and recall scores, rendering them robust contenders for the precise classification of heart disease. It is note...\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "pdf_path = \"papers\\ml_model_cardio_disease_detection.pdf\"\n",
    "url = \"http://localhost:8070/api/processFulltextDocument\"\n",
    "\n",
    "with open(pdf_path, 'rb') as pdf_file:\n",
    "    response = requests.post(url, files={'input': pdf_file})\n",
    "    \n",
    "xml_output = response.text\n",
    "print(xml_output)\n",
    "root = etree.fromstring(xml_output.encode('utf-8'))\n",
    "sections = []\n",
    "\n",
    "for div in root.findall('.//{*}body/{*}div'):\n",
    "    heading = div.findtext('{*}head')\n",
    "    print(f\"Heading: {heading}\")\n",
    "    text_parts = [t for t in div.itertext() if t.strip() != heading]\n",
    "    text = \" \".join(text_parts)\n",
    "    if heading and text: \n",
    "        sections.append({\n",
    "            \"heading\": heading,\n",
    "            \"content\": text\n",
    "        })\n",
    "\n",
    "for s in sections:\n",
    "    print(f\"\\n## {s['heading']}\\n{s['content'][:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd75118a",
   "metadata": {},
   "source": [
    "# GROBID + Hybrid RAG + Sectioned Summariser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea81104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "from tiktoken import get_encoding\n",
    "\n",
    "# langchain / ollama imports\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# --------------------------\n",
    "# Configuration\n",
    "# --------------------------\n",
    "PDF_PATH = \"papers/hospital_bed_capacity_planning.pdf\"  # change path\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "EMBEDDING_MODEL_NAME = \"nomic-embed-text\"  # adjust if different on your Ollama\n",
    "LLM_MODEL_NAME = \"llama3.1:latest\"           # your Qwen model in Ollama\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Chunking / retrieval hyperparams tuned for Qwen-32B\n",
    "CHUNK_SIZE = 512      # tokens per chunk (reduced for embedding model compatibility)\n",
    "CHUNK_OVERLAP = 50\n",
    "TOP_K = 4             # number of chunks to retrieve for each section\n",
    "RERANK_WITH_LLM = True  # set True to use LLM-based reranker (more precise, more compute)\n",
    "\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# --------------------------\n",
    "# Initialize Ollama clients (LangChain wrappers)\n",
    "# --------------------------\n",
    "print(\"Initializing Ollama embeddings and LLM wrappers...\")\n",
    "embedding_model = OllamaEmbeddings(model=EMBEDDING_MODEL_NAME, base_url=OLLAMA_BASE_URL)\n",
    "llm = ChatOllama(model=LLM_MODEL_NAME, temperature=0.05, base_url=OLLAMA_BASE_URL, device=DEVICE)\n",
    "print(\"Done.\\n\")\n",
    "\n",
    "# --------------------------\n",
    "# Utility: Load & chunk PDF (page-aware)\n",
    "# --------------------------\n",
    "def load_and_chunk_pdf(pdf_path, chunk_size=CHUNK_SIZE, overlap=CHUNK_OVERLAP):\n",
    "    print(f\"Loading PDF: {pdf_path}\")\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()  # list of Page objects with .page_content\n",
    "    page_texts = [p.page_content for p in pages[:-3]]\n",
    "    print(f\"Total pages loaded: {len(page_texts)}\")\n",
    "\n",
    "    # Join with page separators to keep page breaks\n",
    "    full_text_with_pages = \"\\n\\n[PAGEREF]\\n\\n\".join(page_texts)\n",
    "\n",
    "    enc = get_encoding(\"cl100k_base\")\n",
    "    tokens = enc.encode(full_text_with_pages)\n",
    "    print(f\"Total tokens in PDF (approx): {len(tokens)}\")\n",
    "\n",
    "    # create token-wise chunks, but also record which page ranges each chunk covers\n",
    "    chunks = []\n",
    "    token_to_page = []  # map every token index to page index for biasing\n",
    "    # build token->page mapping by encoding each page separately\n",
    "    page_token_counts = [len(enc.encode(t)) for t in page_texts]\n",
    "    page_start = 0\n",
    "    page_token_starts = []\n",
    "    for cnt in page_token_counts:\n",
    "        page_token_starts.append(page_start)\n",
    "        page_start += cnt\n",
    "\n",
    "    # make chunks using token slices of the full_text (encode/decode)\n",
    "    for i in range(0, len(tokens), chunk_size - overlap):\n",
    "        t_slice = tokens[i:i + chunk_size]\n",
    "        chunk_text = enc.decode(t_slice)\n",
    "        # estimate page span by finding nearest page start\n",
    "        # find first token index's page\n",
    "        start_page = None\n",
    "        end_page = None\n",
    "        # find which page contains token index i and i+len-1 approximate\n",
    "        # naive approach: compare against page_token_starts cumulative\n",
    "        for pi, start_idx in enumerate(page_token_starts):\n",
    "            if i >= start_idx:\n",
    "                start_page = pi\n",
    "            else:\n",
    "                break\n",
    "        # end page\n",
    "        j = i + len(t_slice) - 1\n",
    "        end_page = start_page\n",
    "        for pi, start_idx in enumerate(page_token_starts[start_page:], start=start_page):\n",
    "            if j >= start_idx:\n",
    "                end_page = pi\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        chunks.append({\n",
    "            \"text\": chunk_text,\n",
    "            \"start_token\": i,\n",
    "            \"token_len\": len(t_slice),\n",
    "            \"start_page\": start_page,\n",
    "            \"end_page\": end_page\n",
    "        })\n",
    "\n",
    "    print(f\"Created {len(chunks)} chunks (chunk_size={chunk_size}, overlap={overlap})\")\n",
    "    return chunks\n",
    "\n",
    "# --------------------------\n",
    "# Build FAISS index using Ollama embeddings\n",
    "# --------------------------\n",
    "def build_faiss_index(chunks, embedding_model):\n",
    "    print(\"Embedding chunks with Ollama embeddings (this may take a while)...\")\n",
    "    vectors = []\n",
    "    for i, c in enumerate(chunks):\n",
    "        emb = embedding_model.embed_query(c[\"text\"])\n",
    "        # ensure vector is a list of floats\n",
    "        vec = np.array(emb, dtype=np.float32)\n",
    "        vectors.append(vec)\n",
    "        if (i + 1) % 20 == 0 or (i + 1) == len(chunks):\n",
    "            print(f\"  ▸ Embedded {i+1}/{len(chunks)} chunks\")\n",
    "\n",
    "    embeddings_array = np.vstack(vectors).astype(\"float32\")\n",
    "    d = embeddings_array.shape[1]\n",
    "    print(f\"Embedding dimension: {d}\")\n",
    "\n",
    "    # create FAISS index (simple FlatL2 index - replace with IndexIVFFlat for large corpora)\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(embeddings_array)\n",
    "    print(f\"FAISS index built. Total vectors in index: {index.ntotal}\")\n",
    "    return index, embeddings_array\n",
    "\n",
    "# --------------------------\n",
    "# Retrieval with optional position bias & reranking\n",
    "# --------------------------\n",
    "def retrieve_chunks_for_query(query, index, chunks, embedding_model, top_k=TOP_K, position_bias=True):\n",
    "    q_emb = np.array([embedding_model.embed_query(query)], dtype=\"float32\")\n",
    "    # search larger set then filter/rerank if needed\n",
    "    search_k = max(top_k * 3, top_k + 5)\n",
    "    distances, indices = index.search(q_emb, search_k)\n",
    "    indices = indices[0].tolist()\n",
    "    distances = distances[0].tolist()\n",
    "\n",
    "    # Build candidates with metadata\n",
    "    candidates = []\n",
    "    for idx, dist in zip(indices, distances):\n",
    "        if idx < 0 or idx >= len(chunks):\n",
    "            continue\n",
    "        c = chunks[idx]\n",
    "        candidates.append({\n",
    "            \"idx\": idx,\n",
    "            \"dist\": float(dist),\n",
    "            \"start_page\": c[\"start_page\"],\n",
    "            \"end_page\": c[\"end_page\"],\n",
    "            \"text\": c[\"text\"]\n",
    "        })\n",
    "\n",
    "    # apply position bias: prefer earlier pages for queries like \"problem statement\" or \"abstract\"\n",
    "    if position_bias:\n",
    "        def score_with_bias(item):\n",
    "            # bias factor: earlier pages get lower score (better)\n",
    "            page_bias = (item[\"start_page\"] or 0) * 0.03\n",
    "            return item[\"dist\"] + page_bias\n",
    "        candidates = sorted(candidates, key=score_with_bias)\n",
    "    else:\n",
    "        candidates = sorted(candidates, key=lambda x: x[\"dist\"])\n",
    "\n",
    "    # trim to top_k final\n",
    "    final = candidates[:top_k]\n",
    "    # debug info\n",
    "    print(\"Retrieved (idx, pages):\", [(c[\"idx\"], (c[\"start_page\"], c[\"end_page\"])) for c in final])\n",
    "    return final\n",
    "\n",
    "# Optional LLM-based reranker to improve precision (reranks the candidate texts by asking LLM a short question)\n",
    "def rerank_with_llm(query, candidates, llm, rerank_k=TOP_K):\n",
    "    # prepare a short prompt asking the LLM to score relevance (1-10)\n",
    "    prompt_template = \"\"\"You are a helpful research assistant. Given the question: \"{query}\"\n",
    "For each candidate passage, give a relevance score between 1 (irrelevant) and 10 (directly answers the question).\n",
    "Return lines in the format: score<TAB>passage_index\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Candidates:\n",
    "{listings}\n",
    "\n",
    "Provide only the scored lines.\n",
    "\"\"\"\n",
    "    listings = \"\\n\\n\".join([f\"[{i}] {c['text'][:400].replace('\\\\n',' ')}\" for i, c in enumerate(candidates)])\n",
    "    prompt = prompt_template.format(query=query, listings=listings)\n",
    "    # call LLM to score (small response)\n",
    "    response = llm.invoke(prompt)\n",
    "    text = response if isinstance(response, str) else (response.content if hasattr(response, \"content\") else str(response))\n",
    "    # parse lines\n",
    "    scores = []\n",
    "    for line in text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        # naive parse: first token is score, last token contains [i]\n",
    "        try:\n",
    "            score = float(parts[0])\n",
    "            # find passage index between brackets\n",
    "            idx_token = [p for p in parts if p.startswith(\"[\") and p.endswith(\"]\")]\n",
    "            if idx_token:\n",
    "                pid = int(idx_token[0].strip(\"[]\"))\n",
    "                scores.append((pid, score))\n",
    "        except Exception:\n",
    "            continue\n",
    "    # map back to candidates and sort by score desc\n",
    "    scored = []\n",
    "    for pid, sc in scores:\n",
    "        if 0 <= pid < len(candidates):\n",
    "            scored.append((candidates[pid], sc))\n",
    "    if not scored:\n",
    "        # fallback: return original candidates\n",
    "        return candidates[:rerank_k]\n",
    "    scored_sorted = sorted(scored, key=lambda x: -x[1])\n",
    "    reranked = [item for item, s in scored_sorted][:rerank_k]\n",
    "    # return reranked list\n",
    "    return reranked\n",
    "\n",
    "# --------------------------\n",
    "# Section prompts & summarization\n",
    "# --------------------------\n",
    "SECTION_QUERIES = {\n",
    "    \"Title & Authors\": \"What is the title and who are the authors of the paper? Provide year if present.\",\n",
    "    \"Problem Statement\": \"What research problem or objective does this paper address? Summarize briefly (1-2 sentences).\",\n",
    "    \"Dataset\": \"Which datasets were used in the experiments? Provide names, sizes, sources if available.\",\n",
    "    \"Methodology\": \"Describe the model architecture or methods proposed in the paper. Include algorithm names or key components.\",\n",
    "    \"Evaluation & Metrics\": \"What evaluation metrics and experimental results are reported? Provide numeric values when present.\",\n",
    "    \"Limitations\": \"What limitations or weaknesses do the authors mention?\",\n",
    "    \"Future Work\": \"What future work or extensions do the authors propose?\"\n",
    "}\n",
    "\n",
    "SECTION_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert AI research assistant. Create a concise academic-style summary for the section: \"{section_name}\".\n",
    "\n",
    "Context (retrieved passages):\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "- Extract facts from the context only (do not hallucinate).\n",
    "- If you cannot find explicit info, say \"Not stated in retrieved passages\".\n",
    "- Be concise and include numeric metrics where possible.\n",
    "\"\"\"\n",
    "\n",
    "section_prompt = PromptTemplate.from_template(SECTION_PROMPT_TEMPLATE)\n",
    "section_chain = section_prompt | llm | StrOutputParser()\n",
    "\n",
    "def summarize_section(section_name, query, index, chunks, embedding_model, llm, top_k=TOP_K, rerank=RERANK_WITH_LLM):\n",
    "    print(f\"\\n--- Section: {section_name} ---\")\n",
    "    candidates = retrieve_chunks_for_query(query, index, chunks, embedding_model, top_k=top_k, position_bias=True)\n",
    "    # prepare contexts\n",
    "    if rerank:\n",
    "        reranked = rerank_with_llm(query, candidates, llm, rerank_k=top_k)\n",
    "        candidates = reranked\n",
    "        print(\"After rerank (idx, pages):\", [(c[\"idx\"], (c[\"start_page\"], c[\"end_page\"])) for c in candidates])\n",
    "    context = \"\\n\\n\".join([c[\"text\"] for c in candidates])\n",
    "    # debug: show snippet of retrieved context\n",
    "    for c in candidates:\n",
    "        print(f\"  -> idx {c['idx']} pages {c['start_page']}-{c['end_page']} (preview): {c['text'][:200]!r}\")\n",
    "    # call LLM summarizer for this section\n",
    "    out = section_chain.invoke({\"section_name\": section_name, \"context\": context})\n",
    "    print(f\"Section summary preview: {out[:300]}...\\n\")\n",
    "    return out\n",
    "\n",
    "# --------------------------\n",
    "# Combine section summaries & final polish\n",
    "# --------------------------\n",
    "FINAL_COMBINE_PROMPT = \"\"\"\n",
    "You are an expert AI research assistant. Combine the following section-level summaries into one coherent and well-structured paper summary.\n",
    "Keep the headings and produce a short global conclusion (2-3 sentences) at the end.\n",
    "\n",
    "Section summaries:\n",
    "{sections_text}\n",
    "\n",
    "Combine and output as a clean, academic-style summary.\n",
    "\"\"\"\n",
    "\n",
    "final_prompt = PromptTemplate.from_template(FINAL_COMBINE_PROMPT)\n",
    "final_chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "def combine_and_refine(section_summaries: dict):\n",
    "    sections_text = \"\\n\\n\".join([f\"## {k}\\n{v}\" for k, v in section_summaries.items()])\n",
    "    combined = final_chain.invoke({\"sections_text\": sections_text})\n",
    "    return combined\n",
    "\n",
    "# --------------------------\n",
    "# Full pipeline runner\n",
    "# --------------------------\n",
    "def run_full_pipeline(pdf_path):\n",
    "    # 1) Load & chunk\n",
    "    chunks = load_and_chunk_pdf(pdf_path)\n",
    "    # 2) Build embeddings index\n",
    "    index, embeddings_array = build_faiss_index(chunks, embedding_model)\n",
    "    # 3) For each section: retrieve, rerank, summarize\n",
    "    section_summaries = {}\n",
    "    for sname, sq in SECTION_QUERIES.items():\n",
    "        summary = summarize_section(sname, sq, index, chunks, embedding_model, llm, top_k=TOP_K, rerank=RERANK_WITH_LLM)\n",
    "        section_summaries[sname] = summary\n",
    "\n",
    "    # 4) Combine & final polish\n",
    "    final_summary = combine_and_refine(section_summaries)\n",
    "    return {\n",
    "        \"sections\": section_summaries,\n",
    "        \"final_summary\": final_summary,\n",
    "        \"chunks\": chunks,\n",
    "        \"index\": index\n",
    "    }\n",
    "\n",
    "# --------------------------\n",
    "# Example usage\n",
    "# --------------------------\n",
    "\n",
    "start = time.time()\n",
    "out = run_full_pipeline(PDF_PATH)\n",
    "elapsed = time.time() - start\n",
    "print(\"\\n\\n==== FINAL SUMMARY (first 1500 chars) ====\\n\")\n",
    "print(out[\"final_summary\"][:1500] + \"...\\n\")\n",
    "print(f\"\\nPipeline completed in {elapsed:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d3b5b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "Initializing Ollama embeddings and LLM wrappers...\n",
      "Done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 20 sections from GROBID\n",
      "Embedding sections...\n",
      "FAISS index built with 20 vectors (dimension 768)\n",
      "\n",
      "--- Section: Title & Authors ---\n",
      "\n",
      "--- Section: Problem Statement ---\n",
      "\n",
      "--- Section: Dataset ---\n",
      "\n",
      "--- Section: Methodology ---\n",
      "\n",
      "--- Section: Evaluation & Metrics ---\n",
      "\n",
      "--- Section: Limitations ---\n",
      "\n",
      "--- Section: Future Work ---\n",
      "\n",
      "\n",
      "==== FINAL SUMMARY (first 1500 chars) ===\n",
      "\n",
      "**Title:** Optimizing Hospital Bed Capacity Forecasting: A Machine Learning Approach\n",
      "**Authors:** Not stated in retrieved passages\n",
      "\n",
      "**Abstract:**\n",
      "\n",
      "This study aims to optimize hospital bed capacity forecasting using machine learning algorithms. The problem statement revolves around optimizing the Length of Stay (LOS) classification for patients in a Heart ward, highlighting issues such as inefficient use of bed capacity during holidays, high proportion of children requiring long LOS, and insufficient bed capacity. A dataset containing 51,231 records collected between 2011 and 2018 was used to examine LOS classification accuracy using various tools, with Support Vector Machine (SVM) providing the best accuracy.\n",
      "\n",
      "The study employed a classification approach to predict LOS using machine learning algorithms, including Bayesian Network (BN), K-Nearest Neighbor (KNN), SVM, Decision Tree (DT), and Logistic Regression (LR). The results show that only 6% of patients experienced LOS for more than 15 days, with most patients staying in the Heart ward for only one day. The study also identified several limitations, including neglecting other essential resources such as Specialists, Nurses, Equipment, and Budget, and not considering various external factors that may impact the hospital's Net Hospital Product (NHP) in the future.\n",
      "\n",
      "**Introduction:**\n",
      "\n",
      "Hospital bed capacity forecasting is a critical task for healthcare administrators to ensure efficient use of hospital resources and provide hi...\n",
      "\n",
      "\n",
      "Pipeline completed in 739.37 seconds.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "import requests\n",
    "from lxml import etree\n",
    "from tiktoken import get_encoding\n",
    "\n",
    "# LangChain / Ollama imports\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# --------------------------\n",
    "# Configuration\n",
    "# --------------------------\n",
    "PDF_PATH = \"papers/hospital_bed_capacity_planning.pdf\"  # adjust path\n",
    "GROBID_URL = \"http://localhost:8070/api/processFulltextDocument\"\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "EMBEDDING_MODEL_NAME = \"nomic-embed-text\"\n",
    "LLM_MODEL_NAME = \"llama3.1:latest\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "TOP_K = 4  # top sections to retrieve per query\n",
    "RERANK_WITH_LLM = True\n",
    "\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# --------------------------\n",
    "# Initialize Ollama clients\n",
    "# --------------------------\n",
    "print(\"Initializing Ollama embeddings and LLM wrappers...\")\n",
    "embedding_model = OllamaEmbeddings(model=EMBEDDING_MODEL_NAME, base_url=OLLAMA_BASE_URL)\n",
    "llm = ChatOllama(model=LLM_MODEL_NAME, temperature=0.05, base_url=OLLAMA_BASE_URL, device=DEVICE)\n",
    "print(\"Done.\\n\")\n",
    "\n",
    "# --------------------------\n",
    "# GROBID section extraction\n",
    "# --------------------------\n",
    "def parse_div(div):\n",
    "    \"\"\"Recursive parsing of TEI <div> elements. Includes heading in content.\"\"\"\n",
    "    heading = div.findtext('{*}head')\n",
    "    content = \" \".join(list(div.itertext())).strip()\n",
    "    subsections = [parse_div(d) for d in div.findall('{*}div')]\n",
    "    return {\n",
    "        \"heading\": heading.strip() if heading else None,\n",
    "        \"content\": content,\n",
    "        \"subsections\": subsections\n",
    "    }\n",
    "\n",
    "def extract_sections_from_grobid(xml_text):\n",
    "    root = etree.fromstring(xml_text.encode(\"utf-8\"))\n",
    "    body = root.find('.//{*}body')\n",
    "    if body is None:\n",
    "        raise ValueError(\"No <body> element found in TEI XML\")\n",
    "    sections = [parse_div(d) for d in body.findall('{*}div')]\n",
    "    return sections\n",
    "\n",
    "def flatten_sections(sections):\n",
    "    \"\"\"Flatten nested sections into a list.\"\"\"\n",
    "    flat = []\n",
    "    for s in sections:\n",
    "        flat.append({\"heading\": s[\"heading\"], \"content\": s[\"content\"]})\n",
    "        flat.extend(flatten_sections(s[\"subsections\"]))\n",
    "    return flat\n",
    "\n",
    "def load_pdf_sections_via_grobid(pdf_path, grobid_client_url=GROBID_URL):\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        resp = requests.post(grobid_client_url, files={\"input\": f})\n",
    "    xml_text = resp.text\n",
    "    sections = extract_sections_from_grobid(xml_text)\n",
    "    flat_sections = flatten_sections(sections)\n",
    "    # Filter empty content\n",
    "    flat_sections = [s for s in flat_sections if s[\"content\"].strip()]\n",
    "    print(f\"Extracted {len(flat_sections)} sections from GROBID\")\n",
    "    return flat_sections\n",
    "\n",
    "# --------------------------\n",
    "# Build FAISS index for sections\n",
    "# --------------------------\n",
    "def build_section_index(sections, embedding_model):\n",
    "    print(\"Embedding sections...\")\n",
    "    vectors = []\n",
    "    for i, s in enumerate(sections):\n",
    "        emb = np.array(embedding_model.embed_query(s[\"content\"]), dtype=np.float32)\n",
    "        vectors.append(emb)\n",
    "    embeddings_array = np.vstack(vectors).astype(\"float32\")\n",
    "    d = embeddings_array.shape[1]\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(embeddings_array)\n",
    "    print(f\"FAISS index built with {index.ntotal} vectors (dimension {d})\")\n",
    "    return index, embeddings_array\n",
    "\n",
    "# --------------------------\n",
    "# Retrieval\n",
    "# --------------------------\n",
    "def retrieve_sections_for_query(query, index, sections, embedding_model, top_k=TOP_K):\n",
    "    q_emb = np.array([embedding_model.embed_query(query)], dtype=np.float32)\n",
    "    distances, indices = index.search(q_emb, top_k)\n",
    "    retrieved = []\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        retrieved.append({\n",
    "            \"idx\": idx,\n",
    "            \"text\": sections[idx][\"content\"],\n",
    "            \"heading\": sections[idx][\"heading\"]\n",
    "        })\n",
    "    return retrieved\n",
    "\n",
    "# Optional LLM reranker\n",
    "def rerank_with_llm(query, candidates, llm, rerank_k=TOP_K):\n",
    "    prompt_template = \"\"\"You are a helpful research assistant. Given the question: \"{query}\"\n",
    "For each candidate passage, give a relevance score between 1 (irrelevant) and 10 (directly answers the question).\n",
    "Return lines in the format: score<TAB>passage_index\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Candidates:\n",
    "{listings}\n",
    "\n",
    "Provide only the scored lines.\n",
    "\"\"\"\n",
    "    listings = \"\\n\\n\".join([f\"[{i}] {c['text'][:400].replace('\\\\n',' ')}\" for i, c in enumerate(candidates)])\n",
    "    prompt = prompt_template.format(query=query, listings=listings)\n",
    "    response = llm.invoke(prompt)\n",
    "    text = response if isinstance(response, str) else (response.content if hasattr(response, \"content\") else str(response))\n",
    "    scores = []\n",
    "    for line in text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        try:\n",
    "            score = float(parts[0])\n",
    "            idx_token = [p for p in parts if p.startswith(\"[\") and p.endswith(\"]\")]\n",
    "            if idx_token:\n",
    "                pid = int(idx_token[0].strip(\"[]\"))\n",
    "                scores.append((pid, score))\n",
    "        except Exception:\n",
    "            continue\n",
    "    scored = [(candidates[pid], s) for pid, s in scores if 0 <= pid < len(candidates)]\n",
    "    if not scored:\n",
    "        return candidates[:rerank_k]\n",
    "    scored_sorted = sorted(scored, key=lambda x: -x[1])\n",
    "    return [item for item, s in scored_sorted][:rerank_k]\n",
    "\n",
    "# --------------------------\n",
    "# Section prompts & summarization\n",
    "# --------------------------\n",
    "SECTION_QUERIES = {\n",
    "    \"Title & Authors\": \"What is the title and who are the authors of the paper? Provide year if present.\",\n",
    "    \"Problem Statement\": \"What research problem or objective does this paper address? Summarize briefly (1-2 sentences).\",\n",
    "    \"Dataset\": \"Which datasets were used in the experiments? Provide names, sizes, sources if available.\",\n",
    "    \"Methodology\": \"Describe the model architecture or methods proposed in the paper. Include algorithm names or key components.\",\n",
    "    \"Evaluation & Metrics\": \"What evaluation metrics and experimental results are reported? Provide numeric values when present.\",\n",
    "    \"Limitations\": \"What limitations or weaknesses do the authors mention?\",\n",
    "    \"Future Work\": \"What future work or extensions do the authors propose?\"\n",
    "}\n",
    "\n",
    "SECTION_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert AI research assistant. Create a concise academic-style summary for the section: \"{section_name}\".\n",
    "\n",
    "Context (retrieved passages):\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "- Extract facts from the context only (do not hallucinate).\n",
    "- If you cannot find explicit info, say \"Not stated in retrieved passages\".\n",
    "- Be concise and include numeric metrics where possible.\n",
    "\"\"\"\n",
    "section_prompt = PromptTemplate.from_template(SECTION_PROMPT_TEMPLATE)\n",
    "section_chain = section_prompt | llm | StrOutputParser()\n",
    "\n",
    "def summarize_section_with_headings(section_name, query, index, sections, embedding_model, llm, top_k=TOP_K, rerank=RERANK_WITH_LLM):\n",
    "    print(f\"\\n--- Section: {section_name} ---\")\n",
    "    candidates = retrieve_sections_for_query(query, index, sections, embedding_model, top_k)\n",
    "    if rerank:\n",
    "        candidates = rerank_with_llm(query, candidates, llm, rerank_k=top_k)\n",
    "    context = \"\\n\\n\".join([f\"### {c['heading']}\\n{c['text']}\" for c in candidates])\n",
    "    out = section_chain.invoke({\"section_name\": section_name, \"context\": context})\n",
    "    return out\n",
    "\n",
    "# --------------------------\n",
    "# Combine section summaries\n",
    "# --------------------------\n",
    "FINAL_COMBINE_PROMPT = \"\"\"\n",
    "You are an expert AI research assistant. Combine the following section-level summaries into one coherent and well-structured paper summary.\n",
    "Keep the headings and produce a short global conclusion (2-3 sentences) at the end.\n",
    "\n",
    "Section summaries:\n",
    "{sections_text}\n",
    "\n",
    "Combine and output as a clean, academic-style summary.\n",
    "\"\"\"\n",
    "final_prompt = PromptTemplate.from_template(FINAL_COMBINE_PROMPT)\n",
    "final_chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "def combine_and_refine(section_summaries: dict):\n",
    "    sections_text = \"\\n\\n\".join([f\"## {k}\\n{v}\" for k, v in section_summaries.items()])\n",
    "    combined = final_chain.invoke({\"sections_text\": sections_text})\n",
    "    return combined\n",
    "\n",
    "# --------------------------\n",
    "# Full pipeline runner\n",
    "# --------------------------\n",
    "def run_full_pipeline(pdf_path):\n",
    "    # 1) Extract sections via GROBID\n",
    "    sections = load_pdf_sections_via_grobid(pdf_path)\n",
    "    \n",
    "    # 2) Build FAISS index on sections\n",
    "    index, embeddings_array = build_section_index(sections, embedding_model)\n",
    "    \n",
    "    # 3) Summarize each target section\n",
    "    section_summaries = {}\n",
    "    for sname, sq in SECTION_QUERIES.items():\n",
    "        summary = summarize_section_with_headings(sname, sq, index, sections, embedding_model, llm)\n",
    "        section_summaries[sname] = summary\n",
    "    \n",
    "    # 4) Combine & final polish\n",
    "    final_summary = combine_and_refine(section_summaries)\n",
    "    \n",
    "    return {\n",
    "        \"sections\": section_summaries,\n",
    "        \"final_summary\": final_summary\n",
    "    }\n",
    "\n",
    "# --------------------------\n",
    "# Example usage\n",
    "# --------------------------\n",
    "\n",
    "start = time.time()\n",
    "output = run_full_pipeline(PDF_PATH)\n",
    "elapsed = time.time() - start\n",
    "print(\"\\n\\n==== FINAL SUMMARY (first 1500 chars) ===\\n\")\n",
    "print(output[\"final_summary\"][:1500] + \"...\\n\")\n",
    "print(f\"\\nPipeline completed in {elapsed:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5da9912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Title:** Optimizing Hospital Bed Capacity Forecasting: A Machine Learning Approach\\n**Authors:** Not stated in retrieved passages\\n\\n**Abstract:**\\n\\nThis study aims to optimize hospital bed capacity forecasting using machine learning algorithms. The problem statement revolves around optimizing the Length of Stay (LOS) classification for patients in a Heart ward, highlighting issues such as inefficient use of bed capacity during holidays, high proportion of children requiring long LOS, and insufficient bed capacity. A dataset containing 51,231 records collected between 2011 and 2018 was used to examine LOS classification accuracy using various tools, with Support Vector Machine (SVM) providing the best accuracy.\\n\\nThe study employed a classification approach to predict LOS using machine learning algorithms, including Bayesian Network (BN), K-Nearest Neighbor (KNN), SVM, Decision Tree (DT), and Logistic Regression (LR). The results show that only 6% of patients experienced LOS for more than 15 days, with most patients staying in the Heart ward for only one day. The study also identified several limitations, including neglecting other essential resources such as Specialists, Nurses, Equipment, and Budget, and not considering various external factors that may impact the hospital's Net Hospital Product (NHP) in the future.\\n\\n**Introduction:**\\n\\nHospital bed capacity forecasting is a critical task for healthcare administrators to ensure efficient use of hospital resources and provide high-quality care for patients. However, current methods often neglect other essential resources and external factors that can impact NHP. This study aims to address these limitations by employing machine learning algorithms to optimize hospital bed capacity forecasting.\\n\\n**Methodology:**\\n\\nThe study employed a classification approach to predict LOS using machine learning algorithms. The methodology involved data collection, feature selection, classification algorithms, evaluation metrics, and results analysis. The dataset was split into training (70%) and test data, with SVM providing the best accuracy for LOS classification.\\n\\n**Results:**\\n\\nThe results show that only 6% of patients experienced LOS for more than 15 days, with most patients staying in the Heart ward for only one day. The study also identified several limitations, including neglecting other essential resources such as Specialists, Nurses, Equipment, and Budget, and not considering various external factors that may impact NHP.\\n\\n**Conclusion:**\\n\\nThis study demonstrates the potential of machine learning algorithms to optimize hospital bed capacity forecasting. However, there are several limitations that need to be addressed in future work, including multivariate time series analysis, uncertainty in decision-making, additional factors affecting NHP, and financial analysis. By addressing these limitations and incorporating additional factors, future research can provide more comprehensive insights into hospital bed capacity forecasting and inform decision-making for healthcare administrators.\\n\\n**Future Work:**\\n\\nThe proposed data-driven methodology for hospital bed capacity forecasting has several limitations that need to be addressed in future work. These include:\\n\\n1. **Multivariate time series analysis**: The current study only focused on Heart ward bed capacity forecasting, ignoring other required resources such as Specialists, Nurses, Equipment, and Budget.\\n2. **Uncertainty in decision-making**: Uncertainty is an inevitable aspect of decision-making, which was not considered in the current study.\\n3. **Additional factors affecting NHP**: The study identified several factors that can affect the Net Hospital Product (NHP) of a hospital, including insurance service level, accessibility to other hospitals, service quality level, limits on specialists and equipment, economic conditions, and people's accessibility to periodic checkups.\\n4. **Financial analysis**: The study highlighted the need for 117 beds in the Heart ward from 2022 onward, which requires a significant budget.\\n\\nBy addressing these limitations and incorporating additional factors, future research can provide more comprehensive insights into hospital bed capacity forecasting and inform decision-making for healthcare administrators.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"final_summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5124c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'heading': 'Introduction',\n",
       "  'content': \"Introduction The Hospital Bed Capacity (HBC) forecasting problem has taken significant attention because of its effects on the sustainability of hospitals, particularly in terms of hospital economic efficiency, and patient satisfaction  [1] [2] [3] [4] [5] [6] [7] . The traditional approach to this problem is using simulation or programming models involving several issues, such as the need for some assumptions on attributes of some quantities, for example, the probability distribution of some factors  [8] [9] [10] [11] . In addition, reaching optimum or reasonable solutions is a big challenge of the bed capacity programming models, particularly in the case of large-scale, multi-objective, and integer models. Consequently, using model-free methods for HBC forecasting seems to be a facilitator. Nowadays, business analytics, including Data Analysis (DA), Machine Learning (ML), and Deep Learning (DL) techniques, are widely used as model-free methods in different businesses of services and manufacturing to reach insights on market trends, such as customers' behavior, costs, and technology by no reliance on the simulation or mathematical models  [12] [13] [14] . Also, a reasonable number of their successful applications in the healthcare sector, such as Length of Stay (LOS) forecasting, patient classification, healthcare resources forecasting, and disease diagnosis have been illustrated  [15] [16] [17] [18] . In recent years, a few researchers applied some forecaster tools of ML to predict the required The rest of the paper is as follows. Section 2 reviews the corresponding literature, and Section 3 introduces the proposed data-driven methodology. Section 4 contains the computational results of applying the proposed hybrid data-driven approach in the case study, and finally, Section 5 involves the conclusions, limitations, and recommendations for future works.\"},\n",
       " {'heading': 'Literature review',\n",
       "  'content': \"Literature review The literature on healthcare centers' bed capacity forecasting is reviewed to clear the paper's contributions and novelty aspects.  Bachouch et al. (2012)  considered some limitations, such as budget, shared resources, and beds needed by acute and emergency patients, in the problem of hospital bed planning. Using constraints such as incompatibility between pathologies and continuity of care, an integer linear programming model was proposed, and the results were compared using several solvers such as the CPLEX  [22] . Ben Abdelaziz and Masmoudi (2012) studied the bed capacity of 157 public hospitals in Tunisia when the demand for beds is random using a multi-objective stochastic programming model to allocate the beds to the hospital's departments. In this problem, the three objectives are the total cost of creating new beds, the number of nurses and doctors, and the optimal number of beds  [11] . The healthcare capacities assessment is a matter of great importance in the same vein.  Devapriya et al. (2015)  proposed a discrete-event simulation model to determine the required bed capacity using forecasted patients' volume and LOS  [23] . Also,  Keegan et al. (2018)  used an expanded HIPPOCRATES macrosimulation method to predict the number of beds needed for public and private hospitals in Ireland by 2030. Baseline year and projected demand and capacity profiles in this analysis are generated through the HIPPOCRATES macro-simulation model of demand and cost of health care developed by the ESRI. The emergency department plays a vital role in the hospital because it is the first deal for patients. Therefore, the effective management of the emergency department is significant in improving the quality of service and treatment. Nas and Koyuncu (2019) used ten ML tools to predict the patients' arrival rates. They applied a simulation model to determine the required number of beds in the emergency department by minimizing the LOS in a case study in Turkey  [24] .  Kutafina et al. (2019)  predicted hospital bed occupancy using recurrent neural networks based on 353520-time series records and four features from a hospital in Germany. The results show that the proposed ML model is a powerful tool for automatic planning and decision-making on existing bed capacity planning  [25] .  Zhu et al. (2020)  developed three mathematical models considering the uncertainty of demand for inpatient beds and the number of periods  [26] . They solved and analyzed these models in a public hospital in China. Predicting the required capacity of hospital wards during pandemics, such as Covid-19s, is essential for the hospital.  Deschepper et al. (2021)  used an incremental Poisson model on the previous patients' statistics to establish a Mont-Carlo simulation model for a 10day prediction of needed beds in various wards of A hospital in Ghent.  Haghshenas et al. (2021)  proposed a bi-objective mixed-integer optimization model for Cancer hospitals' location-allocation problem under bed capacity and efficiency considerations  [27] . They forecasted the cancer incidences in the provinces of Iran in 2040 using LR models to provide a plan for cancer hospitals established in each province in some predefined efficient bed capacities. Also, they applied this forecasting method to determine the demand parameter values in a single objective mathematical model for Cancer-curing supply chain planning  [28] . The healthcare system of a country is very complex and vital, that is why  Kabir et al. (2021)  used Recurrent Neural Network (RNN) to predict population growth and applied the Markov decision process to simulate the number of required beds by the next 30 years in a case study of Bangladesh  [29] .  Ordu et al. (2021)  proposed a linear programming model for bed capacity and staff requirement planning in a case study in England. They also forecasted the demand for specialists with ML tools and simulated the patients' treatment pathway using a discrete-event simulation model. It is crucial to determine the operating room bed capacity according to the critical condition of the patients.  Schiele et al. (2021)  predicted the bed occupancy in the Intensive Care Unit (ICU) using an Artificial Neural Network (ANN) algorithm as an ML forecaster and 6000 patients' data from 2010 to 2016 in an ICU scheduling problem in Germany. High traffic of patients in hospitals' wards, in particular the emergency department, affects the capability to provide the optimal level of care.  Tello et al. (2022)  predicted weekly hospital bed capacity using LR as a forecaster per cluster of beds/day. They applied the Kmeans clustering method in SVM as the classifier of beds/day factor in a case study in the USA  [19] .  Latruwe et al. (2023)  proposed a simulation model called the ProMoBed, for inpatient hospitals' bed capacity forecasting. They used LOS, seasonality, and admission data to simulate a stochastic pattern of demand for beds in a case study in Belgium  [8] . Garcia-Vincuna et al. (2023) initially predicted the LOS using linear and non-linear programming and then simulated the bed prediction for the ICU department  [30] . The Covid epidemic sent about 19 million people to hospitals worldwide and showed the importance of forecasting during epidemics.  Redondo et al. (2023)  used a discrete simulation model to predict hospital discharges for Covid patients  [31] .  Bekker et al. (2023)  proposed a linear programming model for predicting hospital beds in the short term. The model predicts admissions and uses a queue-based model to occupy beds, providing accurate results for three days  [32] .  Widyasari et al. (2023)  predicted the bed capacity of Malahayati Hospital in Indonesia using SVM and linear programming  [33] . Covid has put a lot of pressure on healthcare resources worldwide, often challenging hospital capacity and stressing hospital staff,  Johnson et al. (2023)  predicted hospital resources using time series. Results showed that statistical forecasting and ML methods can provide valuable predictions to help make resource planning decisions during epidemics  [34] . The above-reviewed literature, summarized in Table  1 , shows that the commonly used techniques in HBC forecasting have been simulation and programming models. To our best knowledge, only three researchers, including  Kutafina     2022 ), applied ML tools in the healthcare centers' bed capacity planning. These papers used time series data on occupied beds and forecast the required beds in the short-run future, and ignore the direct effects of LOS and NHP. As illustrated in Table  1 , this paper uses a wide variety of techniques from DA, ML, DL, and Statistics to investigate the nature of significant factors, such as patients' LOS, Patients' Age, and NHP, to discover their historical manner and provide valuable information to forecast HBC. In addition, conducting LOS classification to use in HBC forecasting is a unique attribute of this paper.\"},\n",
       " {'heading': 'A hybrid data-driven approach to HBC forecasting',\n",
       "  'content': 'A hybrid data-driven approach to HBC forecasting In this section, the framework of the proposed hybrid data-driven approach to HBC forecasting is provided, and some classification and forecasting algorithms are opted according to the corresponding literature.'},\n",
       " {'heading': 'New framework for HBC forecasting',\n",
       "  'content': \"New framework for HBC forecasting As mentioned in the previous sections, factors of LOS and NHP play the most significant role in the bed capacity forecasting problem. Therefore, conducting descriptive analyses on these factors and other affecting features, for example, patient's age and bed occupancy, provides great initial insights into the problem. Consequently, the LOS classification, NHP distribution across LOS classes, and NHP forecasting are the heart of the proposed bed capacity forecasting framework. The results of these analyses are applied in a simple assumption-free mathematical model to forecast the required beds in the future. In addition, patients' age analysis could provide beneficial insight into the scatter of NHP according to Age, particularly in hospitals without specialized wards for children. Fig.  1  represents the structure and steps of the proposed framework. According to Fig.  1 , like all data-oriented analyses, data collection and pre-processing activities, such as data set cleaning and feature transformations, are the initial conventional steps. The application of DA techniques to the three major features, including patients' Age, NHP, and patients' LOS, can provide massive great information to use in managerial prescriptive notes providing, LOS classification, and NHP forecasting. Through data analysis, some statistical inferences, such as the Hypothesis tests, might be used to verify some descriptive findings. The results of NHP forecasting and LOS-based NHP data analysis are applied in a mathematical model to forecast the hospital bed capacity. There are several algorithms for LOS classification and NHP forecasting. The following sub-sections opt for a set of algorithms that seems much more appropriate according to the literature.\"},\n",
       " {'heading': 'LOS classification algorithms',\n",
       "  'content': \"LOS classification algorithms The LOS literature review showed that although there is a long list of research on patients' LOS forecasting, no history exists on the LOS classification  [35] [36] [37] [38] . But Patients' classification based on various features using BN, K-Nearest Neighbor (KNN), SVM, DT, ANN, AdaBoost (AB), LR, Random Forest (RF), Recency-Frequency-Monetary analysis (RFM), Gradient Boosting (GB), and Ensembles algorithms has been taken great attention, as illustrated in Table  2 . Mentioning Table  2 , the five most popular ML algorithms, including BN, KNN, SVM, DT, and LR, are considered for LOS classification.\"},\n",
       " {'heading': 'NHP forecasting algorithms',\n",
       "  'content': 'NHP forecasting algorithms Table  3  shows the conventional ML and DL forecasters used in the number of patients forecasting. Considering Table  3 , Time series methods are the most convenient forecaster on NHP. In addition, LR and Neural networks were the well-accurate forecasters in most literature. Therefore, SARIMA, SLR, and LSTM neural networks have opted for NHP forecasting.'},\n",
       " {'heading': 'Case study',\n",
       "  'content': 'Case study Rouhani Hospital is a public hospital in Babol City of Mazandaran province located in the northern band of Iran. This hospital has 508 beds, nine wards, and 391 specialists. In this hospital, the Heart ward is the busiest ward possessing 30 beds in the main hall of the Heart ward and 15 beds in the Emergency section of Heart diseases.'},\n",
       " {'heading': 'Data set',\n",
       "  'content': \"Data set The collected data set contains 51231 records between 2011 and 2018. Some features, including age and LOS, are considered to be used in the Heart ward's bed capacity forecasting problem. After removing the outliers and noisy data, 47605 records remained which 70% data are categorized as training data and others as test data.\"},\n",
       " {'heading': 'Data analysis',\n",
       "  'content': \"Data analysis The NHP in the Heard ward, patients' age distribution, and their LOS play significant roles in the required beds forecasting. In this section, some Data analysis techniques are applied to the NHP, LOS, and Age to provide initial insights on these significant factors affecting the number of required beds equal to 25.\"},\n",
       " {'heading': 'Table 2',\n",
       "  'content': 'Table 2 The popular ML algorithms for patients classification.'},\n",
       " {'heading': 'Research', 'content': 'Research'},\n",
       " {'heading': 'NHP descriptive analysis',\n",
       "  'content': \"NHP descriptive analysis Fig.  2  represents the daily NHP in the Heart ward. In this case study, some Heart patients might be hospitalized temporarily in the Emergency section of the Heart ward or other disease wards, waiting for the Heart ward beds evacuation. The reason is that NHP is over the existing bed capacity of the Heart ward on some days. In Fig.  2 , some drastic fallings occur on NHP around the 19 March-4 April each year. Fig.  3  shows these considerable fluctuations in NHP in more detail from 2013 to 2018. All illustrated fluctuations in Fig.  3  occurred during the annual Nowruz holidays, 19 March-4 April, in Iran as the Persian new year ceremony. In this period, there is no accessibility to Heart specialists because all of them are on their private trips. Therefore, there is no new admittance during this period, and this cause to misuse of some beds and risks for patients. On the other hand, a considerable increase occurs in admittance before and after this holiday, especially from 5 April onwards. Three Hypothesis tests are performed on the mean of hospitalized patients during three 20day periods, as presented in Table  4 , to investigate the significance of falling in admittance during this period. The sample corresponding to each period is formed by pooling the patients' statistics from 2013 to 2018 to carry out the Hypothesis tests. Table  5  depicts the outputs of the conducted test using the MINITAB 21.1.0. The probability values from Table  5  show considerable differences between the mean of patients' admittance during BNH and NH, like      1 𝐻 0 ∶ 𝜇 𝐵𝑁𝐻 = 𝜇 𝑁𝐻 𝐻 1 ∶ 𝜇 𝐵𝑁𝐻 ≠ 𝜇 𝑁𝐻 120 0 2 𝐻 0 ∶ 𝜇 𝑃 𝑁𝐻 = 𝜇 𝑁𝐻 𝐻 1 ∶ 𝜇 𝑃 𝑁𝐻 ≠ 𝜇 𝑁𝐻 120 0 3 𝐻 0 ∶ 𝜇 𝐵𝑁𝐻 = 𝜇 𝑃 𝑁𝐻 𝐻 1 ∶ 𝜇 𝐵𝑁𝐻 ≠ 𝜇 𝑃 𝑁𝐻 120 0.175 PNH and NH. Moreover, the p-value=0.175 shows no significant difference between the mean of patients' admittance along BNH and PNH according to corresponding collected data and conventional significance level 0.05. These results verify the conducted data-driven visual inferences from Fig.  2 .\"},\n",
       " {'heading': 'Age-based NHP descriptive analysis',\n",
       "  'content': \"Age-based NHP descriptive analysis Fig.  4  represents that the NHP follows a bimodal pattern according to the patient's age. In addition, the most significant portion of NHP belongs to patients aged between 45 and 85. Using information represented in Fig.  4 , six classes of are considered, including (0,15],  (15, 30] ,  (30, 45] ,  (45, 60] ,  (60, 85] , and (85,99], as depicted in Table  6 . Although Table  6  shows that children's class only involves six percent of total NHP, its share is considerable enough to provide specialized proper room in the Heart ward or even a particular children's Heart ward regarding their special emotional considerations. Another interesting note in Fig.  4  is that the mean age of children hospitalized with Heart issues is about 7. By conducting some diagnostic analyses on the modal nature of children's NHP, the roots of this manner would be investigated and might be beneficial in children's Heart disease treatment management and even prevention in the future. Fig.  5  illustrates  the fact that the rate of admittance is increasing only among people aged between 30 and 60. Fig.  5  illustrates that the admittance of people of age class  (30, 45 ] has taken more and more acceleration. In other words, Heart diseases are becoming more common over the past between younger individuals. This fact allocates more credit to promoting preventive actions on Heart disease in the public.\"},\n",
       " {'heading': 'LOS descriptive analysis',\n",
       "  'content': \"LOS descriptive analysis Fig.  6  represents the patients' LOS distribution. In Fig.  6 , only a few LOSs are too long, and most seem to be less than ten days. This claim is verified in Figs.  7 and 8 , representing the scatter of NHP in terms of LOS. Table  7  represents the share of the first twenty values of LOS in terms of NHP to investigate the frequency of LOS values in detail. Table  7  shows that LOS=1 makes the role of the first to fourth deciles lonely as the first quartile, LOS=2 is the fifth and sixth deciles as the second quartile, LOS=4 is the third quartile, LOS=3 is the seventh decile, LOS=6 is the eighth decile, and LOS=11 is the ninth decile. Also, more than 95.5 percent of patients stay less than 20 days. This information helps to form appropriate classes of LOS.\"},\n",
       " {'heading': 'LOS classification',\n",
       "  'content': \"LOS classification Several sets of LOS classes are made, and their accuracy is examined using several classification tools coded using the Sklearn library of Python, as presented in Table  8 . In Table  8 , the classification results show that SVM provides the best accuracy and introduces the case of six classes of LOS as the best alternative. Table  9  depicts the information on NHP and the time interval of LOS classes. Table  9  illustrates only 6% of patients experienced LOS for more than 15 days, and most would stay in the Heart ward for only one day. In addition, Table  10  presents detailed information on the NHP distribution in each Age class per LOS class. In Table  10 , the lowest proportion of NHP from the first class of LOS, LOS=1, comes from the eldest people's class which seems reasonable because of the more Heart risk and need for continual health monitoring in this class. But the following place is allocated to children means the admittance of this type of Heart patient tends to be longer over other Age classes. A more diagnostic analysis could provide helpful information to make better decisions on the specialized Heart beds for children because the children's class possesses the first rank in the proportion of NHP allocated to the long LOS class. This situation assigns crucial importance to establishing specialized children's Heart wards in the future.\"},\n",
       " {'heading': 'NHP forecasting',\n",
       "  'content': \"NHP forecasting Table  11  summarizes the results of applying three opted forecasters in Section 3.3 using Python libraries. As illustrated in Table  11 , LR opted for forecasting NHP in the future due to providing the least error index. The mentioned hospital was the main center for COVID-19 patients' treatment in Babol City between 2019 and 2021, and hence, the daily NHP is forecasted for the five years from 2022 to 2026.\"},\n",
       " {'heading': 'Heart ward bed capacity forecasting',\n",
       "  'content': \"Heart ward bed capacity forecasting According to Fig.  1 , the forecasted NHP and LOS-based distribution of NHP should be applied to forecast the Heart ward bed capacity in the future. The proportion of NHP in LOS classes, from Table  9 , is applied to forecast the NHP belonging to each LOS class in the future. It is supposed that the expected nights/beds corresponding to LOS classes are equal to 1, 2, 3, 5, 11, and 22, respectively. Eq. (  1 ) uses the forecasted NHP of LOS classes to predict the required daily beds     between 2022 and 2026 (see Fig.  9 ). 𝐻𝐵𝐶 𝑗 = ∑ 𝑖 𝑁𝐻𝑃 𝑖𝑗 + ∑ 𝑖≥2 𝑁𝐻𝑃 𝑖,𝑗−1 + ∑ 𝑖≥3 𝑁𝐻𝑃 𝑖,𝑗−2 + ∑ 𝑖≥4 𝑗−3 ∑ 𝑘=𝑗−4 𝑁𝐻𝑃 𝑖𝑘 + ∑ 𝑖≥5 𝑗−5 ∑ 𝑘=𝑗−10 𝑁𝐻𝑃 𝑖𝑘 + 𝑗−11 ∑ 𝑘=𝑗−20 𝑁𝐻𝑃 6,𝑘 𝑖 = 1, 2, … , 6; 𝑗 = 1, 2, … , 1825 (1) In Eq. (  1 ), i is the index of LOS classes, and j denotes the order of days between 2022 and 2027. Also, 𝑁𝐻𝑃 𝑖𝑗 represents the NHP belonging to the 𝑖th class of LOS that will be admitted in the Heart during day j, and 𝐻𝐵𝐶 𝑗 denotes the needed beds in day j. Fig.  10  illustrates the forecasted HBC in Heart ward from 1 January 2022 to 31 December 2026. Fig.  10  represents drastic increase in the number of required beds because the older hospitalized patients not considered and the calculation only is dependent on the forthcoming NHPs. In this Figure, the average needed bed capacity in the future is forecasted at 120 beds which is much more than the existing 45 beds. Therefore, this hospital's administration should make strategic decisions to increase the bed capacity of the Heart ward from 45 beds to 137 beds by 2026.\"},\n",
       " {'heading': 'Managerial insights',\n",
       "  'content': \"Managerial insights In section 4.3.1, the NHP descriptive analysis showed a type of mismanagement in the use of the existing bed capacity in the Heart ward during about 20 days per year related to the Persian new year holidays. Therefore, some managerial tasks and cultural efforts are needed to provide an equitable shift working for Heart specialists during the new year holidays avoiding empty beds. This could result in sustainable Heart bed capacity in terms of productivity and reliable treatment for high risks Heart patients. In addition, Tables  6 and  10  showed that children are a considerable ratio of Heart patients, and a noticeable proportion of them require too long LOS. Therefore, establishing an appropriate specialized Heart room or Heart ward for children must be a significant goal of the hospital's authorities. Also, Fig.  10  represented the need for 117 beds in the Heart ward from 2022 upward. Providing proper facilities to establish per specialized Heart bed requires a considerable budget. Hence, conducting financial analysis to estimate the needed resources such as money is inevitable, particularly in a developing country such as Iran with tremendous limits on monitorial resources.\"},\n",
       " {'heading': 'Conclusions, limitations, and recommendations',\n",
       "  'content': \"Conclusions, limitations, and recommendations This paper considered the hospital bed capacity forecasting problem and proposed a Data-driven methodology to avoid the limits and difficulties of using traditional programming or simulation models. A hybrid approach involving DA, ML, DL, and statistical inference was applied in a Heart ward bed capacity forecasting. Results showed the need for establishing more beds in the Heart ward from 26 to 137 in 2027. In addition, more considerations on the child Heart patients' treatment and the increasing trend of the occurring Heart diseases among younger people are recommended by results. This paper only focused on HBC forecasting and paid no attention to other required resources such as Specialists, Nurses, Equipment, and Budget. Forecasting these significant factors could provide beneficial information for decision-makers. In addition, some other factors can affect the NHP of a hospital in the future, such as insurance service level, the accessibility to other hospitals, the service quality level, limits on the number of available corresponding specialists, the number of specialized equipment, the economic conditions, and the people's accessibility to periodic checkup. This needs to use multivariate time series data sets and multivariate ML tools in future works. Also, uncertainty is an inevitable fact in decision-making that could be mentioned in the future use of DA, ML, and DL for HBC forecasting.\"},\n",
       " {'heading': 'Ethical statement',\n",
       "  'content': 'Ethical statement The Authors declare that no real clinical data is applied in this paper.'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_pdf_sections_via_grobid(\"papers/hospital_bed_capacity_planning.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e653e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe7fe49e",
   "metadata": {},
   "source": [
    "# Upgraded adaptive pipline \n",
    "- only feed the most relevant sections to the LLM for each schema field \n",
    "- model sees fewer, more focused passages, saving tokens and improve accuracy for long papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fc61f6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
